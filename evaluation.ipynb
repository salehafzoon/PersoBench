{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bert_score openpyxl gensim requests nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = \"FoCus\"                                # Synthetic-PersonaChat, Blended Skill Talk, PEC, ConvAI2, FoCus, IT-ConvAI2\n",
    "LLM_name = \"Gemma-7B-Instruct\"                               # Mistral-7B-Instruct, Llama3-1-8B-Instruct, Qwen2-7B-Instruct,  Gemma-7B-Instruct, gpt-3.5-turbo, gpt-4-turbo, gpt-4o-mini\n",
    "COT_SETUP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: Sure, you will like to know that this p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>User2: Technische Universität Darmstadt in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>User2: I suggest a place, for your wish of see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: The history of the house you are intere...  \n",
       "1  User2: This house was use as a stop for slaves...  \n",
       "2  User2: Sure, you will like to know that this p...  \n",
       "3  User2: Technische Universität Darmstadt in the...  \n",
       "4  User2: I suggest a place, for your wish of see...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'./Prompts/{Dataset}.csv')\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FoCus'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas        0\n",
      "context         0\n",
      "act_response    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>The history of the house you are interested in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>This house was use as a stop for slaves trying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>Sure, you will like to know that this place wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>Technische Universität Darmstadt in the top 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>I suggest a place, for your wish of see librar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I would like to go to University.I live in Mic...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>They offer 132 bachelors degree programs and 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "5  I would like to go to University.I live in Mic...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "5  User1: I think Ive been there before but I don...   \n",
       "\n",
       "                                        act_response  \n",
       "0  The history of the house you are interested in...  \n",
       "1  This house was use as a stop for slaves trying...  \n",
       "2  Sure, you will like to know that this place wa...  \n",
       "3  Technische Universität Darmstadt in the top 25...  \n",
       "4  I suggest a place, for your wish of see librar...  \n",
       "5  They offer 132 bachelors degree programs and 1...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Only For: FoCus, IT-ConvAI2\n",
    "if Dataset == \"FoCus\" or Dataset == \"IT-ConvAI2\":\n",
    "    df['act_response'] = df['act_response'].apply(lambda x: x.split(':', 1)[1].strip() if ':' in x else x.strip())\n",
    "\n",
    "# ### Only For: Blended Skill Talk\n",
    "if Dataset == \"Blended Skill Talk\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[User 1 persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "# ### Only For: PEC\n",
    "if Dataset == \"PEC\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[Responder persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 2)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     425\n",
      "response_time      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.545006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is such a cool historic house! I've alway...</td>\n",
       "      <td>5.607118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm glad you found this place amazing, it coul...</td>\n",
       "      <td>5.250293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, I'm interested in studying science in G...</td>\n",
       "      <td>3.402483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.625911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>The museum is a pharmacy in which I am working...</td>\n",
       "      <td>5.616063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>This is a fascinating archaeological site. Mah...</td>\n",
       "      <td>4.874345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Hello! This is Armagh County Museum. It is a m...</td>\n",
       "      <td>4.586782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>I'm glad you're interested in Nyanga National ...</td>\n",
       "      <td>5.682001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.761924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          gen_response  response_time\n",
       "0                                                  NaN       5.545006\n",
       "1    This is such a cool historic house! I've alway...       5.607118\n",
       "2    I'm glad you found this place amazing, it coul...       5.250293\n",
       "3    Hello, I'm interested in studying science in G...       3.402483\n",
       "4                                                  NaN       5.625911\n",
       "..                                                 ...            ...\n",
       "995  The museum is a pharmacy in which I am working...       5.616063\n",
       "996  This is a fascinating archaeological site. Mah...       4.874345\n",
       "997  Hello! This is Armagh County Museum. It is a m...       4.586782\n",
       "998  I'm glad you're interested in Nyanga National ...       5.682001\n",
       "999                                                NaN       5.761924\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COT_ = \"-COT\" if COT_SETUP else \"\"\n",
    " \n",
    "response = pd.read_csv(f'Responses/{Dataset}/{LLM_name}{COT_}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 80\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas           0\n",
      "act_response       0\n",
      "gen_response     425\n",
      "response_time      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>act_response</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>The history of the house you are interested in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.545006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>This house was use as a stop for slaves trying...</td>\n",
       "      <td>This is such a cool historic house! I've alway...</td>\n",
       "      <td>5.607118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>Sure, you will like to know that this place wa...</td>\n",
       "      <td>I'm glad you found this place amazing, it coul...</td>\n",
       "      <td>5.250293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>Technische Universität Darmstadt in the top 25...</td>\n",
       "      <td>Hello, I'm interested in studying science in G...</td>\n",
       "      <td>3.402483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>I suggest a place, for your wish of see librar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.625911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  The history of the house you are interested in...   \n",
       "1  This house was use as a stop for slaves trying...   \n",
       "2  Sure, you will like to know that this place wa...   \n",
       "3  Technische Universität Darmstadt in the top 25...   \n",
       "4  I suggest a place, for your wish of see librar...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0                                                NaN       5.545006  \n",
       "1  This is such a cool historic house! I've alway...       5.607118  \n",
       "2  I'm glad you found this place amazing, it coul...       5.250293  \n",
       "3  Hello, I'm interested in studying science in G...       3.402483  \n",
       "4                                                NaN       5.625911  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'act_response': df['act_response'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU\n",
    "# device = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge import Rouge\n",
    "import bert_score\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "rouge = Rouge()\n",
    "\n",
    "# Lists to store the metrics\n",
    "bleu_scores = []\n",
    "rouge_scores = []\n",
    "meteor_scores = []\n",
    "bertscore_prec = []\n",
    "bertscore_rec = []\n",
    "bertscore_f1 = []\n",
    "distinct_1 = []\n",
    "distinct_2 = []\n",
    "ue_scores = []\n",
    "c_scores = []\n",
    "consistency_scores = []\n",
    "idf_scores = []\n",
    "persona_distance_scores = []\n",
    "\n",
    "\n",
    "bert_snli_dir = \"Fine-tuning/output/bert_snli\"\n",
    "bert_snli_model = BertForSequenceClassification.from_pretrained(bert_snli_dir)\n",
    "bert_snli_tokenizer = BertTokenizer.from_pretrained(bert_snli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline for UE Score\n",
    "bert_on_snli = pipeline('text-classification', model = bert_snli_model, tokenizer = bert_snli_tokenizer, device=0)\n",
    "\n",
    "bert_dnli_dir = \"Fine-tuning/output/bert_dnli\"\n",
    "bert_dnli_model = BertForSequenceClassification.from_pretrained(bert_dnli_dir)\n",
    "bert_dnli_tokenizer = BertTokenizer.from_pretrained(bert_dnli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline\n",
    "bert_on_dnli = pipeline('text-classification', model = bert_dnli_model, tokenizer = bert_dnli_tokenizer, device=0)\n",
    "\n",
    "\n",
    "# Initialize the Word2Vec Model\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"./GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Initialize smoothing function\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "# Helper functions\n",
    "def compute_bleu(reference, hypothesis):\n",
    "    reference = [str(reference).replace('\\n', ' ').split()]\n",
    "    hypothesis = str(hypothesis).replace('\\n', ' ').split()\n",
    "    return sentence_bleu(reference, hypothesis, smoothing_function=smoothing_function)\n",
    "\n",
    "def compute_rouge(reference, hypothesis):\n",
    "    scores = rouge.get_scores(str(hypothesis).replace('\\n', ' '), str(reference).replace('\\n', ' '), avg=True)\n",
    "    return scores['rouge-1']['f'], scores['rouge-2']['f'], scores['rouge-l']['f']\n",
    "\n",
    "def compute_meteor(reference, hypothesis):\n",
    "    reference = [str(reference).replace('\\n', ' ').split()]\n",
    "    hypothesis = str(hypothesis).replace('\\n', ' ').split()\n",
    "    return meteor_score(reference, hypothesis)\n",
    "\n",
    "def compute_distinct_ngrams(text, n):\n",
    "    tokens = str(text).replace('\\n', ' ').split()\n",
    "    ngrams = list(zip(*[tokens[i:] for i in range(n)]))\n",
    "    distinct_ngrams = len(set(ngrams))\n",
    "    total_ngrams = len(ngrams)\n",
    "    return distinct_ngrams / total_ngrams if total_ngrams > 0 else 0\n",
    "\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "def calculate_c_score(gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the C score based on the entailment results between a generated response (R)\n",
    "    and a given persona (P).\n",
    "\n",
    "    Returns:\n",
    "    int: C-score with possible values:\n",
    "         1 for entailment (positive),\n",
    "         0 for neutral,\n",
    "         -1 for contradiction (negative).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping to interpret the NLI model's output\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "    \n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_dnli(f\"{persona} {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine C score based on entailment results\n",
    "    if label_pr == 'positive':\n",
    "        return 1\n",
    "    elif label_pr == 'neutral':\n",
    "        return 0\n",
    "    elif label_pr == 'negative':\n",
    "        return -1\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected label encountered: {label_pr}\")\n",
    "\n",
    "\n",
    "def calculate_consistency_score(gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the Consistency Score based on the binary entailment results \n",
    "    between a generated response (R) and a given persona (P).\n",
    "\n",
    "    Returns:\n",
    "    int: Consistency Score with binary values:\n",
    "         1 for entailment or neutral,\n",
    "         0 for contradiction.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping for binary classification\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "\n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_dnli(f\"{persona} {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine Consistency Score based on binary entailment results\n",
    "    if label_pr in ['positive', 'neutral']:\n",
    "        return 1\n",
    "    elif label_pr == 'negative':\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected label encountered: {label_pr}\")\n",
    "\n",
    "\n",
    "def calculate_ue_score(act_response, gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the UE score based on entailment between persona, actual response, and generated response.\n",
    "\n",
    "    Returns:\n",
    "    int: UE score with possible values 2, 1, or 0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping to interpret the NLI model's output\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'entailment',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'contradiction'\n",
    "    }\n",
    "    \n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_snli(f\"{persona} [SEP] {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Check entailment between actual response (Q) and generated response (R)\n",
    "    result_qr = bert_on_snli(f\"{act_response} [SEP] {gen_response}\")\n",
    "    label_qr = label_mapping.get(result_qr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine UE score based on entailment results\n",
    "    if label_pr == 'entailment' and label_qr == 'entailment':\n",
    "        return 2\n",
    "    elif label_pr == 'entailment':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def calculate_idf_weighted_overlap(persona, response):\n",
    "    # Fit TF-IDF on both texts and calculate cosine similarity\n",
    "\n",
    "    processed_persona = preprocess_text(persona)\n",
    "    processed_response = preprocess_text(response)\n",
    "    persona_new = str(processed_persona) if not isinstance(processed_persona, str) else processed_persona\n",
    "    response_new = str(processed_response) if not isinstance(processed_response, str) else processed_response\n",
    "    texts = [persona_new, response_new]\n",
    "\n",
    "    # texts = [persona, response]\n",
    "    \n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "\n",
    "def compute_persona_distance(persona, response, model, stop_words):\n",
    "    # Tokenize and filter stopwords\n",
    "    persona_tokens = [word for word in persona.lower().split() if word not in stop_words]\n",
    "    response_tokens = [word for word in response.lower().split() if word not in stop_words]\n",
    "    \n",
    "    # Get word vectors\n",
    "    persona_vecs = [model[word] for word in persona_tokens if word in model]\n",
    "    response_vecs = [model[word] for word in response_tokens if word in model]\n",
    "    \n",
    "    # If no vectors found, return zero similarity\n",
    "    if not persona_vecs or not response_vecs:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute average vectors\n",
    "    persona_avg_vec = np.mean(persona_vecs, axis=0)\n",
    "    response_avg_vec = np.mean(response_vecs, axis=0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return cosine_similarity([persona_avg_vec], [response_avg_vec])[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level to ERROR to suppress warnings about training\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Default worst-case values\n",
    "worst_bleu = 0.0\n",
    "worst_rouge = (0.0, 0.0, 0.0)\n",
    "worst_meteor = 0.0\n",
    "worst_bertscore = (0.0, 0.0, 0.0)\n",
    "worst_distinct = 0.0\n",
    "worst_c_score = -1.0\n",
    "worst_consistency_score = 0.0\n",
    "worst_idf_score = 0.0\n",
    "worst_ue_score = 0.0\n",
    "worst_persona_distance_score = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [12:59<00:00,  1.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>BERTScore_Rec</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "      <th>Dist1</th>\n",
       "      <th>Dist2</th>\n",
       "      <th>C Score</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>IDF Overlap</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.161943</td>\n",
       "      <td>0.848211</td>\n",
       "      <td>0.872643</td>\n",
       "      <td>0.860254</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.238574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012124</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.202705</td>\n",
       "      <td>0.851323</td>\n",
       "      <td>0.847875</td>\n",
       "      <td>0.849595</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.149118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022863</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.153216</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.851652</td>\n",
       "      <td>0.854349</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.169082</td>\n",
       "      <td>0.811197</td>\n",
       "      <td>0.837593</td>\n",
       "      <td>0.824184</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.410034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.751643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.832957</td>\n",
       "      <td>0.867341</td>\n",
       "      <td>0.849801</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.191487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.016133</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.350067</td>\n",
       "      <td>0.856305</td>\n",
       "      <td>0.890171</td>\n",
       "      <td>0.872910</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.593685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.008649</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.238983</td>\n",
       "      <td>0.840385</td>\n",
       "      <td>0.834732</td>\n",
       "      <td>0.837549</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BLEU        R1        R2        RL    METEOR  BERTScore_Prec  \\\n",
       "0    0.000000  0.000000  0.000000  0.000000  0.000000        0.000000   \n",
       "1    0.005120  0.205882  0.000000  0.176471  0.161943        0.848211   \n",
       "2    0.012124  0.236842  0.044944  0.236842  0.202705        0.851323   \n",
       "3    0.022863  0.171429  0.055556  0.171429  0.153216        0.857064   \n",
       "4    0.000000  0.000000  0.000000  0.000000  0.000000        0.000000   \n",
       "..        ...       ...       ...       ...       ...             ...   \n",
       "995  0.008049  0.196721  0.027027  0.163934  0.169082        0.811197   \n",
       "996  0.004392  0.044444  0.000000  0.044444  0.037879        0.832957   \n",
       "997  0.016133  0.250000  0.088889  0.200000  0.350067        0.856305   \n",
       "998  0.008649  0.210526  0.024096  0.184211  0.238983        0.840385   \n",
       "999  0.000000  0.000000  0.000000  0.000000  0.000000        0.000000   \n",
       "\n",
       "     BERTScore_Rec  BERTScore_F1     Dist1     Dist2  C Score  \\\n",
       "0         0.000000      0.000000  0.000000  0.000000     -1.0   \n",
       "1         0.872643      0.860254  0.827586  0.964912      1.0   \n",
       "2         0.847875      0.849595  0.827586  0.982456      1.0   \n",
       "3         0.851652      0.854349  0.941176  1.000000      0.0   \n",
       "4         0.000000      0.000000  0.000000  0.000000     -1.0   \n",
       "..             ...           ...       ...       ...      ...   \n",
       "995       0.837593      0.824184  0.714286  0.935484      1.0   \n",
       "996       0.867341      0.849801  0.833333  1.000000      1.0   \n",
       "997       0.890171      0.872910  0.815789  0.972973      1.0   \n",
       "998       0.834732      0.837549  0.841270  0.951613      0.0   \n",
       "999       0.000000      0.000000  0.000000  0.000000     -1.0   \n",
       "\n",
       "     P Consistency Score  IDF Overlap  UE Score  Persona Distance  \n",
       "0                    0.0     0.000000       0.0          0.000000  \n",
       "1                    1.0     0.238574       0.0          0.857521  \n",
       "2                    1.0     0.149118       0.0          0.690035  \n",
       "3                    1.0     0.068436       0.0          0.640356  \n",
       "4                    0.0     0.000000       0.0          0.000000  \n",
       "..                   ...          ...       ...               ...  \n",
       "995                  1.0     0.410034       1.0          0.751643  \n",
       "996                  1.0     0.191487       0.0          0.836204  \n",
       "997                  1.0     0.055004       1.0          0.593685  \n",
       "998                  1.0     0.040507       0.0          0.677568  \n",
       "999                  0.0     0.000000       0.0          0.000000  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a counter for invalid gen_response\n",
    "invalid_gen_res_count = 0\n",
    "\n",
    "# Iterate over each row\n",
    "for index, row in tqdm(eval_df.iterrows(), total=len(eval_df)):\n",
    "    personas = row['personas']\n",
    "    act_response = row['act_response']\n",
    "    gen_response = row['gen_response']\n",
    "\n",
    "    # Check for NaN or None in gen_response\n",
    "    if pd.isna(gen_response):\n",
    "        invalid_gen_res_count += 1\n",
    "        \n",
    "        bleu_scores.append(worst_bleu)\n",
    "        rouge_scores.append(worst_rouge)\n",
    "        meteor_scores.append(worst_meteor)\n",
    "        bertscore_prec.append(worst_bertscore[0])\n",
    "        bertscore_rec.append(worst_bertscore[1])\n",
    "        bertscore_f1.append(worst_bertscore[2])\n",
    "        distinct_1.append(worst_distinct)\n",
    "        distinct_2.append(worst_distinct)\n",
    "        c_scores.append(worst_c_score)\n",
    "        consistency_scores.append(worst_consistency_score)\n",
    "        idf_scores.append(worst_idf_score)\n",
    "        persona_distance_scores.append(worst_persona_distance_score)\n",
    "        ue_scores.append(worst_ue_score)\n",
    "\n",
    "        continue\n",
    "\n",
    "    bleu = compute_bleu(act_response, gen_response)\n",
    "    bleu_scores.append(bleu)\n",
    "    \n",
    "    rouge_1, rouge_2, rouge_l = compute_rouge(act_response, gen_response)\n",
    "    rouge_scores.append((rouge_1, rouge_2, rouge_l))\n",
    "    \n",
    "    meteor = compute_meteor(act_response, gen_response)\n",
    "    meteor_scores.append(meteor)\n",
    "    \n",
    "    P, R, F1 = bert_score.score([gen_response], [act_response], lang=\"en\", verbose=False)\n",
    "    bertscore_prec.append(P.mean().item())\n",
    "    bertscore_rec.append(R.mean().item())\n",
    "    bertscore_f1.append(F1.mean().item())\n",
    "    \n",
    "    distinct_1.append(compute_distinct_ngrams(gen_response, 1))\n",
    "    \n",
    "    distinct_2.append(compute_distinct_ngrams(gen_response, 2))\n",
    "    \n",
    "    c_scores.append(calculate_c_score(personas, gen_response))\n",
    "    \n",
    "    consistency_scores.append(calculate_consistency_score(personas, gen_response))\n",
    "    \n",
    "    ue_scores.append(calculate_ue_score(act_response, gen_response, personas))\n",
    "\n",
    "    idf_scores.append(calculate_idf_weighted_overlap(personas, gen_response))\n",
    "    \n",
    "    persona_distance = compute_persona_distance(personas, gen_response, word2vec_model, stop_words)\n",
    "    persona_distance_scores.append(persona_distance)\n",
    "\n",
    "\n",
    "# Compile metrics into DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'BLEU': bleu_scores,\n",
    "    'R1': [score[0] for score in rouge_scores],\n",
    "    'R2': [score[1] for score in rouge_scores],\n",
    "    'RL': [score[2] for score in rouge_scores],\n",
    "    'METEOR': meteor_scores,\n",
    "    'BERTScore_Prec': bertscore_prec,\n",
    "    'BERTScore_Rec': bertscore_rec,\n",
    "    'BERTScore_F1': bertscore_f1,\n",
    "    'Dist1': distinct_1,\n",
    "    'Dist2': distinct_2,\n",
    "    'C Score': c_scores,\n",
    "    'P Consistency Score': consistency_scores,\n",
    "    'IDF Overlap': idf_scores,\n",
    "    'UE Score': ue_scores,\n",
    "    'Persona Distance': persona_distance_scores\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'response_time' column to 'metrics_df'\n",
    "metrics_df['response_time'] = eval_df['response_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>BERTScore_Rec</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "      <th>Dist1</th>\n",
       "      <th>Dist2</th>\n",
       "      <th>C Score</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>IDF Overlap</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gemma-7B-Instruct</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.1</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.08 ± 0.09</td>\n",
       "      <td>0.09 ± 0.1</td>\n",
       "      <td>0.48 ± 0.42</td>\n",
       "      <td>0.49 ± 0.42</td>\n",
       "      <td>0.49 ± 0.42</td>\n",
       "      <td>0.48 ± 0.42</td>\n",
       "      <td>0.56 ± 0.49</td>\n",
       "      <td>-0.13 ± 0.89</td>\n",
       "      <td>0.53 ± 0.5</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.22 ± 0.53</td>\n",
       "      <td>0.39 ± 0.34</td>\n",
       "      <td>5.17 ± 1.03</td>\n",
       "      <td>0.425 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model         BLEU          R1           R2           RL  \\\n",
       "0  Gemma-7B-Instruct  0.01 ± 0.01  0.09 ± 0.1  0.01 ± 0.03  0.08 ± 0.09   \n",
       "\n",
       "       METEOR BERTScore_Prec BERTScore_Rec BERTScore_F1        Dist1  \\\n",
       "0  0.09 ± 0.1    0.48 ± 0.42   0.49 ± 0.42  0.49 ± 0.42  0.48 ± 0.42   \n",
       "\n",
       "         Dist2       C Score P Consistency Score IDF Overlap     UE Score  \\\n",
       "0  0.56 ± 0.49  -0.13 ± 0.89          0.53 ± 0.5  0.08 ± 0.1  0.22 ± 0.53   \n",
       "\n",
       "  Persona Distance response_time Failure Ratio  \n",
       "0      0.39 ± 0.34   5.17 ± 1.03  0.425 ± 0.00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean (average) and standard deviation, rounded to 2 decimal places\n",
    "avg_values = metrics_df.mean().round(2)\n",
    "std_values = metrics_df.std(ddof=0).round(2)  # Use ddof=0 for population standard deviation\n",
    "\n",
    "# Combine the average and standard deviation into the format \"avg ± std\"\n",
    "combined_values = avg_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "\n",
    "# Insert the LLM name at the beginning of the combined values\n",
    "combined_values = combined_values.tolist()\n",
    "combined_values.insert(0, LLM_name)\n",
    "\n",
    "# Create a DataFrame for the combined average ± std row\n",
    "result_df = pd.DataFrame([combined_values], columns=['Model'] + metrics_df.columns.tolist())\n",
    "\n",
    "# Add the ratio of invalid gen_response\n",
    "invalid_gen_res_ratio = invalid_gen_res_count / len(eval_df)\n",
    "result_df['Failure Ratio'] = f\"{round(invalid_gen_res_ratio, 3)} ± 0.00\"  # No std for Failure Ratio\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>...</th>\n",
       "      <th>IDF Overlap</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama3-1-8B-Instruct</td>\n",
       "      <td>0.49 ± 0.5</td>\n",
       "      <td>-0.22 ± 0.87</td>\n",
       "      <td>0.17 ± 0.48\\t</td>\n",
       "      <td>0.02 ± 0.08</td>\n",
       "      <td>0.11 ± 0.15</td>\n",
       "      <td>0.03 ± 0.1</td>\n",
       "      <td>0.1 ± 0.14</td>\n",
       "      <td>0.11 ± 0.14</td>\n",
       "      <td>0.47 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.1</td>\n",
       "      <td>0.33 ± 0.33</td>\n",
       "      <td>4.54 ± 0.21</td>\n",
       "      <td>0.448 ± 0.00</td>\n",
       "      <td>0.51 ± 0.46</td>\n",
       "      <td>0.55 ± 0.49</td>\n",
       "      <td>1.71 ± 1.88</td>\n",
       "      <td>0.42 ± 0.47</td>\n",
       "      <td>0.51 ± 0.46</td>\n",
       "      <td>0.74 ± 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.82 ± 0.39</td>\n",
       "      <td>0.26 ± 0.75</td>\n",
       "      <td>0.37 ± 0.67</td>\n",
       "      <td>0.04 ± 0.09</td>\n",
       "      <td>0.2 ± 0.14</td>\n",
       "      <td>0.06 ± 0.12</td>\n",
       "      <td>0.18 ± 0.14</td>\n",
       "      <td>0.2 ± 0.15</td>\n",
       "      <td>0.78 ± 0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.07</td>\n",
       "      <td>0.51 ± 0.21</td>\n",
       "      <td>1.3 ± 0.42</td>\n",
       "      <td>0.09 ± 0.00</td>\n",
       "      <td>0.84 ± 0.27</td>\n",
       "      <td>0.91 ± 0.29</td>\n",
       "      <td>2.31 ± 1.27</td>\n",
       "      <td>0.72 ± 0.39</td>\n",
       "      <td>0.84 ± 0.27</td>\n",
       "      <td>1.12 ± 0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.81 ± 0.39\\t</td>\n",
       "      <td>0.16 ± 0.71</td>\n",
       "      <td>0.35 ± 0.69</td>\n",
       "      <td>0.03 ± 0.05</td>\n",
       "      <td>0.19 ± 0.11</td>\n",
       "      <td>0.06 ± 0.08</td>\n",
       "      <td>0.17 ± 0.1</td>\n",
       "      <td>0.22 ± 0.15</td>\n",
       "      <td>0.78 ± 0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.05</td>\n",
       "      <td>0.54 ± 0.19</td>\n",
       "      <td>1.43 ± 0.66</td>\n",
       "      <td>0.086 ± 0.00</td>\n",
       "      <td>0.85 ± 0.27</td>\n",
       "      <td>0.91 ± 0.28</td>\n",
       "      <td>2.61 ± 1.2</td>\n",
       "      <td>0.72 ± 0.36</td>\n",
       "      <td>0.86 ± 0.26</td>\n",
       "      <td>1.19 ± 0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>0.84 ± 0.36</td>\n",
       "      <td>0.14 ± 0.66</td>\n",
       "      <td>0.39 ± 0.73</td>\n",
       "      <td>0.04 ± 0.08</td>\n",
       "      <td>0.23 ± 0.13</td>\n",
       "      <td>0.08 ± 0.11</td>\n",
       "      <td>0.2 ± 0.13</td>\n",
       "      <td>0.23 ± 0.16</td>\n",
       "      <td>0.84 ± 0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.05</td>\n",
       "      <td>0.51 ± 0.15</td>\n",
       "      <td>3.32 ± 1.24</td>\n",
       "      <td>0.035 ± 0.00</td>\n",
       "      <td>0.91 ± 0.18</td>\n",
       "      <td>0.96 ± 0.18</td>\n",
       "      <td>2.2 ± 0.94</td>\n",
       "      <td>0.66 ± 0.38</td>\n",
       "      <td>0.91 ± 0.18</td>\n",
       "      <td>1.13 ± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.45 ± 0.5</td>\n",
       "      <td>-0.31 ± 0.84</td>\n",
       "      <td>0.17 ± 0.48</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.08 ± 0.09</td>\n",
       "      <td>0.1 ± 0.13</td>\n",
       "      <td>0.41 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04 ± 0.06</td>\n",
       "      <td>0.29 ± 0.3</td>\n",
       "      <td>3.74 ± 0.76</td>\n",
       "      <td>0.509 ± 0.00</td>\n",
       "      <td>0.46 ± 0.47</td>\n",
       "      <td>0.49 ± 0.5</td>\n",
       "      <td>1.72 ± 1.93</td>\n",
       "      <td>0.43 ± 0.47</td>\n",
       "      <td>0.46 ± 0.47</td>\n",
       "      <td>0.71 ± 0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mistral-7B-Instruct</td>\n",
       "      <td>0.52 ± 0.5\\t</td>\n",
       "      <td>-0.23 ± 0.82</td>\n",
       "      <td>0.21 ± 0.52</td>\n",
       "      <td>0.01 ± 0.04</td>\n",
       "      <td>0.11 ± 0.12</td>\n",
       "      <td>0.03 ± 0.06</td>\n",
       "      <td>0.1 ± 0.11</td>\n",
       "      <td>0.11 ± 0.14</td>\n",
       "      <td>0.48 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.07</td>\n",
       "      <td>0.3 ± 0.28</td>\n",
       "      <td>4.39 ± 0.36</td>\n",
       "      <td>0.435 ± 0.00</td>\n",
       "      <td>0.53 ± 0.46</td>\n",
       "      <td>0.56 ± 0.49</td>\n",
       "      <td>1.54 ± 1.55</td>\n",
       "      <td>0.45 ± 0.46</td>\n",
       "      <td>0.53 ± 0.46</td>\n",
       "      <td>0.72 ± 0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gemma-7B-Instruct</td>\n",
       "      <td>0.53 ± 0.5</td>\n",
       "      <td>-0.13 ± 0.89</td>\n",
       "      <td>0.22 ± 0.53</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.1</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.08 ± 0.09</td>\n",
       "      <td>0.09 ± 0.1</td>\n",
       "      <td>0.48 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.39 ± 0.34</td>\n",
       "      <td>5.17 ± 1.03</td>\n",
       "      <td>0.425 ± 0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model P Consistency Score       C Score       UE Score  \\\n",
       "0  Llama3-1-8B-Instruct          0.49 ± 0.5  -0.22 ± 0.87  0.17 ± 0.48\\t   \n",
       "1         gpt-3.5-turbo         0.82 ± 0.39   0.26 ± 0.75    0.37 ± 0.67   \n",
       "2           gpt-4o-mini       0.81 ± 0.39\\t   0.16 ± 0.71    0.35 ± 0.69   \n",
       "3           gpt-4-turbo         0.84 ± 0.36   0.14 ± 0.66    0.39 ± 0.73   \n",
       "4     Qwen2-7B-Instruct          0.45 ± 0.5  -0.31 ± 0.84    0.17 ± 0.48   \n",
       "5   Mistral-7B-Instruct        0.52 ± 0.5\\t  -0.23 ± 0.82    0.21 ± 0.52   \n",
       "6     Gemma-7B-Instruct          0.53 ± 0.5  -0.13 ± 0.89    0.22 ± 0.53   \n",
       "\n",
       "          BLEU           R1           R2           RL       METEOR  \\\n",
       "0  0.02 ± 0.08  0.11 ± 0.15   0.03 ± 0.1   0.1 ± 0.14  0.11 ± 0.14   \n",
       "1  0.04 ± 0.09   0.2 ± 0.14  0.06 ± 0.12  0.18 ± 0.14   0.2 ± 0.15   \n",
       "2  0.03 ± 0.05  0.19 ± 0.11  0.06 ± 0.08   0.17 ± 0.1  0.22 ± 0.15   \n",
       "3  0.04 ± 0.08  0.23 ± 0.13  0.08 ± 0.11   0.2 ± 0.13  0.23 ± 0.16   \n",
       "4  0.01 ± 0.02   0.08 ± 0.1  0.02 ± 0.04  0.08 ± 0.09   0.1 ± 0.13   \n",
       "5  0.01 ± 0.04  0.11 ± 0.12  0.03 ± 0.06   0.1 ± 0.11  0.11 ± 0.14   \n",
       "6  0.01 ± 0.01   0.09 ± 0.1  0.01 ± 0.03  0.08 ± 0.09   0.09 ± 0.1   \n",
       "\n",
       "  BERTScore_Prec  ...  IDF Overlap Persona Distance response_time  \\\n",
       "0    0.47 ± 0.42  ...   0.06 ± 0.1      0.33 ± 0.33   4.54 ± 0.21   \n",
       "1    0.78 ± 0.25  ...  0.07 ± 0.07      0.51 ± 0.21    1.3 ± 0.42   \n",
       "2    0.78 ± 0.24  ...  0.06 ± 0.05      0.54 ± 0.19   1.43 ± 0.66   \n",
       "3    0.84 ± 0.16  ...  0.05 ± 0.05      0.51 ± 0.15   3.32 ± 1.24   \n",
       "4    0.41 ± 0.42  ...  0.04 ± 0.06       0.29 ± 0.3   3.74 ± 0.76   \n",
       "5    0.48 ± 0.42  ...  0.05 ± 0.07       0.3 ± 0.28   4.39 ± 0.36   \n",
       "6    0.48 ± 0.42  ...   0.08 ± 0.1      0.39 ± 0.34   5.17 ± 1.03   \n",
       "\n",
       "  Failure Ratio UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  0.448 ± 0.00         0.51 ± 0.46       0.55 ± 0.49          1.71 ± 1.88   \n",
       "1   0.09 ± 0.00         0.84 ± 0.27       0.91 ± 0.29          2.31 ± 1.27   \n",
       "2  0.086 ± 0.00         0.85 ± 0.27       0.91 ± 0.28           2.61 ± 1.2   \n",
       "3  0.035 ± 0.00         0.91 ± 0.18       0.96 ± 0.18           2.2 ± 0.94   \n",
       "4  0.509 ± 0.00         0.46 ± 0.47        0.49 ± 0.5          1.72 ± 1.93   \n",
       "5  0.435 ± 0.00         0.53 ± 0.46       0.56 ± 0.49          1.54 ± 1.55   \n",
       "6  0.425 ± 0.00                 NaN               NaN                  NaN   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.42 ± 0.47               0.51 ± 0.46      0.74 ± 0.7  \n",
       "1          0.72 ± 0.39               0.84 ± 0.27     1.12 ± 0.42  \n",
       "2          0.72 ± 0.36               0.86 ± 0.26     1.19 ± 0.41  \n",
       "3          0.66 ± 0.38               0.91 ± 0.18     1.13 ± 0.28  \n",
       "4          0.43 ± 0.47               0.46 ± 0.47     0.71 ± 0.75  \n",
       "5          0.45 ± 0.46               0.53 ± 0.46     0.72 ± 0.65  \n",
       "6                  NaN                       NaN             NaN  \n",
       "\n",
       "[7 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the existing Excel file and update or append the average row\n",
    "output_path = f'./Evaluations/{Dataset}{COT_}-results.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing data\n",
    "    existing_df = pd.read_excel(output_path)\n",
    "    # Check if the model name already exists\n",
    "    if LLM_name in existing_df['Model'].values:\n",
    "        # Update the row with the same model name\n",
    "        existing_df.loc[existing_df['Model'] == LLM_name, :] = result_df.values\n",
    "    else:\n",
    "        # Append the new data\n",
    "        existing_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new DataFrame\n",
    "    existing_df = result_df\n",
    "\n",
    "# Save the updated DataFrame to an Excel file\n",
    "existing_df.to_excel(output_path, index=False)\n",
    "\n",
    "existing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>...</th>\n",
       "      <th>IDF Overlap</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama3-1-8B-Instruct</td>\n",
       "      <td>0.49 ± 0.5</td>\n",
       "      <td>-0.22 ± 0.87</td>\n",
       "      <td>0.17 ± 0.48\\t</td>\n",
       "      <td>0.02 ± 0.08</td>\n",
       "      <td>0.11 ± 0.15</td>\n",
       "      <td>0.03 ± 0.1</td>\n",
       "      <td>0.1 ± 0.14</td>\n",
       "      <td>0.11 ± 0.14</td>\n",
       "      <td>0.47 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.1</td>\n",
       "      <td>0.33 ± 0.33</td>\n",
       "      <td>4.54 ± 0.21</td>\n",
       "      <td>0.448 ± 0.00</td>\n",
       "      <td>0.51 ± 0.46</td>\n",
       "      <td>0.55 ± 0.49</td>\n",
       "      <td>1.71 ± 1.88</td>\n",
       "      <td>0.42 ± 0.47</td>\n",
       "      <td>0.51 ± 0.46</td>\n",
       "      <td>0.74 ± 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.82 ± 0.39</td>\n",
       "      <td>0.26 ± 0.75</td>\n",
       "      <td>0.37 ± 0.67</td>\n",
       "      <td>0.04 ± 0.09</td>\n",
       "      <td>0.2 ± 0.14</td>\n",
       "      <td>0.06 ± 0.12</td>\n",
       "      <td>0.18 ± 0.14</td>\n",
       "      <td>0.2 ± 0.15</td>\n",
       "      <td>0.78 ± 0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.07</td>\n",
       "      <td>0.51 ± 0.21</td>\n",
       "      <td>1.3 ± 0.42</td>\n",
       "      <td>0.09 ± 0.00</td>\n",
       "      <td>0.84 ± 0.27</td>\n",
       "      <td>0.91 ± 0.29</td>\n",
       "      <td>2.31 ± 1.27</td>\n",
       "      <td>0.72 ± 0.39</td>\n",
       "      <td>0.84 ± 0.27</td>\n",
       "      <td>1.12 ± 0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.81 ± 0.39\\t</td>\n",
       "      <td>0.16 ± 0.71</td>\n",
       "      <td>0.35 ± 0.69</td>\n",
       "      <td>0.03 ± 0.05</td>\n",
       "      <td>0.19 ± 0.11</td>\n",
       "      <td>0.06 ± 0.08</td>\n",
       "      <td>0.17 ± 0.1</td>\n",
       "      <td>0.22 ± 0.15</td>\n",
       "      <td>0.78 ± 0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.05</td>\n",
       "      <td>0.54 ± 0.19</td>\n",
       "      <td>1.43 ± 0.66</td>\n",
       "      <td>0.086 ± 0.00</td>\n",
       "      <td>0.85 ± 0.27</td>\n",
       "      <td>0.91 ± 0.28</td>\n",
       "      <td>2.61 ± 1.2</td>\n",
       "      <td>0.72 ± 0.36</td>\n",
       "      <td>0.86 ± 0.26</td>\n",
       "      <td>1.19 ± 0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>0.84 ± 0.36</td>\n",
       "      <td>0.14 ± 0.66</td>\n",
       "      <td>0.39 ± 0.73</td>\n",
       "      <td>0.04 ± 0.08</td>\n",
       "      <td>0.23 ± 0.13</td>\n",
       "      <td>0.08 ± 0.11</td>\n",
       "      <td>0.2 ± 0.13</td>\n",
       "      <td>0.23 ± 0.16</td>\n",
       "      <td>0.84 ± 0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.05</td>\n",
       "      <td>0.51 ± 0.15</td>\n",
       "      <td>3.32 ± 1.24</td>\n",
       "      <td>0.035 ± 0.00</td>\n",
       "      <td>0.91 ± 0.18</td>\n",
       "      <td>0.96 ± 0.18</td>\n",
       "      <td>2.2 ± 0.94</td>\n",
       "      <td>0.66 ± 0.38</td>\n",
       "      <td>0.91 ± 0.18</td>\n",
       "      <td>1.13 ± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.45 ± 0.5</td>\n",
       "      <td>-0.31 ± 0.84</td>\n",
       "      <td>0.17 ± 0.48</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.08 ± 0.09</td>\n",
       "      <td>0.1 ± 0.13</td>\n",
       "      <td>0.41 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04 ± 0.06</td>\n",
       "      <td>0.29 ± 0.3</td>\n",
       "      <td>3.74 ± 0.76</td>\n",
       "      <td>0.509 ± 0.00</td>\n",
       "      <td>0.46 ± 0.47</td>\n",
       "      <td>0.49 ± 0.5</td>\n",
       "      <td>1.72 ± 1.93</td>\n",
       "      <td>0.43 ± 0.47</td>\n",
       "      <td>0.46 ± 0.47</td>\n",
       "      <td>0.71 ± 0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mistral-7B-Instruct</td>\n",
       "      <td>0.52 ± 0.5\\t</td>\n",
       "      <td>-0.23 ± 0.82</td>\n",
       "      <td>0.21 ± 0.52</td>\n",
       "      <td>0.01 ± 0.04</td>\n",
       "      <td>0.11 ± 0.12</td>\n",
       "      <td>0.03 ± 0.06</td>\n",
       "      <td>0.1 ± 0.11</td>\n",
       "      <td>0.11 ± 0.14</td>\n",
       "      <td>0.48 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.07</td>\n",
       "      <td>0.3 ± 0.28</td>\n",
       "      <td>4.39 ± 0.36</td>\n",
       "      <td>0.435 ± 0.00</td>\n",
       "      <td>0.53 ± 0.46</td>\n",
       "      <td>0.56 ± 0.49</td>\n",
       "      <td>1.54 ± 1.55</td>\n",
       "      <td>0.45 ± 0.46</td>\n",
       "      <td>0.53 ± 0.46</td>\n",
       "      <td>0.72 ± 0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gemma-7B-Instruct</td>\n",
       "      <td>0.53 ± 0.5</td>\n",
       "      <td>-0.13 ± 0.89</td>\n",
       "      <td>0.22 ± 0.53</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.1</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.08 ± 0.09</td>\n",
       "      <td>0.09 ± 0.1</td>\n",
       "      <td>0.48 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.39 ± 0.34</td>\n",
       "      <td>5.17 ± 1.03</td>\n",
       "      <td>0.425 ± 0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model P Consistency Score       C Score       UE Score  \\\n",
       "0  Llama3-1-8B-Instruct          0.49 ± 0.5  -0.22 ± 0.87  0.17 ± 0.48\\t   \n",
       "1         gpt-3.5-turbo         0.82 ± 0.39   0.26 ± 0.75    0.37 ± 0.67   \n",
       "2           gpt-4o-mini       0.81 ± 0.39\\t   0.16 ± 0.71    0.35 ± 0.69   \n",
       "3           gpt-4-turbo         0.84 ± 0.36   0.14 ± 0.66    0.39 ± 0.73   \n",
       "4     Qwen2-7B-Instruct          0.45 ± 0.5  -0.31 ± 0.84    0.17 ± 0.48   \n",
       "5   Mistral-7B-Instruct        0.52 ± 0.5\\t  -0.23 ± 0.82    0.21 ± 0.52   \n",
       "6     Gemma-7B-Instruct          0.53 ± 0.5  -0.13 ± 0.89    0.22 ± 0.53   \n",
       "\n",
       "          BLEU           R1           R2           RL       METEOR  \\\n",
       "0  0.02 ± 0.08  0.11 ± 0.15   0.03 ± 0.1   0.1 ± 0.14  0.11 ± 0.14   \n",
       "1  0.04 ± 0.09   0.2 ± 0.14  0.06 ± 0.12  0.18 ± 0.14   0.2 ± 0.15   \n",
       "2  0.03 ± 0.05  0.19 ± 0.11  0.06 ± 0.08   0.17 ± 0.1  0.22 ± 0.15   \n",
       "3  0.04 ± 0.08  0.23 ± 0.13  0.08 ± 0.11   0.2 ± 0.13  0.23 ± 0.16   \n",
       "4  0.01 ± 0.02   0.08 ± 0.1  0.02 ± 0.04  0.08 ± 0.09   0.1 ± 0.13   \n",
       "5  0.01 ± 0.04  0.11 ± 0.12  0.03 ± 0.06   0.1 ± 0.11  0.11 ± 0.14   \n",
       "6  0.01 ± 0.01   0.09 ± 0.1  0.01 ± 0.03  0.08 ± 0.09   0.09 ± 0.1   \n",
       "\n",
       "  BERTScore_Prec  ...  IDF Overlap Persona Distance response_time  \\\n",
       "0    0.47 ± 0.42  ...   0.06 ± 0.1      0.33 ± 0.33   4.54 ± 0.21   \n",
       "1    0.78 ± 0.25  ...  0.07 ± 0.07      0.51 ± 0.21    1.3 ± 0.42   \n",
       "2    0.78 ± 0.24  ...  0.06 ± 0.05      0.54 ± 0.19   1.43 ± 0.66   \n",
       "3    0.84 ± 0.16  ...  0.05 ± 0.05      0.51 ± 0.15   3.32 ± 1.24   \n",
       "4    0.41 ± 0.42  ...  0.04 ± 0.06       0.29 ± 0.3   3.74 ± 0.76   \n",
       "5    0.48 ± 0.42  ...  0.05 ± 0.07       0.3 ± 0.28   4.39 ± 0.36   \n",
       "6    0.48 ± 0.42  ...   0.08 ± 0.1      0.39 ± 0.34   5.17 ± 1.03   \n",
       "\n",
       "  Failure Ratio UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  0.448 ± 0.00         0.51 ± 0.46       0.55 ± 0.49          1.71 ± 1.88   \n",
       "1   0.09 ± 0.00         0.84 ± 0.27       0.91 ± 0.29          2.31 ± 1.27   \n",
       "2  0.086 ± 0.00         0.85 ± 0.27       0.91 ± 0.28           2.61 ± 1.2   \n",
       "3  0.035 ± 0.00         0.91 ± 0.18       0.96 ± 0.18           2.2 ± 0.94   \n",
       "4  0.509 ± 0.00         0.46 ± 0.47        0.49 ± 0.5          1.72 ± 1.93   \n",
       "5  0.435 ± 0.00         0.53 ± 0.46       0.56 ± 0.49          1.54 ± 1.55   \n",
       "6  0.425 ± 0.00                 NaN               NaN                  NaN   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.42 ± 0.47               0.51 ± 0.46      0.74 ± 0.7  \n",
       "1          0.72 ± 0.39               0.84 ± 0.27     1.12 ± 0.42  \n",
       "2          0.72 ± 0.36               0.86 ± 0.26     1.19 ± 0.41  \n",
       "3          0.66 ± 0.38               0.91 ± 0.18     1.13 ± 0.28  \n",
       "4          0.43 ± 0.47               0.46 ± 0.47     0.71 ± 0.75  \n",
       "5          0.45 ± 0.46               0.53 ± 0.46     0.72 ± 0.65  \n",
       "6                  NaN                       NaN             NaN  \n",
       "\n",
       "[7 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_excel(f'./Evaluations/{Dataset}{COT_}-results.xlsx')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salehafzoon/Desktop/Perso-LLM-Benchmarking/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import gensim\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU\n",
    "\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"./GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "nli_model = pipeline('text-classification', model='facebook/bart-large-mnli', device=device)\n",
    "\n",
    "persona_text = \"I am a software engineer. I love coding in Python. I also enjoy hiking during weekends.\"\n",
    "response_text = \"Coding in Python is one of my favorite activities. On weekends, I often go hiking.\"\n",
    "gen_response_text = \"On weekends, I often go hiking, and Python coding is something I really enjoy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00336669  1.         -0.01056319  0.13576175  0.11221063  0.19117984\n",
      "   0.09335288  0.1638258   1.          0.2615446 ]]\n",
      "[[ 0.18068513  0.25550863 -0.03758506  0.21812178  0.02882948  0.05052864\n",
      "   0.34898528  0.13838342  0.2555086   0.21406093]]\n",
      "[[0.00118619 0.09245683 0.03459306 0.02209745 0.14510264 0.51879144\n",
      "  0.06418717 0.0685657  0.09245681 0.0643034 ]]\n",
      "[[-0.00336669  1.         -0.01056319  0.13576175  0.11221063  0.19117984\n",
      "   0.09335288  0.1638258   1.          0.2615446 ]]\n",
      "[[0.04461894 0.16269058 0.1994664  0.20273286 0.06281446 0.03281252\n",
      "  0.06216637 0.31501308 0.16269056 0.41482794]]\n",
      "[[-2.1985812e-02  1.9117984e-01  1.2112212e-01  2.7989851e-02\n",
      "   1.6500372e-01  1.0000000e+00 -3.7418772e-04  1.0601519e-01\n",
      "   1.9117984e-01  6.1645295e-02]]\n",
      "[[0.3958767  0.01996717 0.14580318 0.15322813 0.0025511  0.02053415\n",
      "  0.243254   0.08290297 0.01996717 0.18737666]]\n",
      "[[-0.00336669  1.         -0.01056319  0.13576175  0.11221063  0.19117984\n",
      "   0.09335288  0.1638258   1.          0.2615446 ]]\n",
      "[[ 0.2104019  -0.04289635  0.3481123   0.0782875   0.03665383  0.00811716\n",
      "   0.147345    0.22326273 -0.04289632  0.28244206]]\n",
      "[[ 0.10209026  0.08480105  0.10774407  0.30473733 -0.03164742  0.00379885\n",
      "   0.14880571  0.19968794  0.08480105  0.28791246]]\n",
      "[[0.08312806 0.00245738 0.04830759 0.14001153 0.10175038 0.03978709\n",
      "  0.03277263 0.09682474 0.00245735 0.06542248]]\n",
      "[[ 0.30746818 -0.04894466  0.19001004  0.09381618 -0.03622447 -0.0037804\n",
      "   0.03164372  0.0304765  -0.04894465  0.12457976]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5649009"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_persona_distance(persona, response, word2vec):\n",
    "    \n",
    "    # persona and response are already pre-processed and stopwords are removed\n",
    "    \n",
    "    persona_tokens = [word for word in persona.lower().split()]\n",
    "    response_tokens = [word for word in response.lower().split()]\n",
    "    \n",
    "    \n",
    "    # Get embeddings for tokens if they exist in the word2vec model\n",
    "    persona_embeddings = [word2vec[word] for word in persona_tokens if word in word2vec]\n",
    "    response_embeddings = [word2vec[word] for word in response_tokens if word in word2vec]\n",
    "    \n",
    "    # Calculate similarity matrices M_i for each persona keyword embedding p_i\n",
    "    similarity_matrices = []\n",
    "    for p_i in persona_embeddings:\n",
    "        similarity_matrix = cosine_similarity([p_i], response_embeddings)\n",
    "        print(similarity_matrix)\n",
    "        similarity_matrices.append(np.max(similarity_matrix))\n",
    "    \n",
    "    # Calculate the P.Distance\n",
    "    p_distance = np.mean(similarity_matrices)\n",
    "    \n",
    "    return p_distance\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "calculate_persona_distance(persona_text, gen_response_text, word2vec_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coh_con_score(act_response, gen_response, persona):\n",
    "    # Check entailment between full Persona (P) and Generated Response (gen_response)\n",
    "    nli_result_pr = nli_model(f\"{persona} [SEP] {gen_response}\")\n",
    "    label_pr = nli_result_pr[0]['label'].lower()\n",
    "    print(f\"Persona Premise: {persona}\")\n",
    "    print(f\"Generated Response Hypothesis: {gen_response}\")\n",
    "    print(f\"NLI Result for (P, gen_response): {nli_result_pr}\")\n",
    "    is_persona_entails_response = label_pr == 'entailment'\n",
    "\n",
    "    # Check entailment between full Actual Response (act_response) and Generated Response (gen_response)\n",
    "    nli_result_qr = nli_model(f\"{act_response} [SEP] {gen_response}\")\n",
    "    label_qr = nli_result_qr[0]['label'].lower()\n",
    "    print(f\"Actual Response Premise: {act_response}\")\n",
    "    print(f\"Generated Response Hypothesis: {gen_response}\")\n",
    "    print(f\"NLI Result for (act_response, gen_response): {nli_result_qr}\")\n",
    "    is_act_entails_response = label_qr == 'entailment'\n",
    "\n",
    "    # Assign the Coh-Con.Score based on the entailment results\n",
    "    if is_persona_entails_response and is_act_entails_response:\n",
    "        score = 2\n",
    "    elif is_persona_entails_response:\n",
    "        score = 1\n",
    "    else:\n",
    "        score = 0\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona Premise: I am a software engineer. I love coding in Python. I also enjoy hiking during weekends.\n",
      "Generated Response Hypothesis: On weekends, I often go hiking, and Python coding is something I really enjoy.\n",
      "NLI Result for (P, gen_response): [{'label': 'entailment', 'score': 0.9853878617286682}]\n",
      "Actual Response Premise: Coding in Python is one of my favorite activities. On weekends, I often go hiking.\n",
      "Generated Response Hypothesis: On weekends, I often go hiking, and Python coding is something I really enjoy.\n",
      "NLI Result for (act_response, gen_response): [{'label': 'entailment', 'score': 0.9843922853469849}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_coh_con_score(response_text, gen_response_text, persona_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the fine-tuned BERT on SNLI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels of the SNLI dataset:\n",
    "\n",
    "- 0: entailment\n",
    "- 1: neutral\n",
    "- 2: contradiction\n",
    "\n",
    "\n",
    "UE-score:\n",
    "\n",
    "- 2: R is aligned with P and Q\n",
    "- 1: R is alinged with P\n",
    "- 0: no alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load the model and tokenizer (assuming the model is already fine-tuned on SNLI)\n",
    "model_dir = \"Fine-tuning/output/bert_snli\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initialize the NLI pipeline\n",
    "bert_on_snli = pipeline('text-classification', model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "def calculate_ue_score(act_response, gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the UE score based on entailment between persona, actual response, and generated response.\n",
    "\n",
    "    Returns:\n",
    "    int: UE score with possible values 2, 1, or 0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping to interpret the NLI model's output\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'entailment',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'contradiction'\n",
    "    }\n",
    "    \n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_snli(f\"{persona} [SEP] {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Check entailment between actual response (Q) and generated response (R)\n",
    "    result_qr = bert_on_snli(f\"{act_response} [SEP] {gen_response}\")\n",
    "    label_qr = label_mapping.get(result_qr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine UE score based on entailment results\n",
    "    if label_pr == 'entailment' and label_qr == 'entailment':\n",
    "        return 2\n",
    "    elif label_pr == 'entailment':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual response\n",
    "act_response = \"Coding in Python is one of my favorite activities. On weekends, I often go hiking.\"\n",
    "\n",
    "# Generated response\n",
    "gen_response_text = \"On weekends, I often go hiking, and Python coding is something I really enjoy.\"\n",
    "\n",
    "persona_text = \"I am a software engineer. I love coding in Python. I also enjoy hiking during weekends.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_ue_score(act_response, gen_response_text, persona_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the fine-tuned BERT on DNLI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels of the DNLI dataset:\n",
    "\n",
    "- 0: negative\n",
    "- 1: neutral\n",
    "- 2: positive\n",
    "\n",
    "C-score:\n",
    "\n",
    "- 1: R,P entailment\n",
    "- 0: R,P neutral\n",
    "- -1: R,P contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load the model and tokenizer (assuming the model is already fine-tuned on DNLI)\n",
    "model_dir = \"Fine-tuning/output/bert_dnli\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# Initialize the NLI pipeline\n",
    "bert_on_dnli = pipeline('text-classification', model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "def calculate_c_score(gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the C score based on the entailment results between a generated response (R)\n",
    "    and a given persona (P).\n",
    "\n",
    "    Returns:\n",
    "    int: C-score with possible values:\n",
    "         1 for entailment (positive),\n",
    "         0 for neutral,\n",
    "         -1 for contradiction (negative).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping to interpret the NLI model's output\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "    \n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_dnli(f\"{persona} {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine C score based on entailment results\n",
    "    if label_pr == 'positive':\n",
    "        return 1\n",
    "    elif label_pr == 'neutral':\n",
    "        return 0\n",
    "    elif label_pr == 'negative':\n",
    "        return -1\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected label encountered: {label_pr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated response\n",
    "gen_response_text = \"On weekends, I often go hiking, and Python coding is something I really enjoy.\"\n",
    "\n",
    "persona_text = \"I am a software engineer. I love coding in Python. I also enjoy hiking during weekends.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_c_score(gen_response_text, persona_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persoagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

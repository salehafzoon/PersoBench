{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bert_score openpyxl gensim requests nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = \"FoCus\"                                   # Synthetic-PersonaChat, Blended Skill Talk, PEC, ConvAI2, FoCus, IT-ConvAI2\n",
    "LLM_name = \"Llama3-1-8B-Instruct\"                         # Mistral-7B-Instruct, Llama3-1-8B-Instruct, Qwen2-7B-Instruct,  Gemma-7B-Instruct, gpt-3.5-turbo, gpt-4-turbo, gpt-4o-mini, gemini-1.5-pro\n",
    "COT_SETUP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: Sure, you will like to know that this p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>User2: Technische Universität Darmstadt in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>User2: I suggest a place, for your wish of see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: The history of the house you are intere...  \n",
       "1  User2: This house was use as a stop for slaves...  \n",
       "2  User2: Sure, you will like to know that this p...  \n",
       "3  User2: Technische Universität Darmstadt in the...  \n",
       "4  User2: I suggest a place, for your wish of see...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'./Prompts/{Dataset}.csv')\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FoCus'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas        0\n",
      "context         0\n",
      "act_response    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>The history of the house you are interested in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>This house was use as a stop for slaves trying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>Sure, you will like to know that this place wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>Technische Universität Darmstadt in the top 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>I suggest a place, for your wish of see librar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I would like to go to University.I live in Mic...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>They offer 132 bachelors degree programs and 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "5  I would like to go to University.I live in Mic...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "5  User1: I think Ive been there before but I don...   \n",
       "\n",
       "                                        act_response  \n",
       "0  The history of the house you are interested in...  \n",
       "1  This house was use as a stop for slaves trying...  \n",
       "2  Sure, you will like to know that this place wa...  \n",
       "3  Technische Universität Darmstadt in the top 25...  \n",
       "4  I suggest a place, for your wish of see librar...  \n",
       "5  They offer 132 bachelors degree programs and 1...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Only For: FoCus, IT-ConvAI2\n",
    "if Dataset == \"FoCus\" or Dataset == \"IT-ConvAI2\":\n",
    "    df['act_response'] = df['act_response'].apply(lambda x: x.split(':', 1)[1].strip() if ':' in x else x.strip())\n",
    "\n",
    "# ### Only For: Blended Skill Talk\n",
    "if Dataset == \"Blended Skill Talk\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[User 1 persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "# ### Only For: PEC\n",
    "if Dataset == \"PEC\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[Responder persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 2)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     50\n",
      "response_time     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nazareth House is a truly remarkable place, an...</td>\n",
       "      <td>8.849191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm glad you're interested in historic houses!...</td>\n",
       "      <td>8.896329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Marion Palace Theatre's architecture is a ...</td>\n",
       "      <td>8.867732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technische Universität Darmstadt is a great ch...</td>\n",
       "      <td>9.021704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.908265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think you're referring to the museum come ph...</td>\n",
       "      <td>8.841254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>It's great to know that Mahasthangarh has such...</td>\n",
       "      <td>8.828058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Armagh County Museum is a must-visit destinati...</td>\n",
       "      <td>8.916159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The Nyanga National Park is a great destinatio...</td>\n",
       "      <td>8.955311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>You can definitely visit the wall today! Since...</td>\n",
       "      <td>9.073043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          gen_response  response_time\n",
       "0    Nazareth House is a truly remarkable place, an...       8.849191\n",
       "1    I'm glad you're interested in historic houses!...       8.896329\n",
       "2    The Marion Palace Theatre's architecture is a ...       8.867732\n",
       "3    Technische Universität Darmstadt is a great ch...       9.021704\n",
       "4                                                  NaN       8.908265\n",
       "..                                                 ...            ...\n",
       "995  I think you're referring to the museum come ph...       8.841254\n",
       "996  It's great to know that Mahasthangarh has such...       8.828058\n",
       "997  Armagh County Museum is a must-visit destinati...       8.916159\n",
       "998  The Nyanga National Park is a great destinatio...       8.955311\n",
       "999  You can definitely visit the wall today! Since...       9.073043\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COT_ = \"-COT\" if COT_SETUP else \"\"\n",
    " \n",
    "response = pd.read_csv(f'Responses/{Dataset}/{LLM_name}{COT_}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 116\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas          0\n",
      "act_response      0\n",
      "gen_response     50\n",
      "response_time     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>act_response</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>The history of the house you are interested in...</td>\n",
       "      <td>Nazareth House is a truly remarkable place, an...</td>\n",
       "      <td>8.849191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>This house was use as a stop for slaves trying...</td>\n",
       "      <td>I'm glad you're interested in historic houses!...</td>\n",
       "      <td>8.896329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>Sure, you will like to know that this place wa...</td>\n",
       "      <td>The Marion Palace Theatre's architecture is a ...</td>\n",
       "      <td>8.867732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>Technische Universität Darmstadt in the top 25...</td>\n",
       "      <td>Technische Universität Darmstadt is a great ch...</td>\n",
       "      <td>9.021704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>I suggest a place, for your wish of see librar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.908265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  The history of the house you are interested in...   \n",
       "1  This house was use as a stop for slaves trying...   \n",
       "2  Sure, you will like to know that this place wa...   \n",
       "3  Technische Universität Darmstadt in the top 25...   \n",
       "4  I suggest a place, for your wish of see librar...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  Nazareth House is a truly remarkable place, an...       8.849191  \n",
       "1  I'm glad you're interested in historic houses!...       8.896329  \n",
       "2  The Marion Palace Theatre's architecture is a ...       8.867732  \n",
       "3  Technische Universität Darmstadt is a great ch...       9.021704  \n",
       "4                                                NaN       8.908265  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'act_response': df['act_response'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU\n",
    "# device = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge import Rouge\n",
    "import bert_score\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "rouge = Rouge()\n",
    "\n",
    "# Lists to store the metrics\n",
    "bleu_scores = []\n",
    "rouge_scores = []\n",
    "meteor_scores = []\n",
    "bertscore_prec = []\n",
    "bertscore_rec = []\n",
    "bertscore_f1 = []\n",
    "distinct_1 = []\n",
    "distinct_2 = []\n",
    "ue_scores = []\n",
    "c_scores = []\n",
    "consistency_scores = []\n",
    "idf_scores = []\n",
    "persona_distance_scores = []\n",
    "\n",
    "\n",
    "bert_snli_dir = \"Fine-tuning/output/bert_snli\"\n",
    "bert_snli_model = BertForSequenceClassification.from_pretrained(bert_snli_dir)\n",
    "bert_snli_tokenizer = BertTokenizer.from_pretrained(bert_snli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline for UE Score\n",
    "bert_on_snli = pipeline('text-classification', model = bert_snli_model, tokenizer = bert_snli_tokenizer, device=0)\n",
    "\n",
    "bert_dnli_dir = \"Fine-tuning/output/bert_dnli\"\n",
    "bert_dnli_model = BertForSequenceClassification.from_pretrained(bert_dnli_dir)\n",
    "bert_dnli_tokenizer = BertTokenizer.from_pretrained(bert_dnli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline\n",
    "bert_on_dnli = pipeline('text-classification', model = bert_dnli_model, tokenizer = bert_dnli_tokenizer, device=0)\n",
    "\n",
    "\n",
    "# Initialize the Word2Vec Model\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"./GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Initialize smoothing function\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "# Helper functions\n",
    "def compute_bleu(reference, hypothesis):\n",
    "    reference = [str(reference).replace('\\n', ' ').split()]\n",
    "    hypothesis = str(hypothesis).replace('\\n', ' ').split()\n",
    "    return sentence_bleu(reference, hypothesis, smoothing_function=smoothing_function)\n",
    "\n",
    "def compute_rouge(reference, hypothesis):\n",
    "    scores = rouge.get_scores(str(hypothesis).replace('\\n', ' '), str(reference).replace('\\n', ' '), avg=True)\n",
    "    return scores['rouge-1']['f'], scores['rouge-2']['f'], scores['rouge-l']['f']\n",
    "\n",
    "def compute_meteor(reference, hypothesis):\n",
    "    reference = [str(reference).replace('\\n', ' ').split()]\n",
    "    hypothesis = str(hypothesis).replace('\\n', ' ').split()\n",
    "    return meteor_score(reference, hypothesis)\n",
    "\n",
    "def compute_distinct_ngrams(text, n):\n",
    "    tokens = str(text).replace('\\n', ' ').split()\n",
    "    ngrams = list(zip(*[tokens[i:] for i in range(n)]))\n",
    "    distinct_ngrams = len(set(ngrams))\n",
    "    total_ngrams = len(ngrams)\n",
    "    return distinct_ngrams / total_ngrams if total_ngrams > 0 else 0\n",
    "\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "def calculate_c_score(gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the C score based on the entailment results between a generated response (R)\n",
    "    and a given persona (P).\n",
    "\n",
    "    Returns:\n",
    "    int: C-score with possible values:\n",
    "         1 for entailment (positive),\n",
    "         0 for neutral,\n",
    "         -1 for contradiction (negative).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping to interpret the NLI model's output\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "    \n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_dnli(f\"{persona} {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine C score based on entailment results\n",
    "    if label_pr == 'positive':\n",
    "        return 1\n",
    "    elif label_pr == 'neutral':\n",
    "        return 0\n",
    "    elif label_pr == 'negative':\n",
    "        return -1\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected label encountered: {label_pr}\")\n",
    "\n",
    "\n",
    "def calculate_consistency_score(gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the Consistency Score based on the binary entailment results \n",
    "    between a generated response (R) and a given persona (P).\n",
    "\n",
    "    Returns:\n",
    "    int: Consistency Score with binary values:\n",
    "         1 for entailment or neutral,\n",
    "         0 for contradiction.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping for binary classification\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "\n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_dnli(f\"{persona} {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine Consistency Score based on binary entailment results\n",
    "    if label_pr in ['positive', 'neutral']:\n",
    "        return 1\n",
    "    elif label_pr == 'negative':\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected label encountered: {label_pr}\")\n",
    "\n",
    "\n",
    "def calculate_ue_score(act_response, gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the UE score based on entailment between persona, actual response, and generated response.\n",
    "\n",
    "    Returns:\n",
    "    int: UE score with possible values 2, 1, or 0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping to interpret the NLI model's output\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'entailment',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'contradiction'\n",
    "    }\n",
    "    \n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_snli(f\"{persona} [SEP] {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Check entailment between actual response (Q) and generated response (R)\n",
    "    result_qr = bert_on_snli(f\"{act_response} [SEP] {gen_response}\")\n",
    "    label_qr = label_mapping.get(result_qr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine UE score based on entailment results\n",
    "    if label_pr == 'entailment' and label_qr == 'entailment':\n",
    "        return 2\n",
    "    elif label_pr == 'entailment':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def calculate_idf_weighted_overlap(persona, response):\n",
    "    # Fit TF-IDF on both texts and calculate cosine similarity\n",
    "\n",
    "    processed_persona = preprocess_text(persona)\n",
    "    processed_response = preprocess_text(response)\n",
    "    persona_new = str(processed_persona) if not isinstance(processed_persona, str) else processed_persona\n",
    "    response_new = str(processed_response) if not isinstance(processed_response, str) else processed_response\n",
    "    texts = [persona_new, response_new]\n",
    "\n",
    "    # texts = [persona, response]\n",
    "    \n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "\n",
    "def compute_persona_distance(persona, response, model, stop_words):\n",
    "    # Tokenize and filter stopwords\n",
    "    persona_tokens = [word for word in persona.lower().split() if word not in stop_words]\n",
    "    response_tokens = [word for word in response.lower().split() if word not in stop_words]\n",
    "    \n",
    "    # Get word vectors\n",
    "    persona_vecs = [model[word] for word in persona_tokens if word in model]\n",
    "    response_vecs = [model[word] for word in response_tokens if word in model]\n",
    "    \n",
    "    # If no vectors found, return zero similarity\n",
    "    if not persona_vecs or not response_vecs:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute average vectors\n",
    "    persona_avg_vec = np.mean(persona_vecs, axis=0)\n",
    "    response_avg_vec = np.mean(response_vecs, axis=0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return cosine_similarity([persona_avg_vec], [response_avg_vec])[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level to ERROR to suppress warnings about training\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Default worst-case values\n",
    "worst_bleu = 0.0\n",
    "worst_rouge = (0.0, 0.0, 0.0)\n",
    "worst_meteor = 0.0\n",
    "worst_bertscore = (0.0, 0.0, 0.0)\n",
    "worst_distinct = 0.0\n",
    "worst_c_score = -1.0\n",
    "worst_consistency_score = 0.0\n",
    "worst_idf_score = 0.0\n",
    "worst_ue_score = 0.0\n",
    "worst_persona_distance_score = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [18:03<00:00,  1.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>BERTScore_Rec</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "      <th>Dist1</th>\n",
       "      <th>Dist2</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.816107</td>\n",
       "      <td>0.831056</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.562215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837872</td>\n",
       "      <td>0.889504</td>\n",
       "      <td>0.862917</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.743971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.841942</td>\n",
       "      <td>0.870469</td>\n",
       "      <td>0.855968</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.847506</td>\n",
       "      <td>0.925325</td>\n",
       "      <td>0.884708</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.601566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.836625</td>\n",
       "      <td>0.870675</td>\n",
       "      <td>0.853311</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.826543</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.831214</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.829818</td>\n",
       "      <td>0.911610</td>\n",
       "      <td>0.868793</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.644514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.831442</td>\n",
       "      <td>0.945189</td>\n",
       "      <td>0.884674</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.671408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.855791</td>\n",
       "      <td>0.855816</td>\n",
       "      <td>0.855804</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BERTScore_Prec  BERTScore_Rec  BERTScore_F1     Dist1     Dist2  C Score  \\\n",
       "0          0.846562       0.816107      0.831056  0.702128  0.956989      1.0   \n",
       "1          0.837872       0.889504      0.862917  0.881356  1.000000      1.0   \n",
       "2          0.841942       0.870469      0.855968  0.829268  1.000000      1.0   \n",
       "3          0.847506       0.925325      0.884708  0.864198  1.000000      1.0   \n",
       "4          0.836625       0.870675      0.853311  0.830986  1.000000      1.0   \n",
       "..              ...            ...           ...       ...       ...      ...   \n",
       "995        0.826543       0.835938      0.831214  0.918033  1.000000      0.0   \n",
       "996        0.829818       0.911610      0.868793  0.921875  1.000000      0.0   \n",
       "997        0.831442       0.945189      0.884674  0.859375  1.000000      1.0   \n",
       "998        0.855791       0.855816      0.855804  0.896552  1.000000      0.0   \n",
       "999        0.000000       0.000000      0.000000  0.000000  0.000000     -1.0   \n",
       "\n",
       "     UE Score  Persona Distance  \n",
       "0         2.0          0.562215  \n",
       "1         0.0          0.743971  \n",
       "2         0.0          0.760262  \n",
       "3         0.0          0.601566  \n",
       "4         0.0          0.662243  \n",
       "..        ...               ...  \n",
       "995       0.0          0.619469  \n",
       "996       0.0          0.644514  \n",
       "997       1.0          0.671408  \n",
       "998       0.0          0.536340  \n",
       "999       0.0          0.000000  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a counter for invalid gen_response\n",
    "invalid_gen_res_count = 0\n",
    "\n",
    "# Iterate over each row\n",
    "for index, row in tqdm(eval_df.iterrows(), total=len(eval_df)):\n",
    "    personas = row['personas']\n",
    "    act_response = row['act_response']\n",
    "    gen_response = row['gen_response']\n",
    "\n",
    "    # Check for NaN or None in gen_response\n",
    "    if pd.isna(gen_response):\n",
    "        invalid_gen_res_count += 1\n",
    "        \n",
    "        # bleu_scores.append(worst_bleu)\n",
    "        # rouge_scores.append(worst_rouge)\n",
    "        # meteor_scores.append(worst_meteor)\n",
    "        bertscore_prec.append(worst_bertscore[0])\n",
    "        bertscore_rec.append(worst_bertscore[1])\n",
    "        bertscore_f1.append(worst_bertscore[2])\n",
    "        distinct_1.append(worst_distinct)\n",
    "        distinct_2.append(worst_distinct)\n",
    "        c_scores.append(worst_c_score)\n",
    "        # consistency_scores.append(worst_consistency_score)\n",
    "        # idf_scores.append(worst_idf_score)\n",
    "        persona_distance_scores.append(worst_persona_distance_score)\n",
    "        ue_scores.append(worst_ue_score)\n",
    "\n",
    "        continue\n",
    "\n",
    "    # bleu = compute_bleu(act_response, gen_response)\n",
    "    # bleu_scores.append(bleu)\n",
    "    \n",
    "    # rouge_1, rouge_2, rouge_l = compute_rouge(act_response, gen_response)\n",
    "    # rouge_scores.append((rouge_1, rouge_2, rouge_l))\n",
    "    \n",
    "    # meteor = compute_meteor(act_response, gen_response)\n",
    "    # meteor_scores.append(meteor)\n",
    "    \n",
    "    P, R, F1 = bert_score.score([gen_response], [act_response], lang=\"en\", verbose=False)\n",
    "    bertscore_prec.append(P.mean().item())\n",
    "    bertscore_rec.append(R.mean().item())\n",
    "    bertscore_f1.append(F1.mean().item())\n",
    "    \n",
    "    distinct_1.append(compute_distinct_ngrams(gen_response, 1))\n",
    "    \n",
    "    distinct_2.append(compute_distinct_ngrams(gen_response, 2))\n",
    "    \n",
    "    c_scores.append(calculate_c_score(personas, gen_response))\n",
    "    \n",
    "    # consistency_scores.append(calculate_consistency_score(personas, gen_response))\n",
    "    \n",
    "    ue_scores.append(calculate_ue_score(act_response, gen_response, personas))\n",
    "\n",
    "    # idf_scores.append(calculate_idf_weighted_overlap(personas, gen_response))\n",
    "    \n",
    "    persona_distance = compute_persona_distance(personas, gen_response, word2vec_model, stop_words)\n",
    "    persona_distance_scores.append(persona_distance)\n",
    "\n",
    "\n",
    "# Compile metrics into DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    # 'BLEU': bleu_scores,\n",
    "    # 'R1': [score[0] for score in rouge_scores],\n",
    "    # 'R2': [score[1] for score in rouge_scores],\n",
    "    # 'RL': [score[2] for score in rouge_scores],\n",
    "    # 'METEOR': meteor_scores,\n",
    "    'BERTScore_Prec': bertscore_prec,\n",
    "    'BERTScore_Rec': bertscore_rec,\n",
    "    'BERTScore_F1': bertscore_f1,\n",
    "    'Dist1': distinct_1,\n",
    "    'Dist2': distinct_2,\n",
    "    'C Score': c_scores,\n",
    "    # 'P Consistency Score': consistency_scores,\n",
    "    # 'IDF Overlap': idf_scores,\n",
    "    'UE Score': ue_scores,\n",
    "    'Persona Distance': persona_distance_scores\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'response_time' column to 'metrics_df'\n",
    "metrics_df['response_time'] = eval_df['response_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>BERTScore_Rec</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "      <th>Dist1</th>\n",
       "      <th>Dist2</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>0.7 ± 0.32</td>\n",
       "      <td>0.73 ± 0.34</td>\n",
       "      <td>0.71 ± 0.33</td>\n",
       "      <td>0.71 ± 0.33</td>\n",
       "      <td>0.82 ± 0.38</td>\n",
       "      <td>0.15 ± 0.79</td>\n",
       "      <td>0.32 ± 0.67</td>\n",
       "      <td>0.48 ± 0.24</td>\n",
       "      <td>4.75 ± 3.43</td>\n",
       "      <td>0.173 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model BERTScore_Prec BERTScore_Rec BERTScore_F1        Dist1  \\\n",
       "0  gemini-1.5-pro     0.7 ± 0.32   0.73 ± 0.34  0.71 ± 0.33  0.71 ± 0.33   \n",
       "\n",
       "         Dist2      C Score     UE Score Persona Distance response_time  \\\n",
       "0  0.82 ± 0.38  0.15 ± 0.79  0.32 ± 0.67      0.48 ± 0.24   4.75 ± 3.43   \n",
       "\n",
       "  Failure Ratio  \n",
       "0  0.173 ± 0.00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean (average) and standard deviation, rounded to 2 decimal places\n",
    "avg_values = metrics_df.mean().round(2)\n",
    "std_values = metrics_df.std(ddof=0).round(2)  # Use ddof=0 for population standard deviation\n",
    "\n",
    "# Combine the average and standard deviation into the format \"avg ± std\"\n",
    "combined_values = avg_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "\n",
    "# Insert the LLM name at the beginning of the combined values\n",
    "combined_values = combined_values.tolist()\n",
    "combined_values.insert(0, LLM_name)\n",
    "\n",
    "# Create a DataFrame for the combined average ± std row\n",
    "result_df = pd.DataFrame([combined_values], columns=['Model'] + metrics_df.columns.tolist())\n",
    "\n",
    "# Add the ratio of invalid gen_response\n",
    "invalid_gen_res_ratio = invalid_gen_res_count / len(eval_df)\n",
    "result_df['Failure Ratio'] = f\"{round(invalid_gen_res_ratio, 3)} ± 0.00\"  # No std for Failure Ratio\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing Excel file and update or append the average row\n",
    "output_path = f'./Evaluations/{Dataset}{COT_}-results.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing data\n",
    "    existing_df = pd.read_excel(output_path)\n",
    "    # Check if the model name already exists\n",
    "    if LLM_name in existing_df['Model'].values:\n",
    "        # Update the row with the same model name\n",
    "        existing_df.loc[existing_df['Model'] == LLM_name, :] = result_df.values\n",
    "    else:\n",
    "        # Append the new data\n",
    "        existing_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new DataFrame\n",
    "    existing_df = result_df\n",
    "\n",
    "# Save the updated DataFrame to an Excel file\n",
    "existing_df.to_excel(output_path, index=False)\n",
    "\n",
    "existing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>...</th>\n",
       "      <th>IDF Overlap</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>0.84 ± 0.37</td>\n",
       "      <td>-0.05 ± 0.53</td>\n",
       "      <td>0.50 ± 0.82</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.11 ± 0.07</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.1 ± 0.07</td>\n",
       "      <td>0.12 ± 0.08</td>\n",
       "      <td>0.84 ± 0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.07</td>\n",
       "      <td>0.47 ± 0.13</td>\n",
       "      <td>5.15 ± 1.13</td>\n",
       "      <td>0.001 ± 0.00</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>0.98 ± 0.09</td>\n",
       "      <td>2.54 ± 0.79</td>\n",
       "      <td>0.55 ± 0.4</td>\n",
       "      <td>0.95 ± 0.03</td>\n",
       "      <td>1.2 ± 0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistral-7B-Instruct</td>\n",
       "      <td>0.78 ± 0.41</td>\n",
       "      <td>-0.08 ± 0.59</td>\n",
       "      <td>0.44 ± 0.79</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.1 ± 0.07</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.09 ± 0.07</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.8 ± 0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.07</td>\n",
       "      <td>0.43 ± 0.17</td>\n",
       "      <td>6.71 ± 1.85</td>\n",
       "      <td>0.046 ± 0.00</td>\n",
       "      <td>0.9 ± 0.2</td>\n",
       "      <td>0.94 ± 0.22</td>\n",
       "      <td>2.54 ± 1.28</td>\n",
       "      <td>0.39 ± 0.43</td>\n",
       "      <td>0.9 ± 0.2</td>\n",
       "      <td>1.13 ± 0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama3-1-8B-Instruct</td>\n",
       "      <td>0.83 ± 0.37</td>\n",
       "      <td>-0.05 ± 0.53</td>\n",
       "      <td>0.37 ± 0.73\\t</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.1 ± 0.07</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.85 ± 0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.08</td>\n",
       "      <td>0.46 ± 0.14</td>\n",
       "      <td>8.69 ± 0.15</td>\n",
       "      <td>0.0 ± 0.00</td>\n",
       "      <td>0.95 ± 0.02</td>\n",
       "      <td>0.94 ± 0.19</td>\n",
       "      <td>2.01 ± 0.94</td>\n",
       "      <td>0.49 ± 0.44</td>\n",
       "      <td>0.95 ± 0.01</td>\n",
       "      <td>1.07 ± 0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.83 ± 0.38</td>\n",
       "      <td>0.02 ± 0.6</td>\n",
       "      <td>0.57 ± 0.86</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.11 ± 0.07</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.1 ± 0.06</td>\n",
       "      <td>0.12 ± 0.08</td>\n",
       "      <td>0.82 ± 0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.09</td>\n",
       "      <td>0.48 ± 0.16</td>\n",
       "      <td>1.56 ± 0.47</td>\n",
       "      <td>0.023 ± 0.00</td>\n",
       "      <td>0.92 ± 0.15</td>\n",
       "      <td>0.96 ± 0.16</td>\n",
       "      <td>2.81 ± 0.98</td>\n",
       "      <td>0.54 ± 0.44</td>\n",
       "      <td>0.93 ± 0.14</td>\n",
       "      <td>1.23 ± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.84 ± 0.37</td>\n",
       "      <td>-0.05 ± 0.52</td>\n",
       "      <td>0.39 ± 0.76</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.12 ± 0.07</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.11 ± 0.06</td>\n",
       "      <td>0.14 ± 0.08</td>\n",
       "      <td>0.84 ± 0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.06</td>\n",
       "      <td>0.5 ± 0.13</td>\n",
       "      <td>1.63 ± 0.42</td>\n",
       "      <td>0.0 ± 0.00</td>\n",
       "      <td>0.95 ± 0.02</td>\n",
       "      <td>0.99 ± 0.03</td>\n",
       "      <td>3.23 ± 0.89</td>\n",
       "      <td>0.72 ± 0.35</td>\n",
       "      <td>0.95 ± 0.02</td>\n",
       "      <td>1.37 ± 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.84 ± 0.36</td>\n",
       "      <td>0.01 ± 0.57\\t</td>\n",
       "      <td>0.52 ± 0.84</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.06</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.09 ± 0.06</td>\n",
       "      <td>0.11 ± 0.07</td>\n",
       "      <td>0.83 ± 0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.06</td>\n",
       "      <td>0.49 ± 0.13</td>\n",
       "      <td>4.8 ± 0.88</td>\n",
       "      <td>0.003 ± 0.00</td>\n",
       "      <td>0.93 ± 0.07</td>\n",
       "      <td>0.97 ± 0.13</td>\n",
       "      <td>3.14 ± 1.17</td>\n",
       "      <td>0.72 ± 0.37</td>\n",
       "      <td>0.94 ± 0.06</td>\n",
       "      <td>1.34 ± 0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gemma-7B-Instruct</td>\n",
       "      <td>0.77 ± 0.42</td>\n",
       "      <td>-0.03 ± 0.65</td>\n",
       "      <td>0.35 ± 0.71</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.12 ± 0.08</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.11 ± 0.07</td>\n",
       "      <td>0.12 ± 0.09</td>\n",
       "      <td>0.78 ± 0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.12</td>\n",
       "      <td>0.46 ± 0.19</td>\n",
       "      <td>7.47 ± 1.25</td>\n",
       "      <td>0.078 ± 0.00</td>\n",
       "      <td>0.87 ± 0.26</td>\n",
       "      <td>0.91 ± 0.28</td>\n",
       "      <td>2.91 ± 1.36</td>\n",
       "      <td>0.47 ± 0.45</td>\n",
       "      <td>0.87 ± 0.26</td>\n",
       "      <td>1.2 ± 0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1 ± 0.55</td>\n",
       "      <td>0.44 ± 0.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.82 ± 0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.48 ± 0.14</td>\n",
       "      <td>5.21 ± 5.4</td>\n",
       "      <td>0.015 ± 0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model P Consistency Score        C Score       UE Score  \\\n",
       "0           gpt-4-turbo         0.84 ± 0.37   -0.05 ± 0.53    0.50 ± 0.82   \n",
       "1   Mistral-7B-Instruct         0.78 ± 0.41   -0.08 ± 0.59    0.44 ± 0.79   \n",
       "2  Llama3-1-8B-Instruct         0.83 ± 0.37   -0.05 ± 0.53  0.37 ± 0.73\\t   \n",
       "3         gpt-3.5-turbo         0.83 ± 0.38     0.02 ± 0.6    0.57 ± 0.86   \n",
       "4           gpt-4o-mini         0.84 ± 0.37   -0.05 ± 0.52    0.39 ± 0.76   \n",
       "5     Qwen2-7B-Instruct         0.84 ± 0.36  0.01 ± 0.57\\t    0.52 ± 0.84   \n",
       "6     Gemma-7B-Instruct         0.77 ± 0.42   -0.03 ± 0.65    0.35 ± 0.71   \n",
       "7        gemini-1.5-pro                 NaN    -0.1 ± 0.55    0.44 ± 0.79   \n",
       "\n",
       "          BLEU           R1           R2           RL       METEOR  \\\n",
       "0  0.01 ± 0.01  0.11 ± 0.07  0.01 ± 0.03   0.1 ± 0.07  0.12 ± 0.08   \n",
       "1  0.01 ± 0.01   0.1 ± 0.07  0.01 ± 0.02  0.09 ± 0.07  0.11 ± 0.08   \n",
       "2  0.01 ± 0.01  0.11 ± 0.08  0.01 ± 0.03   0.1 ± 0.07  0.11 ± 0.08   \n",
       "3  0.01 ± 0.01  0.11 ± 0.07  0.01 ± 0.03   0.1 ± 0.06  0.12 ± 0.08   \n",
       "4  0.01 ± 0.01  0.12 ± 0.07  0.01 ± 0.03  0.11 ± 0.06  0.14 ± 0.08   \n",
       "5  0.01 ± 0.01  0.09 ± 0.06  0.01 ± 0.02  0.09 ± 0.06  0.11 ± 0.07   \n",
       "6  0.01 ± 0.01  0.12 ± 0.08  0.01 ± 0.03  0.11 ± 0.07  0.12 ± 0.09   \n",
       "7          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "  BERTScore_Prec  ...  IDF Overlap Persona Distance response_time  \\\n",
       "0    0.84 ± 0.03  ...  0.06 ± 0.07      0.47 ± 0.13   5.15 ± 1.13   \n",
       "1     0.8 ± 0.18  ...  0.05 ± 0.07      0.43 ± 0.17   6.71 ± 1.85   \n",
       "2    0.85 ± 0.02  ...  0.06 ± 0.08      0.46 ± 0.14   8.69 ± 0.15   \n",
       "3    0.82 ± 0.13  ...  0.07 ± 0.09      0.48 ± 0.16   1.56 ± 0.47   \n",
       "4    0.84 ± 0.02  ...  0.06 ± 0.06       0.5 ± 0.13   1.63 ± 0.42   \n",
       "5    0.83 ± 0.05  ...  0.06 ± 0.06      0.49 ± 0.13    4.8 ± 0.88   \n",
       "6    0.78 ± 0.23  ...  0.08 ± 0.12      0.46 ± 0.19   7.47 ± 1.25   \n",
       "7     0.82 ± 0.1  ...          NaN      0.48 ± 0.14    5.21 ± 5.4   \n",
       "\n",
       "  Failure Ratio UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  0.001 ± 0.00         0.96 ± 0.03       0.98 ± 0.09          2.54 ± 0.79   \n",
       "1  0.046 ± 0.00           0.9 ± 0.2       0.94 ± 0.22          2.54 ± 1.28   \n",
       "2    0.0 ± 0.00         0.95 ± 0.02       0.94 ± 0.19          2.01 ± 0.94   \n",
       "3  0.023 ± 0.00         0.92 ± 0.15       0.96 ± 0.16          2.81 ± 0.98   \n",
       "4    0.0 ± 0.00         0.95 ± 0.02       0.99 ± 0.03          3.23 ± 0.89   \n",
       "5  0.003 ± 0.00         0.93 ± 0.07       0.97 ± 0.13          3.14 ± 1.17   \n",
       "6  0.078 ± 0.00         0.87 ± 0.26       0.91 ± 0.28          2.91 ± 1.36   \n",
       "7  0.015 ± 0.00                 NaN               NaN                  NaN   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0           0.55 ± 0.4               0.95 ± 0.03      1.2 ± 0.19  \n",
       "1          0.39 ± 0.43                 0.9 ± 0.2     1.13 ± 0.35  \n",
       "2          0.49 ± 0.44               0.95 ± 0.01     1.07 ± 0.21  \n",
       "3          0.54 ± 0.44               0.93 ± 0.14     1.23 ± 0.28  \n",
       "4          0.72 ± 0.35               0.95 ± 0.02      1.37 ± 0.2  \n",
       "5          0.72 ± 0.37               0.94 ± 0.06     1.34 ± 0.25  \n",
       "6          0.47 ± 0.45               0.87 ± 0.26      1.2 ± 0.42  \n",
       "7                  NaN                       NaN             NaN  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_excel(f'./Evaluations/{Dataset}{COT_}-results.xlsx')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "prompt = pd.read_csv(f'./Prompts/FoCus.csv')\n",
    "print(\"Shape:\", prompt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2-7B Average Response Length (in words): 56.68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "      <td>Nazareth House is a historic place located on ...</td>\n",
       "      <td>3.733489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.197150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: Sure, you will like to know that this p...</td>\n",
       "      <td>The Marion Palace Theatre is a stunning exampl...</td>\n",
       "      <td>2.774832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>User2: Technische Universität Darmstadt in the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.265017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>User2: I suggest a place, for your wish of see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.194262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  User2: The history of the house you are intere...   \n",
       "1  User2: This house was use as a stop for slaves...   \n",
       "2  User2: Sure, you will like to know that this p...   \n",
       "3  User2: Technische Universität Darmstadt in the...   \n",
       "4  User2: I suggest a place, for your wish of see...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  Nazareth House is a historic place located on ...       3.733489  \n",
       "1                                                NaN       4.197150  \n",
       "2  The Marion Palace Theatre is a stunning exampl...       2.774832  \n",
       "3                                                NaN       4.265017  \n",
       "4                                                NaN       4.194262  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen2_res = pd.read_csv(f'Responses/FoCus/Qwen2-7B-Instruct.csv')\n",
    "print(\"Qwen2-7B Average Response Length (in words):\", round(qwen2_res['gen_response'].str.split().str.len().mean(),2))\n",
    "qwen2_df = pd.concat([prompt, qwen2_res], axis=1)\n",
    "qwen2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini 1.5 Pro Average Response Length (in words): 55.35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "      <td>Nazareth House has a rich history rooted in be...</td>\n",
       "      <td>The user persona indicates a strong interest i...</td>\n",
       "      <td>5.792017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "      <td>It's fascinating to think about what life was ...</td>\n",
       "      <td>The persona indicates an interest in history, ...</td>\n",
       "      <td>5.167329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: Sure, you will like to know that this p...</td>\n",
       "      <td>The Marion Palace Theatre is a stunning exampl...</td>\n",
       "      <td>The user persona expresses interest in Histori...</td>\n",
       "      <td>4.482702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>User2: Technische Universität Darmstadt in the...</td>\n",
       "      <td>Technische Universität Darmstadt consistently ...</td>\n",
       "      <td>The user persona expresses a strong interest i...</td>\n",
       "      <td>5.374144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>User2: I suggest a place, for your wish of see...</td>\n",
       "      <td>Given your interest in libraries and church or...</td>\n",
       "      <td>The user persona expresses interest in England...</td>\n",
       "      <td>4.855018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  User2: The history of the house you are intere...   \n",
       "1  User2: This house was use as a stop for slaves...   \n",
       "2  User2: Sure, you will like to know that this p...   \n",
       "3  User2: Technische Universität Darmstadt in the...   \n",
       "4  User2: I suggest a place, for your wish of see...   \n",
       "\n",
       "                                        gen_response  \\\n",
       "0  Nazareth House has a rich history rooted in be...   \n",
       "1  It's fascinating to think about what life was ...   \n",
       "2  The Marion Palace Theatre is a stunning exampl...   \n",
       "3  Technische Universität Darmstadt consistently ...   \n",
       "4  Given your interest in libraries and church or...   \n",
       "\n",
       "                                           reasoning  response_time  \n",
       "0  The user persona indicates a strong interest i...       5.792017  \n",
       "1  The persona indicates an interest in history, ...       5.167329  \n",
       "2  The user persona expresses interest in Histori...       4.482702  \n",
       "3  The user persona expresses a strong interest i...       5.374144  \n",
       "4  The user persona expresses interest in England...       4.855018  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_res = pd.read_csv(f'Responses/FoCus/gemini-1.5-pro-COT.csv')\n",
    "print(\"Gemini 1.5 Pro Average Response Length (in words):\", round(gemini_res['gen_response'].str.split().str.len().mean(),2))\n",
    "gemini_df = pd.concat([prompt, gemini_res], axis=1)\n",
    "gemini_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3.1-8B Average Response Length (in words): 66.84\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "      <td>Nazareth House is a truly remarkable place, an...</td>\n",
       "      <td>8.849191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "      <td>I'm glad you're interested in historic houses!...</td>\n",
       "      <td>8.896329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: Sure, you will like to know that this p...</td>\n",
       "      <td>The Marion Palace Theatre's architecture is a ...</td>\n",
       "      <td>8.867732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>User2: Technische Universität Darmstadt in the...</td>\n",
       "      <td>Technische Universität Darmstadt is a great ch...</td>\n",
       "      <td>9.021704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>User2: I suggest a place, for your wish of see...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.908265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  User2: The history of the house you are intere...   \n",
       "1  User2: This house was use as a stop for slaves...   \n",
       "2  User2: Sure, you will like to know that this p...   \n",
       "3  User2: Technische Universität Darmstadt in the...   \n",
       "4  User2: I suggest a place, for your wish of see...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  Nazareth House is a truly remarkable place, an...       8.849191  \n",
       "1  I'm glad you're interested in historic houses!...       8.896329  \n",
       "2  The Marion Palace Theatre's architecture is a ...       8.867732  \n",
       "3  Technische Universität Darmstadt is a great ch...       9.021704  \n",
       "4                                                NaN       8.908265  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_res = pd.read_csv(f'Responses/FoCus/Llama3-1-8B-Instruct-COT.csv')\n",
    "print(\"Llama 3.1-8B Average Response Length (in words):\", round(llama3_res['gen_response'].str.split().str.len().mean(),2))\n",
    "llama3_df = pd.concat([prompt, llama3_res], axis=1)\n",
    "llama3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 858  # or any row index you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personas: My father served in the Navy.I live in California.I like basketball.Ive never been on a ship before.I would like to visit Panama.\n",
      "\n",
      "Context: User1: I think Ive been there before but I dont remember the name of this place.\n",
      "User2: This is the USS Midway, which was formerly an aircraft carrier for the United States Navy, the branch of military that your father served in.\n",
      "User1: Where is the ship right now?\n",
      "User2: The ship is moored at her final location as a museum in San Diego, California, your home state!\n",
      "User1: When did it open as a museum?\n",
      "User2: The USS Midway was opened to the public as a museum on June 7th, 2004.\n",
      "User1: When was this ship decommisioned?\n",
      "\n",
      "Actual Response: User2: The USS Midway was decommissioned in a ceremony at Naval Air Station North Island on April 11th, 1992.\n"
     ]
    }
   ],
   "source": [
    "print(\"Personas:\", prompt.iloc[idx]['personas'])\n",
    "print(\"\\nContext:\", prompt.iloc[idx]['context'])\n",
    "print(\"\\nActual Response:\", prompt.iloc[idx]['act_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2 7B:\n",
      "\tResponse Length: 154\n",
      "\tResponse: Wow, it's amazing that the USS Midway is now a museum in San Diego. I'm glad it opened to the public in 2004. I wonder when exactly it was decommissioned?\n"
     ]
    }
   ],
   "source": [
    "print(\"Qwen2 7B:\")\n",
    "print(\"\\tResponse Length:\", len(qwen2_df.iloc[idx]['gen_response']))\n",
    "print(\"\\tResponse:\", qwen2_df.iloc[idx]['gen_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini 1.5 Pro:\n",
      "\tResponse Length: 261\n",
      "\tResponse: The USS Midway was decommissioned on April 11, 1992.  Given your father's Navy background and the fact that you live in California, a visit might be a particularly meaningful experience.  It's a pretty impressive piece of history right there in your home state!\n"
     ]
    }
   ],
   "source": [
    "print(\"Gemini 1.5 Pro:\")\n",
    "print(\"\\tResponse Length:\", len(gemini_df.iloc[idx]['gen_response']))\n",
    "print(\"\\tResponse:\", gemini_df.iloc[idx]['gen_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama3.1 8B:\n",
      "\tResponse Length: 345\n",
      "\tResponse: I think it would be really cool to visit the USS Midway in San Diego, California. It's a great way to learn about naval history and the role of the US Navy. Plus, it's located in my home state, so it's definitely on my bucket list. Who knows, maybe one day I'll even get to visit Panama and see the Panama Canal, which is a major shipping route.\n"
     ]
    }
   ],
   "source": [
    "print(\"Llama3.1 8B:\")\n",
    "print(\"\\tResponse Length:\", len(llama3_df.iloc[idx]['gen_response']))\n",
    "print(\"\\tResponse:\", llama3_df.iloc[idx]['gen_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

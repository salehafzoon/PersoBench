{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = \"FoCus\"                               \n",
    "LLM_name = \"Mistral-7B-Instruct\"           # Llama3-1-8B-Instruct,  gpt-3.5-turbo, gpt-4o-mini, Gemma-7B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: Sure, you will like to know that this p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>User2: Technische Universität Darmstadt in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>User2: I suggest a place, for your wish of see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: The history of the house you are intere...  \n",
       "1  User2: This house was use as a stop for slaves...  \n",
       "2  User2: Sure, you will like to know that this p...  \n",
       "3  User2: Technische Universität Darmstadt in the...  \n",
       "4  User2: I suggest a place, for your wish of see...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'./Prompts/{Dataset}.csv')\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas        0\n",
      "context         0\n",
      "act_response    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>The history of the house you are interested in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>This house was use as a stop for slaves trying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>Sure, you will like to know that this place wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>Technische Universität Darmstadt in the top 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>I suggest a place, for your wish of see librar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I would like to go to University.I live in Mic...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>They offer 132 bachelors degree programs and 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "5  I would like to go to University.I live in Mic...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "5  User1: I think Ive been there before but I don...   \n",
       "\n",
       "                                        act_response  \n",
       "0  The history of the house you are interested in...  \n",
       "1  This house was use as a stop for slaves trying...  \n",
       "2  Sure, you will like to know that this place wa...  \n",
       "3  Technische Universität Darmstadt in the top 25...  \n",
       "4  I suggest a place, for your wish of see librar...  \n",
       "5  They offer 132 bachelors degree programs and 1...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Only For: FoCus, IT-ConvAI2\n",
    "df['act_response'] = df['act_response'].apply(lambda x: x.split(':', 1)[1].strip() if ':' in x else x.strip())\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 2)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     102\n",
      "response_time      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nazareth House is a historic benevolent instit...</td>\n",
       "      <td>6.746092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Truman Galusha House is a fascinating hist...</td>\n",
       "      <td>8.609739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Marion Palace Theatre is a stunning exampl...</td>\n",
       "      <td>6.194755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technische Universität Darmstadt is a great ch...</td>\n",
       "      <td>7.916744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Boston Stump, as it's commonly known, is a...</td>\n",
       "      <td>7.536268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>You're working in a fascinating place, a museu...</td>\n",
       "      <td>8.595941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Mahasthangarh is an ancient city located in th...</td>\n",
       "      <td>8.572887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Armagh County Museum is a museum located in Ar...</td>\n",
       "      <td>8.644711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The Nyanga National Park is a perfect destinat...</td>\n",
       "      <td>7.161740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Hadrian's Wall is an ancient fortification bui...</td>\n",
       "      <td>6.960827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          gen_response  response_time\n",
       "0    Nazareth House is a historic benevolent instit...       6.746092\n",
       "1    The Truman Galusha House is a fascinating hist...       8.609739\n",
       "2    The Marion Palace Theatre is a stunning exampl...       6.194755\n",
       "3    Technische Universität Darmstadt is a great ch...       7.916744\n",
       "4    The Boston Stump, as it's commonly known, is a...       7.536268\n",
       "..                                                 ...            ...\n",
       "995  You're working in a fascinating place, a museu...       8.595941\n",
       "996  Mahasthangarh is an ancient city located in th...       8.572887\n",
       "997  Armagh County Museum is a museum located in Ar...       8.644711\n",
       "998  The Nyanga National Park is a perfect destinat...       7.161740\n",
       "999  Hadrian's Wall is an ancient fortification bui...       6.960827\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_csv(f'Responses/{Dataset}/{LLM_name}{\"-COT\"}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 131\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas           0\n",
      "act_response       0\n",
      "context            0\n",
      "gen_response     102\n",
      "response_time      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>act_response</th>\n",
       "      <th>context</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>The history of the house you are interested in...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>Nazareth House is a historic benevolent instit...</td>\n",
       "      <td>6.746092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>This house was use as a stop for slaves trying...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>The Truman Galusha House is a fascinating hist...</td>\n",
       "      <td>8.609739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>Sure, you will like to know that this place wa...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>The Marion Palace Theatre is a stunning exampl...</td>\n",
       "      <td>6.194755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>Technische Universität Darmstadt in the top 25...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>Technische Universität Darmstadt is a great ch...</td>\n",
       "      <td>7.916744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>I suggest a place, for your wish of see librar...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>The Boston Stump, as it's commonly known, is a...</td>\n",
       "      <td>7.536268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  The history of the house you are interested in...   \n",
       "1  This house was use as a stop for slaves trying...   \n",
       "2  Sure, you will like to know that this place wa...   \n",
       "3  Technische Universität Darmstadt in the top 25...   \n",
       "4  I suggest a place, for your wish of see librar...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  Nazareth House is a historic benevolent instit...       6.746092  \n",
       "1  The Truman Galusha House is a fascinating hist...       8.609739  \n",
       "2  The Marion Palace Theatre is a stunning exampl...       6.194755  \n",
       "3  Technische Universität Darmstadt is a great ch...       7.916744  \n",
       "4  The Boston Stump, as it's commonly known, is a...       7.536268  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'act_response': df['act_response'],\n",
    "    'context': df['context'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/salehafzoon/Desktop/Perso-LLM-Benchmarking/UniEval')\n",
    "\n",
    "from UniEval.metric.evaluator import get_evaluator\n",
    "from UniEval.utils import convert_to_json\n",
    "\n",
    "\n",
    "ue_scores = []\n",
    "c_scores = []\n",
    "persona_distance_scores = []\n",
    "\n",
    "\n",
    "bert_snli_dir = \"Fine-tuning/output/bert_snli\"\n",
    "bert_snli_model = BertForSequenceClassification.from_pretrained(bert_snli_dir)\n",
    "bert_snli_tokenizer = BertTokenizer.from_pretrained(bert_snli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline for UE Score\n",
    "bert_on_snli = pipeline('text-classification', model = bert_snli_model, tokenizer = bert_snli_tokenizer, device=0)\n",
    "\n",
    "bert_dnli_dir = \"Fine-tuning/output/bert_dnli\"\n",
    "bert_dnli_model = BertForSequenceClassification.from_pretrained(bert_dnli_dir)\n",
    "bert_dnli_tokenizer = BertTokenizer.from_pretrained(bert_dnli_dir)\n",
    "\n",
    "# Initialize the NLI pipeline\n",
    "bert_on_dnli = pipeline('text-classification', model = bert_dnli_model, tokenizer = bert_dnli_tokenizer, device=0)\n",
    "\n",
    "\n",
    "# Initialize the Word2Vec Model\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"./GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Initialize smoothing function\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "\n",
    "def compute_distinct_ngrams(text, n):\n",
    "    tokens = str(text).replace('\\n', ' ').split()\n",
    "    ngrams = list(zip(*[tokens[i:] for i in range(n)]))\n",
    "    distinct_ngrams = len(set(ngrams))\n",
    "    total_ngrams = len(ngrams)\n",
    "    return distinct_ngrams / total_ngrams if total_ngrams > 0 else 0\n",
    "\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "def calculate_c_score(gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the C score based on the entailment results between a generated response (R)\n",
    "    and a given persona (P).\n",
    "\n",
    "    Returns:\n",
    "    int: C-score with possible values:\n",
    "         1 for entailment (positive),\n",
    "         0 for neutral,\n",
    "         -1 for contradiction (negative).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping to interpret the NLI model's output\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'negative',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'positive'\n",
    "    }\n",
    "    \n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_dnli(f\"{persona} {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine C score based on entailment results\n",
    "    if label_pr == 'positive':\n",
    "        return 1\n",
    "    elif label_pr == 'neutral':\n",
    "        return 0\n",
    "    elif label_pr == 'negative':\n",
    "        return -1\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected label encountered: {label_pr}\")\n",
    "\n",
    "\n",
    "\n",
    "def calculate_ue_score(act_response, gen_response, persona):\n",
    "    \"\"\"\n",
    "    Calculate the UE score based on entailment between persona, actual response, and generated response.\n",
    "\n",
    "    Returns:\n",
    "    int: UE score with possible values 2, 1, or 0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the label mapping to interpret the NLI model's output\n",
    "    label_mapping = {\n",
    "        'LABEL_0': 'entailment',\n",
    "        'LABEL_1': 'neutral',\n",
    "        'LABEL_2': 'contradiction'\n",
    "    }\n",
    "    \n",
    "    # Check entailment between persona (P) and generated response (R)\n",
    "    result_pr = bert_on_snli(f\"{persona} [SEP] {gen_response}\")\n",
    "    label_pr = label_mapping.get(result_pr[0]['label'], 'unknown')\n",
    "\n",
    "    # Check entailment between actual response (Q) and generated response (R)\n",
    "    result_qr = bert_on_snli(f\"{act_response} [SEP] {gen_response}\")\n",
    "    label_qr = label_mapping.get(result_qr[0]['label'], 'unknown')\n",
    "\n",
    "    # Determine UE score based on entailment results\n",
    "    if label_pr == 'entailment' and label_qr == 'entailment':\n",
    "        return 2\n",
    "    elif label_pr == 'entailment':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def compute_persona_distance(persona, response, model, stop_words):\n",
    "    # Tokenize and filter stopwords\n",
    "    persona_tokens = [word for word in persona.lower().split() if word not in stop_words]\n",
    "    response_tokens = [word for word in response.lower().split() if word not in stop_words]\n",
    "    \n",
    "    # Get word vectors\n",
    "    persona_vecs = [model[word] for word in persona_tokens if word in model]\n",
    "    response_vecs = [model[word] for word in response_tokens if word in model]\n",
    "    \n",
    "    # If no vectors found, return zero similarity\n",
    "    if not persona_vecs or not response_vecs:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute average vectors\n",
    "    persona_avg_vec = np.mean(persona_vecs, axis=0)\n",
    "    response_avg_vec = np.mean(response_vecs, axis=0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return cosine_similarity([persona_avg_vec], [response_avg_vec])[0][0]\n",
    "\n",
    "\n",
    "def calculate_unieval_scores(personas, contexts, gen_responses):\n",
    "    \"\"\"\n",
    "    Calculates UniEval scores for a batch of inputs.\n",
    "\n",
    "    Args:\n",
    "        personas (list): List of persona information as additional context.\n",
    "        contexts (list): List of conversation histories leading to the responses.\n",
    "        gen_responses (list): List of generated responses to be evaluated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing UniEval scores for each input.\n",
    "    \"\"\"\n",
    "    # Flatten personas if they are lists\n",
    "    personas = [' '.join(p) if isinstance(p, list) else p for p in personas]\n",
    "\n",
    "    # Prepare inputs for UniEval\n",
    "    data = convert_to_json(output_list=gen_responses, src_list=contexts, context_list=personas)\n",
    "\n",
    "    # Initialize the evaluator for dialogue tasks\n",
    "    evaluator = get_evaluator('dialogue')\n",
    "\n",
    "    # Evaluate and obtain scores for all inputs\n",
    "    eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "    return eval_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "worst_c_score = -1.0\n",
    "worst_ue_score = 0.0\n",
    "worst_persona_distance_score = 0.0\n",
    "\n",
    "worst_unieval_score = {\n",
    "    'naturalness': 0.0,\n",
    "    'coherence': 0.0,\n",
    "    'engagingness': 0.0,\n",
    "    'groundedness': 0.0,\n",
    "    'understandability': 0.0,\n",
    "    'overall': 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 100.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.604714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.737407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.648557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C Score  UE Score  Persona Distance\n",
       "0        1.0       2.0          0.604714\n",
       "1        1.0       0.0          0.734168\n",
       "2        1.0       0.0          0.737407\n",
       "3        1.0       0.0          0.761614\n",
       "4        1.0       0.0          0.504854\n",
       "..       ...       ...               ...\n",
       "995      0.0       0.0          0.627368\n",
       "996      0.0       0.0          0.425594\n",
       "997      1.0       0.0          0.361952\n",
       "998      1.0       0.0          0.539867\n",
       "999      1.0       0.0          0.648557\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a counter for invalid gen_response\n",
    "invalid_gen_res_count = 0\n",
    "\n",
    "# Iterate over each row\n",
    "for index, row in tqdm(eval_df.iterrows(), total=len(eval_df)):\n",
    "    personas = row['personas']\n",
    "    act_response = row['act_response']\n",
    "    gen_response = row['gen_response']\n",
    "\n",
    "    # Check for NaN or None in gen_response\n",
    "    if pd.isna(gen_response):\n",
    "        invalid_gen_res_count += 1\n",
    "        \n",
    "        c_scores.append(worst_c_score)\n",
    "        persona_distance_scores.append(worst_persona_distance_score)\n",
    "        ue_scores.append(worst_ue_score)\n",
    "\n",
    "        continue\n",
    "    \n",
    "    c_scores.append(calculate_c_score(personas, gen_response))\n",
    "    \n",
    "    ue_scores.append(calculate_ue_score(act_response, gen_response, personas))\n",
    "\n",
    "    persona_distance = compute_persona_distance(personas, gen_response, word2vec_model, stop_words)\n",
    "    persona_distance_scores.append(persona_distance)\n",
    "\n",
    "\n",
    "# Compile metrics into DataFrame\n",
    "metrics_df_1  = pd.DataFrame({\n",
    "    'C Score': c_scores,\n",
    "    'UE Score': ue_scores,\n",
    "    'Persona Distance': persona_distance_scores\n",
    "})\n",
    "\n",
    "metrics_df_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating batches: 100%|██████████| 5/5 [15:39<00:00, 187.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.930204</td>\n",
       "      <td>0.998417</td>\n",
       "      <td>3.990297</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>0.936348</td>\n",
       "      <td>1.570674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.918790</td>\n",
       "      <td>0.997200</td>\n",
       "      <td>2.969362</td>\n",
       "      <td>0.909232</td>\n",
       "      <td>0.927470</td>\n",
       "      <td>1.344411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.947152</td>\n",
       "      <td>0.998238</td>\n",
       "      <td>3.981049</td>\n",
       "      <td>0.990371</td>\n",
       "      <td>0.943944</td>\n",
       "      <td>1.572151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.821111</td>\n",
       "      <td>0.998489</td>\n",
       "      <td>4.949582</td>\n",
       "      <td>0.998149</td>\n",
       "      <td>0.858559</td>\n",
       "      <td>1.725178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.863987</td>\n",
       "      <td>0.998076</td>\n",
       "      <td>3.965243</td>\n",
       "      <td>0.997227</td>\n",
       "      <td>0.870674</td>\n",
       "      <td>1.539041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniEval Naturalness  UniEval Coherence  UniEval Engagingness  \\\n",
       "0               0.930204           0.998417              3.990297   \n",
       "1               0.918790           0.997200              2.969362   \n",
       "2               0.947152           0.998238              3.981049   \n",
       "3               0.821111           0.998489              4.949582   \n",
       "4               0.863987           0.998076              3.965243   \n",
       "..                   ...                ...                   ...   \n",
       "995             0.000000           0.000000              0.000000   \n",
       "996             0.000000           0.000000              0.000000   \n",
       "997             0.000000           0.000000              0.000000   \n",
       "998             0.000000           0.000000              0.000000   \n",
       "999             0.000000           0.000000              0.000000   \n",
       "\n",
       "     UniEval Groundedness  UniEval Understandability  UniEval Overall  \n",
       "0                0.998103                   0.936348         1.570674  \n",
       "1                0.909232                   0.927470         1.344411  \n",
       "2                0.990371                   0.943944         1.572151  \n",
       "3                0.998149                   0.858559         1.725178  \n",
       "4                0.997227                   0.870674         1.539041  \n",
       "..                    ...                        ...              ...  \n",
       "995              0.000000                   0.000000         0.000000  \n",
       "996              0.000000                   0.000000         0.000000  \n",
       "997              0.000000                   0.000000         0.000000  \n",
       "998              0.000000                   0.000000         0.000000  \n",
       "999              0.000000                   0.000000         0.000000  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Function to evaluate in batches or the entire DataFrame\n",
    "batch_size = 200  # Adjust batch size as needed\n",
    "\n",
    "# List to store all UniEval scores\n",
    "all_unieval_scores = []\n",
    "\n",
    "# Split into batches if necessary\n",
    "for i in tqdm(range(0, len(eval_df), batch_size), desc=\"Evaluating batches\"):\n",
    "    batch = eval_df.iloc[i:i+batch_size]\n",
    "\n",
    "    # Extract relevant fields from the batch\n",
    "    personas = batch['personas'].tolist()\n",
    "    contexts = batch['context'].tolist()\n",
    "    gen_responses = batch['gen_response'].tolist()\n",
    "\n",
    "    # Check for NaN responses and handle them\n",
    "    valid_indices = [j for j, response in enumerate(gen_responses) if pd.notna(response) and response.strip() != '']\n",
    "    invalid_indices = [j for j, response in enumerate(gen_responses) if j not in valid_indices]\n",
    "\n",
    "    # Prepare valid inputs\n",
    "    valid_personas = [personas[j] for j in valid_indices]\n",
    "    valid_contexts = [contexts[j] for j in valid_indices]\n",
    "    valid_gen_responses = [gen_responses[j] for j in valid_indices]\n",
    "\n",
    "    # Evaluate valid inputs\n",
    "    if valid_personas:\n",
    "        eval_scores = calculate_unieval_scores(valid_personas, valid_contexts, valid_gen_responses)\n",
    "        all_unieval_scores.extend(eval_scores)\n",
    "\n",
    "    # Append worst scores for invalid inputs\n",
    "    all_unieval_scores.extend([worst_unieval_score] * len(invalid_indices))\n",
    "\n",
    "# Convert all scores into a DataFrame\n",
    "metrics_df_2  = pd.DataFrame(all_unieval_scores)\n",
    "\n",
    "# Rename columns for clarity\n",
    "metrics_df_2 .columns = [\n",
    "    \"UniEval Naturalness\",\n",
    "    \"UniEval Coherence\",\n",
    "    \"UniEval Engagingness\",\n",
    "    \"UniEval Groundedness\",\n",
    "    \"UniEval Understandability\",\n",
    "    \"UniEval Overall\"\n",
    "]\n",
    "\n",
    "metrics_df_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both metric sets\n",
    "metrics_df = pd.concat([metrics_df_1.reset_index(drop=True), metrics_df_2.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.604714</td>\n",
       "      <td>0.930204</td>\n",
       "      <td>0.998417</td>\n",
       "      <td>3.990297</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>0.936348</td>\n",
       "      <td>1.570674</td>\n",
       "      <td>6.746092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734168</td>\n",
       "      <td>0.918790</td>\n",
       "      <td>0.997200</td>\n",
       "      <td>2.969362</td>\n",
       "      <td>0.909232</td>\n",
       "      <td>0.927470</td>\n",
       "      <td>1.344411</td>\n",
       "      <td>8.609739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.737407</td>\n",
       "      <td>0.947152</td>\n",
       "      <td>0.998238</td>\n",
       "      <td>3.981049</td>\n",
       "      <td>0.990371</td>\n",
       "      <td>0.943944</td>\n",
       "      <td>1.572151</td>\n",
       "      <td>6.194755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761614</td>\n",
       "      <td>0.821111</td>\n",
       "      <td>0.998489</td>\n",
       "      <td>4.949582</td>\n",
       "      <td>0.998149</td>\n",
       "      <td>0.858559</td>\n",
       "      <td>1.725178</td>\n",
       "      <td>7.916744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.863987</td>\n",
       "      <td>0.998076</td>\n",
       "      <td>3.965243</td>\n",
       "      <td>0.997227</td>\n",
       "      <td>0.870674</td>\n",
       "      <td>1.539041</td>\n",
       "      <td>7.536268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.595941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.572887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.644711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.161740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.648557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.960827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C Score  UE Score  Persona Distance  UniEval Naturalness  \\\n",
       "0        1.0       2.0          0.604714             0.930204   \n",
       "1        1.0       0.0          0.734168             0.918790   \n",
       "2        1.0       0.0          0.737407             0.947152   \n",
       "3        1.0       0.0          0.761614             0.821111   \n",
       "4        1.0       0.0          0.504854             0.863987   \n",
       "..       ...       ...               ...                  ...   \n",
       "995      0.0       0.0          0.627368             0.000000   \n",
       "996      0.0       0.0          0.425594             0.000000   \n",
       "997      1.0       0.0          0.361952             0.000000   \n",
       "998      1.0       0.0          0.539867             0.000000   \n",
       "999      1.0       0.0          0.648557             0.000000   \n",
       "\n",
       "     UniEval Coherence  UniEval Engagingness  UniEval Groundedness  \\\n",
       "0             0.998417              3.990297              0.998103   \n",
       "1             0.997200              2.969362              0.909232   \n",
       "2             0.998238              3.981049              0.990371   \n",
       "3             0.998489              4.949582              0.998149   \n",
       "4             0.998076              3.965243              0.997227   \n",
       "..                 ...                   ...                   ...   \n",
       "995           0.000000              0.000000              0.000000   \n",
       "996           0.000000              0.000000              0.000000   \n",
       "997           0.000000              0.000000              0.000000   \n",
       "998           0.000000              0.000000              0.000000   \n",
       "999           0.000000              0.000000              0.000000   \n",
       "\n",
       "     UniEval Understandability  UniEval Overall  response_time  \n",
       "0                     0.936348         1.570674       6.746092  \n",
       "1                     0.927470         1.344411       8.609739  \n",
       "2                     0.943944         1.572151       6.194755  \n",
       "3                     0.858559         1.725178       7.916744  \n",
       "4                     0.870674         1.539041       7.536268  \n",
       "..                         ...              ...            ...  \n",
       "995                   0.000000         0.000000       8.595941  \n",
       "996                   0.000000         0.000000       8.572887  \n",
       "997                   0.000000         0.000000       8.644711  \n",
       "998                   0.000000         0.000000       7.161740  \n",
       "999                   0.000000         0.000000       6.960827  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the 'response_time' column to 'metrics_df'\n",
    "metrics_df['response_time'] = eval_df['response_time']\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(f'Metric_values/{Dataset}_{LLM_name}-COT_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 COMPARISON: Llama3-1-8B vs GPT-4O-Mini\n",
      "\n",
      "📌 Metric: C Score\n",
      "  Paired t-test:     t = 9.6888, p = 0.00000\n",
      "  Wilcoxon test:     W = 30110.0000, p = 0.00000\n",
      "\n",
      "📌 Metric: BERTScore_Prec\n",
      "  Paired t-test:     t = -8.9430, p = 0.00000\n",
      "  Wilcoxon test:     W = 55052.0000, p = 0.00000\n",
      "\n",
      "📌 Metric: BERTScore_Rec\n",
      "  Paired t-test:     t = -10.4733, p = 0.00000\n",
      "  Wilcoxon test:     W = 35670.0000, p = 0.00000\n",
      "\n",
      "📌 Metric: BERTScore_F1\n",
      "  Paired t-test:     t = -9.6948, p = 0.00000\n",
      "  Wilcoxon test:     W = 39380.0000, p = 0.00000\n",
      "\n",
      "📌 Metric: Dist1\n",
      "  Paired t-test:     t = -15.0159, p = 0.00000\n",
      "  Wilcoxon test:     W = 78414.5000, p = 0.00000\n",
      "\n",
      "📌 Metric: Dist2\n",
      "  Paired t-test:     t = -8.7999, p = 0.00000\n",
      "  Wilcoxon test:     W = 47954.0000, p = 0.00000\n",
      "\n",
      "📌 Metric: Persona Distance\n",
      "  Paired t-test:     t = 4.3339, p = 0.00002\n",
      "  Wilcoxon test:     W = 150969.0000, p = 0.00000\n",
      "\n",
      "📌 Metric: UniEval Naturalness\n",
      "  Paired t-test:     t = -12.1395, p = 0.00000\n",
      "  Wilcoxon test:     W = 96850.0000, p = 0.00000\n",
      "\n",
      "📌 Metric: UniEval Coherence\n",
      "  Paired t-test:     t = -7.3737, p = 0.00000\n",
      "  Wilcoxon test:     W = 112655.0000, p = 0.00000\n",
      "\n",
      "📌 Metric: UniEval Overall\n",
      "  Paired t-test:     t = 3.9457, p = 0.00009\n",
      "  Wilcoxon test:     W = 170632.0000, p = 0.00000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "# --------------------------\n",
    "# CONFIGURE THESE\n",
    "# --------------------------\n",
    "DATASET = \"FoCus\"\n",
    "\n",
    "# Llama3-1-8B-Instruct,  gpt-3.5-turbo, gpt-4o-mini\n",
    "\n",
    "# LLMs\n",
    "models = {\n",
    "    'Llama3-1-8B': f'Metric_values/{DATASET}_Llama3-1-8B-Instruct-COT_metrics.csv',\n",
    "    'GPT-4O-Mini': f'Metric_values/{DATASET}_gpt-4o-mini-COT_metrics.csv',\n",
    "}\n",
    "\n",
    "# List of metrics to test\n",
    "metrics_to_compare = [\n",
    "    'C Score',\n",
    "    'BERTScore_Prec',\n",
    "    'BERTScore_Rec',\n",
    "    'BERTScore_F1',\n",
    "    'Dist1',\n",
    "    'Dist2',\n",
    "    'Persona Distance',\n",
    "    'UniEval Naturalness',\n",
    "    'UniEval Coherence',\n",
    "    'UniEval Overall'\n",
    "]\n",
    "\n",
    "# --------------------------\n",
    "# TEST FUNCTION\n",
    "# --------------------------\n",
    "def run_statistical_tests(df1, df2, model1, model2):\n",
    "    print(f\"\\n🔍 COMPARISON: {model1} vs {model2}\")\n",
    "    for metric in metrics_to_compare:\n",
    "        try:\n",
    "            scores1 = df1[metric].values\n",
    "            scores2 = df2[metric].values\n",
    "\n",
    "            # Paired t-test\n",
    "            t_stat, p_t = ttest_rel(scores1, scores2)\n",
    "\n",
    "            # Wilcoxon test\n",
    "            w_stat, p_w = wilcoxon(scores1, scores2)\n",
    "\n",
    "            print(f\"\\n📌 Metric: {metric}\")\n",
    "            print(f\"  Paired t-test:     t = {t_stat:.4f}, p = {p_t:.5f}\")\n",
    "            print(f\"  Wilcoxon test:     W = {w_stat:.4f}, p = {p_w:.5f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Could not compute {metric}: {e}\")\n",
    "\n",
    "# --------------------------\n",
    "# LOAD CSVs & COMPARE\n",
    "# --------------------------\n",
    "\n",
    "# COT comparison\n",
    "df_c1 = pd.read_csv(models['Llama3-1-8B'])\n",
    "df_c2 = pd.read_csv(models['GPT-4O-Mini'])\n",
    "run_statistical_tests(df_c1, df_c2, 'Llama3-1-8B', 'GPT-4O-Mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persoagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

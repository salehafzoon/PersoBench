{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 54.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation scores are shown below:\n",
      "+-------------------+----------+\n",
      "|     Dimensions    |  Score   |\n",
      "+-------------------+----------+\n",
      "|    naturalness    | 0.950217 |\n",
      "|     coherence     | 0.973135 |\n",
      "|    engagingness   | 1.750486 |\n",
      "|    groundedness   | 0.999566 |\n",
      "| understandability | 0.946209 |\n",
      "|      overall      | 1.123923 |\n",
      "+-------------------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'dialogue'\n",
    "\n",
    "# a list of dialogue histories\n",
    "src_list = ['hi , do you know much about the internet ? \\n i know a lot about different sites and some website design , how about you ? \\n\\n']\n",
    "# a list of additional context that should be included into the generated response\n",
    "context_list = ['the 3 horizontal line menu on apps and websites is called a hamburger button .\\n']\n",
    "# a list of model outputs to be evaluated\n",
    "output_list = ['i do too . did you know the 3 horizontal line menu on apps and websites is called the hamburger button ?']\n",
    "\n",
    "# Prepare data for pre-trained evaluators\n",
    "data = convert_to_json(output_list=output_list, \n",
    "                       src_list=src_list, context_list=context_list)\n",
    "# Initialize evaluator for a specific task\n",
    "evaluator = get_evaluator(task)\n",
    "# Get multi-dimensional evaluation scores\n",
    "eval_scores = evaluator.evaluate(data, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 42.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for example 1: {'naturalness': 0.9502174201360719, 'coherence': 0.9731347836152868, 'engagingness': 1.7504860805525295, 'groundedness': 0.9995656267195939, 'understandability': 0.9462095037239142, 'overall': 1.1239226829494793}\n",
      "Scores for example 2: {'naturalness': 0.9675946477090701, 'coherence': 0.998674558536015, 'engagingness': 1.9936029005678884, 'groundedness': 0.9857853472625128, 'understandability': 0.9632170362278318, 'overall': 1.1817748980606635}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'dialogue'\n",
    "\n",
    "# Batch inputs: multiple dialogue histories, contexts, and model outputs\n",
    "src_list = [\n",
    "    'hi , do you know much about the internet ? \\n i know a lot about different sites and some website design , how about you ? \\n\\n',\n",
    "    'what is your favorite color ? \\n i like blue a lot , but sometimes i prefer green . \\n\\n'\n",
    "]\n",
    "context_list = [\n",
    "    'the 3 horizontal line menu on apps and websites is called a hamburger button .\\n',\n",
    "    'colors can reflect your mood and personality .\\n'\n",
    "]\n",
    "output_list = [\n",
    "    'i do too . did you know the 3 horizontal line menu on apps and websites is called the hamburger button ?',\n",
    "    'i like blue as well . it is calming and reminds me of the ocean .'\n",
    "]\n",
    "\n",
    "# Prepare data for pre-trained evaluators\n",
    "data = convert_to_json(output_list=output_list, \n",
    "                       src_list=src_list, context_list=context_list)\n",
    "\n",
    "# Initialize evaluator for a specific task\n",
    "evaluator = get_evaluator(task)\n",
    "\n",
    "# Get multi-dimensional evaluation scores for the batch\n",
    "eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "# Display scores\n",
    "for i, score in enumerate(eval_scores):\n",
    "    print(f\"Scores for example {i + 1}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'naturalness': 0.9502174201360719,\n",
       "  'coherence': 0.9731347836152868,\n",
       "  'engagingness': 1.7504860805525295,\n",
       "  'groundedness': 0.9995656267195939,\n",
       "  'understandability': 0.9462095037239142,\n",
       "  'overall': 1.1239226829494793},\n",
       " {'naturalness': 0.9675946477090701,\n",
       "  'coherence': 0.998674558536015,\n",
       "  'engagingness': 1.9936029005678884,\n",
       "  'groundedness': 0.9857853472625128,\n",
       "  'understandability': 0.9632170362278318,\n",
       "  'overall': 1.1817748980606635}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Generation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = \"IT-ConvAI2\"                                # Synthetic-PersonaChat, Blended Skill Talk, PEC, ConvAI2, FoCus, IT-ConvAI2\n",
    "LLM_name = \"gemini-1.5-pro\"                           # Mistral-7B-Instruct, Llama3-1-8B-Instruct, Qwen2-7B-Instruct,  Gemma-7B-Instruct, gpt-3.5-turbo, gpt-4-turbo, gpt-4o-mini\n",
    "COT_SETUP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1183, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love disneyland and mickey mouse.i love to s...</td>\n",
       "      <td>User1: no , we recently purchased a new house ...</td>\n",
       "      <td>User2: yes i love mickey mouse such a cute lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love to drink fancy tea.i have a big library...</td>\n",
       "      <td>User1: hi how are you doing ? i am okay how ab...</td>\n",
       "      <td>User2: i am doing good . just sipping tea . wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im a little girl.ive superpowers.i like to mak...</td>\n",
       "      <td>User1: what is your name ? are you a male or f...</td>\n",
       "      <td>User2: im a girl . i do not give out my name .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i love cats and have two cats.my favorite seas...</td>\n",
       "      <td>User1: hi ! do you like turtles ?</td>\n",
       "      <td>User2: i am much more of a cat person actually</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love cats and have two cats.my favorite seas...</td>\n",
       "      <td>User1: what are your kitties names ?</td>\n",
       "      <td>User2: snow and winter , named after my favori...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  i love disneyland and mickey mouse.i love to s...   \n",
       "1  i love to drink fancy tea.i have a big library...   \n",
       "2  im a little girl.ive superpowers.i like to mak...   \n",
       "3  i love cats and have two cats.my favorite seas...   \n",
       "4  i love cats and have two cats.my favorite seas...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: no , we recently purchased a new house ...   \n",
       "1  User1: hi how are you doing ? i am okay how ab...   \n",
       "2  User1: what is your name ? are you a male or f...   \n",
       "3                  User1: hi ! do you like turtles ?   \n",
       "4               User1: what are your kitties names ?   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: yes i love mickey mouse such a cute lit...  \n",
       "1  User2: i am doing good . just sipping tea . wh...  \n",
       "2     User2: im a girl . i do not give out my name .  \n",
       "3     User2: i am much more of a cat person actually  \n",
       "4  User2: snow and winter , named after my favori...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'../Prompts/{Dataset}.csv')\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IT-ConvAI2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas        0\n",
      "context         0\n",
      "act_response    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love disneyland and mickey mouse.i love to s...</td>\n",
       "      <td>User1: no , we recently purchased a new house ...</td>\n",
       "      <td>User2: yes i love mickey mouse such a cute lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love to drink fancy tea.i have a big library...</td>\n",
       "      <td>User1: hi how are you doing ? i am okay how ab...</td>\n",
       "      <td>User2: i am doing good . just sipping tea . wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im a little girl.ive superpowers.i like to mak...</td>\n",
       "      <td>User1: what is your name ? are you a male or f...</td>\n",
       "      <td>User2: im a girl . i do not give out my name .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i love cats and have two cats.my favorite seas...</td>\n",
       "      <td>User1: hi ! do you like turtles ?</td>\n",
       "      <td>User2: i am much more of a cat person actually</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love cats and have two cats.my favorite seas...</td>\n",
       "      <td>User1: what are your kitties names ?</td>\n",
       "      <td>User2: snow and winter , named after my favori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i love cats and have two cats.my favorite seas...</td>\n",
       "      <td>User1: how old are you ? i turned four on my b...</td>\n",
       "      <td>User2: i am an old woman . i won a gold medal ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  i love disneyland and mickey mouse.i love to s...   \n",
       "1  i love to drink fancy tea.i have a big library...   \n",
       "2  im a little girl.ive superpowers.i like to mak...   \n",
       "3  i love cats and have two cats.my favorite seas...   \n",
       "4  i love cats and have two cats.my favorite seas...   \n",
       "5  i love cats and have two cats.my favorite seas...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: no , we recently purchased a new house ...   \n",
       "1  User1: hi how are you doing ? i am okay how ab...   \n",
       "2  User1: what is your name ? are you a male or f...   \n",
       "3                  User1: hi ! do you like turtles ?   \n",
       "4               User1: what are your kitties names ?   \n",
       "5  User1: how old are you ? i turned four on my b...   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: yes i love mickey mouse such a cute lit...  \n",
       "1  User2: i am doing good . just sipping tea . wh...  \n",
       "2     User2: im a girl . i do not give out my name .  \n",
       "3     User2: i am much more of a cat person actually  \n",
       "4  User2: snow and winter , named after my favori...  \n",
       "5  User2: i am an old woman . i won a gold medal ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Only For: Blended Skill Talk\n",
    "if Dataset == \"Blended Skill Talk\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[User 1 persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "# ### Only For: PEC\n",
    "if Dataset == \"PEC\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[Responder persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1183, 3)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     9\n",
      "reasoning        9\n",
      "response_time    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's completely understandable! Buying a new...</td>\n",
       "      <td>The user mentioned not being able to afford a ...</td>\n",
       "      <td>22.281498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm doing quite well, thank you for asking.  E...</td>\n",
       "      <td>The persona enjoys fancy tea, has a large libr...</td>\n",
       "      <td>3.786208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm Nimbus, a girl.  I live up in the fluffy c...</td>\n",
       "      <td>I'm personalizing my response as a little girl...</td>\n",
       "      <td>3.242977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi!  Turtles are pretty cool. I definitely pre...</td>\n",
       "      <td>The persona loves cats and has two.  While the...</td>\n",
       "      <td>3.913722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My two wonderful kitties are named Mittens and...</td>\n",
       "      <td>The user asked about the names of my cats.  My...</td>\n",
       "      <td>3.177750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>Yeah, I produce music for artists. That's cool...</td>\n",
       "      <td>The user mentioned their job.  My persona incl...</td>\n",
       "      <td>4.521672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>I can definitely understand why you'd be terri...</td>\n",
       "      <td>The user expresses fear of scorpions. My perso...</td>\n",
       "      <td>5.380517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>I'm working as a custodian right now to make e...</td>\n",
       "      <td>The user asks a direct question about my livel...</td>\n",
       "      <td>3.849250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>While I'm not a tennis player myself, I can de...</td>\n",
       "      <td>The user asks about sports and mentions tennis...</td>\n",
       "      <td>6.353053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>I like to go skydiving!  It's a great way to d...</td>\n",
       "      <td>The user mentioned using dog walks to de-stres...</td>\n",
       "      <td>4.219043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1183 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           gen_response  \\\n",
       "0     That's completely understandable! Buying a new...   \n",
       "1     I'm doing quite well, thank you for asking.  E...   \n",
       "2     I'm Nimbus, a girl.  I live up in the fluffy c...   \n",
       "3     Hi!  Turtles are pretty cool. I definitely pre...   \n",
       "4     My two wonderful kitties are named Mittens and...   \n",
       "...                                                 ...   \n",
       "1178  Yeah, I produce music for artists. That's cool...   \n",
       "1179  I can definitely understand why you'd be terri...   \n",
       "1180  I'm working as a custodian right now to make e...   \n",
       "1181  While I'm not a tennis player myself, I can de...   \n",
       "1182  I like to go skydiving!  It's a great way to d...   \n",
       "\n",
       "                                              reasoning  response_time  \n",
       "0     The user mentioned not being able to afford a ...      22.281498  \n",
       "1     The persona enjoys fancy tea, has a large libr...       3.786208  \n",
       "2     I'm personalizing my response as a little girl...       3.242977  \n",
       "3     The persona loves cats and has two.  While the...       3.913722  \n",
       "4     The user asked about the names of my cats.  My...       3.177750  \n",
       "...                                                 ...            ...  \n",
       "1178  The user mentioned their job.  My persona incl...       4.521672  \n",
       "1179  The user expresses fear of scorpions. My perso...       5.380517  \n",
       "1180  The user asks a direct question about my livel...       3.849250  \n",
       "1181  The user asks about sports and mentions tennis...       6.353053  \n",
       "1182  The user mentioned using dog walks to de-stres...       4.219043  \n",
       "\n",
       "[1183 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COT_ = \"-COT\" if COT_SETUP else \"\"\n",
    " \n",
    "response = pd.read_csv(f'../Responses/{Dataset}/{LLM_name}{COT_}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 95\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas         0\n",
      "context          0\n",
      "gen_response     9\n",
      "response_time    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love disneyland and mickey mouse.i love to s...</td>\n",
       "      <td>User1: no , we recently purchased a new house ...</td>\n",
       "      <td>That's completely understandable! Buying a new...</td>\n",
       "      <td>22.281498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love to drink fancy tea.i have a big library...</td>\n",
       "      <td>User1: hi how are you doing ? i am okay how ab...</td>\n",
       "      <td>I'm doing quite well, thank you for asking.  E...</td>\n",
       "      <td>3.786208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im a little girl.ive superpowers.i like to mak...</td>\n",
       "      <td>User1: what is your name ? are you a male or f...</td>\n",
       "      <td>I'm Nimbus, a girl.  I live up in the fluffy c...</td>\n",
       "      <td>3.242977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i love cats and have two cats.my favorite seas...</td>\n",
       "      <td>User1: hi ! do you like turtles ?</td>\n",
       "      <td>Hi!  Turtles are pretty cool. I definitely pre...</td>\n",
       "      <td>3.913722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love cats and have two cats.my favorite seas...</td>\n",
       "      <td>User1: what are your kitties names ?</td>\n",
       "      <td>My two wonderful kitties are named Mittens and...</td>\n",
       "      <td>3.177750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  i love disneyland and mickey mouse.i love to s...   \n",
       "1  i love to drink fancy tea.i have a big library...   \n",
       "2  im a little girl.ive superpowers.i like to mak...   \n",
       "3  i love cats and have two cats.my favorite seas...   \n",
       "4  i love cats and have two cats.my favorite seas...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: no , we recently purchased a new house ...   \n",
       "1  User1: hi how are you doing ? i am okay how ab...   \n",
       "2  User1: what is your name ? are you a male or f...   \n",
       "3                  User1: hi ! do you like turtles ?   \n",
       "4               User1: what are your kitties names ?   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  That's completely understandable! Buying a new...      22.281498  \n",
       "1  I'm doing quite well, thank you for asking.  E...       3.786208  \n",
       "2  I'm Nimbus, a girl.  I live up in the fluffy c...       3.242977  \n",
       "3  Hi!  Turtles are pretty cool. I definitely pre...       3.913722  \n",
       "4  My two wonderful kitties are named Mittens and...       3.177750  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'context': df['context'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU\n",
    "# device = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finalized Input Mapping:**\n",
    "\n",
    "- src_list: Use the context column (conversation history).\n",
    "- context_list: Use the flattened and cleaned persona column.\n",
    "- output_list: Use the gen_response (the response your model generates).\n",
    "\n",
    "**Note:**\n",
    "\n",
    "The act_response (true or reference response) is not required as an input for the UniEval evaluation process because UniEval evaluates the generated response (gen_response) based on how well it fits the provided context (conversation history) and additional persona information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "def calculate_unieval_scores(personas, contexts, gen_responses):\n",
    "    \"\"\"\n",
    "    Calculates UniEval scores for a batch of inputs.\n",
    "\n",
    "    Args:\n",
    "        personas (list): List of persona information as additional context.\n",
    "        contexts (list): List of conversation histories leading to the responses.\n",
    "        gen_responses (list): List of generated responses to be evaluated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing UniEval scores for each input.\n",
    "    \"\"\"\n",
    "    # Flatten personas if they are lists\n",
    "    personas = [' '.join(p) if isinstance(p, list) else p for p in personas]\n",
    "\n",
    "    # Prepare inputs for UniEval\n",
    "    data = convert_to_json(output_list=gen_responses, src_list=contexts, context_list=personas)\n",
    "\n",
    "    # Initialize the evaluator for dialogue tasks\n",
    "    evaluator = get_evaluator('dialogue')\n",
    "\n",
    "    # Evaluate and obtain scores for all inputs\n",
    "    eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "    return eval_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the worst UniEval score as a dictionary\n",
    "worst_unieval_score = {\n",
    "    'naturalness': 0.0,\n",
    "    'coherence': 0.0,\n",
    "    'engagingness': 0.0,\n",
    "    'groundedness': 0.0,\n",
    "    'understandability': 0.0,\n",
    "    'overall': 0.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating batches:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Evaluating batches: 100%|██████████| 6/6 [08:06<00:00, 81.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932827</td>\n",
       "      <td>0.947502</td>\n",
       "      <td>3.620819</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>0.929676</td>\n",
       "      <td>1.486116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.911020</td>\n",
       "      <td>0.984557</td>\n",
       "      <td>3.783001</td>\n",
       "      <td>0.998065</td>\n",
       "      <td>0.909855</td>\n",
       "      <td>1.517300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.923072</td>\n",
       "      <td>0.845386</td>\n",
       "      <td>1.655268</td>\n",
       "      <td>0.972248</td>\n",
       "      <td>0.912169</td>\n",
       "      <td>1.061629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.962173</td>\n",
       "      <td>0.998624</td>\n",
       "      <td>2.809815</td>\n",
       "      <td>0.068020</td>\n",
       "      <td>0.957679</td>\n",
       "      <td>1.159262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.968726</td>\n",
       "      <td>0.994031</td>\n",
       "      <td>0.997240</td>\n",
       "      <td>0.727822</td>\n",
       "      <td>0.966274</td>\n",
       "      <td>0.930818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>0.971041</td>\n",
       "      <td>0.883818</td>\n",
       "      <td>4.798749</td>\n",
       "      <td>0.997742</td>\n",
       "      <td>0.969830</td>\n",
       "      <td>1.724236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>0.949776</td>\n",
       "      <td>0.999081</td>\n",
       "      <td>2.006373</td>\n",
       "      <td>0.887707</td>\n",
       "      <td>0.936774</td>\n",
       "      <td>1.155942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>0.924758</td>\n",
       "      <td>0.990696</td>\n",
       "      <td>3.891174</td>\n",
       "      <td>0.995875</td>\n",
       "      <td>0.924021</td>\n",
       "      <td>1.545305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>0.963098</td>\n",
       "      <td>0.968711</td>\n",
       "      <td>1.930888</td>\n",
       "      <td>0.999239</td>\n",
       "      <td>0.959356</td>\n",
       "      <td>1.164258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1183 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UniEval Naturalness  UniEval Coherence  UniEval Engagingness  \\\n",
       "0                0.932827           0.947502              3.620819   \n",
       "1                0.911020           0.984557              3.783001   \n",
       "2                0.923072           0.845386              1.655268   \n",
       "3                0.962173           0.998624              2.809815   \n",
       "4                0.968726           0.994031              0.997240   \n",
       "...                   ...                ...                   ...   \n",
       "1178             0.971041           0.883818              4.798749   \n",
       "1179             0.949776           0.999081              2.006373   \n",
       "1180             0.924758           0.990696              3.891174   \n",
       "1181             0.963098           0.968711              1.930888   \n",
       "1182             0.000000           0.000000              0.000000   \n",
       "\n",
       "      UniEval Groundedness  UniEval Understandability  UniEval Overall  \n",
       "0                 0.999758                   0.929676         1.486116  \n",
       "1                 0.998065                   0.909855         1.517300  \n",
       "2                 0.972248                   0.912169         1.061629  \n",
       "3                 0.068020                   0.957679         1.159262  \n",
       "4                 0.727822                   0.966274         0.930818  \n",
       "...                    ...                        ...              ...  \n",
       "1178              0.997742                   0.969830         1.724236  \n",
       "1179              0.887707                   0.936774         1.155942  \n",
       "1180              0.995875                   0.924021         1.545305  \n",
       "1181              0.999239                   0.959356         1.164258  \n",
       "1182              0.000000                   0.000000         0.000000  \n",
       "\n",
       "[1183 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Function to evaluate in batches or the entire DataFrame\n",
    "batch_size = 200  # Adjust batch size as needed\n",
    "\n",
    "# List to store all UniEval scores\n",
    "all_unieval_scores = []\n",
    "\n",
    "# Split into batches if necessary\n",
    "for i in tqdm(range(0, len(eval_df), batch_size), desc=\"Evaluating batches\"):\n",
    "    batch = eval_df.iloc[i:i+batch_size]\n",
    "\n",
    "    # Extract relevant fields from the batch\n",
    "    personas = batch['personas'].tolist()\n",
    "    contexts = batch['context'].tolist()\n",
    "    gen_responses = batch['gen_response'].tolist()\n",
    "\n",
    "    # Check for NaN responses and handle them\n",
    "    valid_indices = [j for j, response in enumerate(gen_responses) if pd.notna(response) and response.strip() != '']\n",
    "    invalid_indices = [j for j, response in enumerate(gen_responses) if j not in valid_indices]\n",
    "\n",
    "    # Prepare valid inputs\n",
    "    valid_personas = [personas[j] for j in valid_indices]\n",
    "    valid_contexts = [contexts[j] for j in valid_indices]\n",
    "    valid_gen_responses = [gen_responses[j] for j in valid_indices]\n",
    "\n",
    "    # Evaluate valid inputs\n",
    "    if valid_personas:\n",
    "        eval_scores = calculate_unieval_scores(valid_personas, valid_contexts, valid_gen_responses)\n",
    "        all_unieval_scores.extend(eval_scores)\n",
    "\n",
    "    # Append worst scores for invalid inputs\n",
    "    all_unieval_scores.extend([worst_unieval_score] * len(invalid_indices))\n",
    "\n",
    "# Convert all scores into a DataFrame\n",
    "metrics_df = pd.DataFrame(all_unieval_scores)\n",
    "\n",
    "# Rename columns for clarity\n",
    "metrics_df.columns = [\n",
    "    \"UniEval Naturalness\",\n",
    "    \"UniEval Coherence\",\n",
    "    \"UniEval Engagingness\",\n",
    "    \"UniEval Groundedness\",\n",
    "    \"UniEval Understandability\",\n",
    "    \"UniEval Overall\"\n",
    "]\n",
    "\n",
    "# Combine with original DataFrame if needed\n",
    "eval_df = pd.concat([eval_df.reset_index(drop=True), metrics_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean (average) and standard deviation, rounded to 2 decimal places\n",
    "avg_values = metrics_df.mean().round(2)\n",
    "std_values = metrics_df.std(ddof=0).round(2)  # Use ddof=0 for population standard deviation\n",
    "\n",
    "# Combine the average and standard deviation into the format \"avg ± std\"\n",
    "combined_values = avg_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "\n",
    "# Insert the LLM name at the beginning of the combined values\n",
    "combined_values = combined_values.tolist()\n",
    "combined_values.insert(0, LLM_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>0.94 ± 0.09</td>\n",
       "      <td>0.9 ± 0.23</td>\n",
       "      <td>2.67 ± 1.28</td>\n",
       "      <td>0.76 ± 0.37</td>\n",
       "      <td>0.94 ± 0.09</td>\n",
       "      <td>1.24 ± 0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  gemini-1.5-pro         0.94 ± 0.09        0.9 ± 0.23          2.67 ± 1.28   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.76 ± 0.37               0.94 ± 0.09     1.24 ± 0.29  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for the combined average ± std row\n",
    "result_df = pd.DataFrame([combined_values], columns=['Model'] + metrics_df.columns.tolist())\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>...</th>\n",
       "      <th>IDF Overlap</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral-7B-Instruct</td>\n",
       "      <td>0.79 ± 0.41</td>\n",
       "      <td>0.02 ± 0.67\\t</td>\n",
       "      <td>0.31 ± 0.67</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.08</td>\n",
       "      <td>0.01 ± 0.04</td>\n",
       "      <td>0.09 ± 0.07</td>\n",
       "      <td>0.11 ± 0.09</td>\n",
       "      <td>0.8 ± 0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.08</td>\n",
       "      <td>0.54 ± 0.2</td>\n",
       "      <td>6.9 ± 1.61</td>\n",
       "      <td>0.046 ± 0.00</td>\n",
       "      <td>0.9 ± 0.2</td>\n",
       "      <td>0.83 ± 0.32</td>\n",
       "      <td>1.98 ± 1.22</td>\n",
       "      <td>0.63 ± 0.44</td>\n",
       "      <td>0.9 ± 0.2</td>\n",
       "      <td>1.05 ± 0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama3-1-8B-Instruct</td>\n",
       "      <td>0.83 ± 0.38\\t</td>\n",
       "      <td>0.05 ± 0.63</td>\n",
       "      <td>0.22 ± 0.58\\t</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.11 ± 0.09</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.1 ± 0.08</td>\n",
       "      <td>0.12 ± 0.09</td>\n",
       "      <td>0.84 ± 0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.08</td>\n",
       "      <td>0.58 ± 0.13</td>\n",
       "      <td>8.17 ± 0.11</td>\n",
       "      <td>0.006 ± 0.00</td>\n",
       "      <td>0.94 ± 0.1</td>\n",
       "      <td>0.8 ± 0.32</td>\n",
       "      <td>1.81 ± 1.07</td>\n",
       "      <td>0.66 ± 0.41</td>\n",
       "      <td>0.93 ± 0.1</td>\n",
       "      <td>1.03 ± 0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.87 ± 0.34\\t</td>\n",
       "      <td>0.23 ± 0.67</td>\n",
       "      <td>0.38 ± 0.72\\t</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.06</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.08 ± 0.06</td>\n",
       "      <td>0.12 ± 0.09</td>\n",
       "      <td>0.82 ± 0.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.07</td>\n",
       "      <td>0.63 ± 0.13</td>\n",
       "      <td>4.7 ± 0.94</td>\n",
       "      <td>0.008 ± 0.00</td>\n",
       "      <td>0.93 ± 0.1</td>\n",
       "      <td>0.87 ± 0.25</td>\n",
       "      <td>2.96 ± 1.22</td>\n",
       "      <td>0.84 ± 0.32</td>\n",
       "      <td>0.93 ± 0.11</td>\n",
       "      <td>1.31 ± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.85 ± 0.36\\t</td>\n",
       "      <td>0.1 ± 0.62</td>\n",
       "      <td>0.38 ± 0.74</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.1 ± 0.07</td>\n",
       "      <td>0.13 ± 0.1</td>\n",
       "      <td>0.84 ± 0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.08</td>\n",
       "      <td>0.6 ± 0.13</td>\n",
       "      <td>1.4 ± 0.3</td>\n",
       "      <td>0.001 ± 0.00</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>0.87 ± 0.25</td>\n",
       "      <td>2.28 ± 0.95</td>\n",
       "      <td>0.72 ± 0.39</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>1.16 ± 0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>0.83 ± 0.37\\t</td>\n",
       "      <td>0.01 ± 0.58</td>\n",
       "      <td>0.42 ± 0.78</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.1 ± 0.08</td>\n",
       "      <td>0.13 ± 0.1</td>\n",
       "      <td>0.84 ± 0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.07</td>\n",
       "      <td>0.59 ± 0.12</td>\n",
       "      <td>4.81 ± 1.45</td>\n",
       "      <td>0.0 ± 0.00</td>\n",
       "      <td>0.96 ± 0.02</td>\n",
       "      <td>0.91 ± 0.21</td>\n",
       "      <td>2.21 ± 0.9</td>\n",
       "      <td>0.78 ± 0.34</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>1.16 ± 0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.87 ± 0.33\\t</td>\n",
       "      <td>0.14 ± 0.61</td>\n",
       "      <td>0.38 ± 0.74\\t</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.1 ± 0.06</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.1 ± 0.06</td>\n",
       "      <td>0.16 ± 0.09</td>\n",
       "      <td>0.83 ± 0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09 ± 0.07</td>\n",
       "      <td>0.64 ± 0.11</td>\n",
       "      <td>2.2 ± 0.67</td>\n",
       "      <td>0.002 ± 0.00</td>\n",
       "      <td>0.95 ± 0.04</td>\n",
       "      <td>0.96 ± 0.13</td>\n",
       "      <td>3.17 ± 1.02</td>\n",
       "      <td>0.91 ± 0.23</td>\n",
       "      <td>0.95 ± 0.04</td>\n",
       "      <td>1.39 ± 0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gemma-7B-Instruct</td>\n",
       "      <td>0.79 ± 0.41</td>\n",
       "      <td>0.19 ± 0.76</td>\n",
       "      <td>0.25 ± 0.56</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.08</td>\n",
       "      <td>0.01 ± 0.04</td>\n",
       "      <td>0.09 ± 0.07</td>\n",
       "      <td>0.12 ± 0.1</td>\n",
       "      <td>0.75 ± 0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12 ± 0.13</td>\n",
       "      <td>0.57 ± 0.24</td>\n",
       "      <td>8.64 ± 1.59</td>\n",
       "      <td>0.105 ± 0.00</td>\n",
       "      <td>0.85 ± 0.29</td>\n",
       "      <td>0.73 ± 0.4</td>\n",
       "      <td>2.42 ± 1.38</td>\n",
       "      <td>0.74 ± 0.41</td>\n",
       "      <td>0.85 ± 0.29</td>\n",
       "      <td>1.12 ± 0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03 ± 0.64</td>\n",
       "      <td>0.33 ± 0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.83 ± 0.08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.58 ± 0.15</td>\n",
       "      <td>4.83 ± 3.46</td>\n",
       "      <td>0.008 ± 0.00</td>\n",
       "      <td>0.94 ± 0.09</td>\n",
       "      <td>0.9 ± 0.23</td>\n",
       "      <td>2.67 ± 1.28</td>\n",
       "      <td>0.76 ± 0.37</td>\n",
       "      <td>0.94 ± 0.09</td>\n",
       "      <td>1.24 ± 0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model P Consistency Score        C Score       UE Score  \\\n",
       "0   Mistral-7B-Instruct         0.79 ± 0.41  0.02 ± 0.67\\t    0.31 ± 0.67   \n",
       "1  Llama3-1-8B-Instruct       0.83 ± 0.38\\t    0.05 ± 0.63  0.22 ± 0.58\\t   \n",
       "2     Qwen2-7B-Instruct       0.87 ± 0.34\\t    0.23 ± 0.67  0.38 ± 0.72\\t   \n",
       "3         gpt-3.5-turbo       0.85 ± 0.36\\t     0.1 ± 0.62    0.38 ± 0.74   \n",
       "4           gpt-4-turbo       0.83 ± 0.37\\t    0.01 ± 0.58    0.42 ± 0.78   \n",
       "5           gpt-4o-mini       0.87 ± 0.33\\t    0.14 ± 0.61  0.38 ± 0.74\\t   \n",
       "6     Gemma-7B-Instruct         0.79 ± 0.41    0.19 ± 0.76    0.25 ± 0.56   \n",
       "7        gemini-1.5-pro                 NaN    0.03 ± 0.64     0.33 ± 0.7   \n",
       "\n",
       "          BLEU           R1           R2           RL       METEOR  \\\n",
       "0  0.01 ± 0.01  0.09 ± 0.08  0.01 ± 0.04  0.09 ± 0.07  0.11 ± 0.09   \n",
       "1  0.01 ± 0.02  0.11 ± 0.09  0.02 ± 0.04   0.1 ± 0.08  0.12 ± 0.09   \n",
       "2  0.01 ± 0.01  0.09 ± 0.06  0.01 ± 0.03  0.08 ± 0.06  0.12 ± 0.09   \n",
       "3  0.01 ± 0.01  0.11 ± 0.08  0.02 ± 0.04   0.1 ± 0.07   0.13 ± 0.1   \n",
       "4  0.01 ± 0.01  0.11 ± 0.08  0.02 ± 0.04   0.1 ± 0.08   0.13 ± 0.1   \n",
       "5  0.01 ± 0.01   0.1 ± 0.06  0.01 ± 0.03   0.1 ± 0.06  0.16 ± 0.09   \n",
       "6  0.01 ± 0.01  0.09 ± 0.08  0.01 ± 0.04  0.09 ± 0.07   0.12 ± 0.1   \n",
       "7          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "  BERTScore_Prec  ...  IDF Overlap Persona Distance response_time  \\\n",
       "0     0.8 ± 0.18  ...  0.07 ± 0.08       0.54 ± 0.2    6.9 ± 1.61   \n",
       "1    0.84 ± 0.07  ...  0.07 ± 0.08      0.58 ± 0.13   8.17 ± 0.11   \n",
       "2    0.82 ± 0.08  ...  0.08 ± 0.07      0.63 ± 0.13    4.7 ± 0.94   \n",
       "3    0.84 ± 0.03  ...  0.08 ± 0.08       0.6 ± 0.13     1.4 ± 0.3   \n",
       "4    0.84 ± 0.02  ...  0.08 ± 0.07      0.59 ± 0.12   4.81 ± 1.45   \n",
       "5    0.83 ± 0.04  ...  0.09 ± 0.07      0.64 ± 0.11    2.2 ± 0.67   \n",
       "6    0.75 ± 0.26  ...  0.12 ± 0.13      0.57 ± 0.24   8.64 ± 1.59   \n",
       "7    0.83 ± 0.08  ...          NaN      0.58 ± 0.15   4.83 ± 3.46   \n",
       "\n",
       "  Failure Ratio UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  0.046 ± 0.00           0.9 ± 0.2       0.83 ± 0.32          1.98 ± 1.22   \n",
       "1  0.006 ± 0.00          0.94 ± 0.1        0.8 ± 0.32          1.81 ± 1.07   \n",
       "2  0.008 ± 0.00          0.93 ± 0.1       0.87 ± 0.25          2.96 ± 1.22   \n",
       "3  0.001 ± 0.00         0.96 ± 0.03       0.87 ± 0.25          2.28 ± 0.95   \n",
       "4    0.0 ± 0.00         0.96 ± 0.02       0.91 ± 0.21           2.21 ± 0.9   \n",
       "5  0.002 ± 0.00         0.95 ± 0.04       0.96 ± 0.13          3.17 ± 1.02   \n",
       "6  0.105 ± 0.00         0.85 ± 0.29        0.73 ± 0.4          2.42 ± 1.38   \n",
       "7  0.008 ± 0.00         0.94 ± 0.09        0.9 ± 0.23          2.67 ± 1.28   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.63 ± 0.44                 0.9 ± 0.2     1.05 ± 0.34  \n",
       "1          0.66 ± 0.41                0.93 ± 0.1     1.03 ± 0.25  \n",
       "2          0.84 ± 0.32               0.93 ± 0.11     1.31 ± 0.28  \n",
       "3          0.72 ± 0.39               0.96 ± 0.03     1.16 ± 0.21  \n",
       "4          0.78 ± 0.34               0.96 ± 0.03     1.16 ± 0.19  \n",
       "5          0.91 ± 0.23               0.95 ± 0.04     1.39 ± 0.22  \n",
       "6          0.74 ± 0.41               0.85 ± 0.29     1.12 ± 0.45  \n",
       "7          0.76 ± 0.37               0.94 ± 0.09     1.24 ± 0.29  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the existing Excel file and update or append the average row\n",
    "output_path = f'../Evaluations/{Dataset}{COT_}-results.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing data\n",
    "    existing_df = pd.read_excel(output_path)\n",
    "    \n",
    "    # Check if the model name already exists\n",
    "    if LLM_name in existing_df['Model'].values:\n",
    "        # Update the row by appending the new columns\n",
    "        existing_index = existing_df.loc[existing_df['Model'] == LLM_name].index[0]\n",
    "        for col in result_df.columns:\n",
    "            if col not in existing_df.columns:\n",
    "                existing_df[col] = None  # Add new column if missing\n",
    "            existing_df.at[existing_index, col] = result_df[col].values[0]  # Update column values\n",
    "    else:\n",
    "        # Append the new data\n",
    "        existing_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new DataFrame\n",
    "    existing_df = result_df\n",
    "\n",
    "# # Save the updated DataFrame to an Excel file\n",
    "existing_df.to_excel(output_path, index=False)\n",
    "\n",
    "existing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>...</th>\n",
       "      <th>IDF Overlap</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral-7B-Instruct</td>\n",
       "      <td>0.79 ± 0.41</td>\n",
       "      <td>0.02 ± 0.67\\t</td>\n",
       "      <td>0.31 ± 0.67</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.08</td>\n",
       "      <td>0.01 ± 0.04</td>\n",
       "      <td>0.09 ± 0.07</td>\n",
       "      <td>0.11 ± 0.09</td>\n",
       "      <td>0.8 ± 0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.08</td>\n",
       "      <td>0.54 ± 0.2</td>\n",
       "      <td>6.9 ± 1.61</td>\n",
       "      <td>0.046 ± 0.00</td>\n",
       "      <td>0.9 ± 0.2</td>\n",
       "      <td>0.83 ± 0.32</td>\n",
       "      <td>1.98 ± 1.22</td>\n",
       "      <td>0.63 ± 0.44</td>\n",
       "      <td>0.9 ± 0.2</td>\n",
       "      <td>1.05 ± 0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama3-1-8B-Instruct</td>\n",
       "      <td>0.83 ± 0.38\\t</td>\n",
       "      <td>0.05 ± 0.63</td>\n",
       "      <td>0.22 ± 0.58\\t</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.11 ± 0.09</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.1 ± 0.08</td>\n",
       "      <td>0.12 ± 0.09</td>\n",
       "      <td>0.84 ± 0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.08</td>\n",
       "      <td>0.58 ± 0.13</td>\n",
       "      <td>8.17 ± 0.11</td>\n",
       "      <td>0.006 ± 0.00</td>\n",
       "      <td>0.94 ± 0.1</td>\n",
       "      <td>0.8 ± 0.32</td>\n",
       "      <td>1.81 ± 1.07</td>\n",
       "      <td>0.66 ± 0.41</td>\n",
       "      <td>0.93 ± 0.1</td>\n",
       "      <td>1.03 ± 0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.87 ± 0.34\\t</td>\n",
       "      <td>0.23 ± 0.67</td>\n",
       "      <td>0.38 ± 0.72\\t</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.06</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.08 ± 0.06</td>\n",
       "      <td>0.12 ± 0.09</td>\n",
       "      <td>0.82 ± 0.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.07</td>\n",
       "      <td>0.63 ± 0.13</td>\n",
       "      <td>4.7 ± 0.94</td>\n",
       "      <td>0.008 ± 0.00</td>\n",
       "      <td>0.93 ± 0.1</td>\n",
       "      <td>0.87 ± 0.25</td>\n",
       "      <td>2.96 ± 1.22</td>\n",
       "      <td>0.84 ± 0.32</td>\n",
       "      <td>0.93 ± 0.11</td>\n",
       "      <td>1.31 ± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.85 ± 0.36\\t</td>\n",
       "      <td>0.1 ± 0.62</td>\n",
       "      <td>0.38 ± 0.74</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.1 ± 0.07</td>\n",
       "      <td>0.13 ± 0.1</td>\n",
       "      <td>0.84 ± 0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.08</td>\n",
       "      <td>0.6 ± 0.13</td>\n",
       "      <td>1.4 ± 0.3</td>\n",
       "      <td>0.001 ± 0.00</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>0.87 ± 0.25</td>\n",
       "      <td>2.28 ± 0.95</td>\n",
       "      <td>0.72 ± 0.39</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>1.16 ± 0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>0.83 ± 0.37\\t</td>\n",
       "      <td>0.01 ± 0.58</td>\n",
       "      <td>0.42 ± 0.78</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.1 ± 0.08</td>\n",
       "      <td>0.13 ± 0.1</td>\n",
       "      <td>0.84 ± 0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.07</td>\n",
       "      <td>0.59 ± 0.12</td>\n",
       "      <td>4.81 ± 1.45</td>\n",
       "      <td>0.0 ± 0.00</td>\n",
       "      <td>0.96 ± 0.02</td>\n",
       "      <td>0.91 ± 0.21</td>\n",
       "      <td>2.21 ± 0.9</td>\n",
       "      <td>0.78 ± 0.34</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>1.16 ± 0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.87 ± 0.33\\t</td>\n",
       "      <td>0.14 ± 0.61</td>\n",
       "      <td>0.38 ± 0.74\\t</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.1 ± 0.06</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.1 ± 0.06</td>\n",
       "      <td>0.16 ± 0.09</td>\n",
       "      <td>0.83 ± 0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09 ± 0.07</td>\n",
       "      <td>0.64 ± 0.11</td>\n",
       "      <td>2.2 ± 0.67</td>\n",
       "      <td>0.002 ± 0.00</td>\n",
       "      <td>0.95 ± 0.04</td>\n",
       "      <td>0.96 ± 0.13</td>\n",
       "      <td>3.17 ± 1.02</td>\n",
       "      <td>0.91 ± 0.23</td>\n",
       "      <td>0.95 ± 0.04</td>\n",
       "      <td>1.39 ± 0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gemma-7B-Instruct</td>\n",
       "      <td>0.79 ± 0.41</td>\n",
       "      <td>0.19 ± 0.76</td>\n",
       "      <td>0.25 ± 0.56</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.08</td>\n",
       "      <td>0.01 ± 0.04</td>\n",
       "      <td>0.09 ± 0.07</td>\n",
       "      <td>0.12 ± 0.1</td>\n",
       "      <td>0.75 ± 0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12 ± 0.13</td>\n",
       "      <td>0.57 ± 0.24</td>\n",
       "      <td>8.64 ± 1.59</td>\n",
       "      <td>0.105 ± 0.00</td>\n",
       "      <td>0.85 ± 0.29</td>\n",
       "      <td>0.73 ± 0.4</td>\n",
       "      <td>2.42 ± 1.38</td>\n",
       "      <td>0.74 ± 0.41</td>\n",
       "      <td>0.85 ± 0.29</td>\n",
       "      <td>1.12 ± 0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini-1.5-pro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03 ± 0.64</td>\n",
       "      <td>0.33 ± 0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.83 ± 0.08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.58 ± 0.15</td>\n",
       "      <td>4.83 ± 3.46</td>\n",
       "      <td>0.008 ± 0.00</td>\n",
       "      <td>0.94 ± 0.09</td>\n",
       "      <td>0.9 ± 0.23</td>\n",
       "      <td>2.67 ± 1.28</td>\n",
       "      <td>0.76 ± 0.37</td>\n",
       "      <td>0.94 ± 0.09</td>\n",
       "      <td>1.24 ± 0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model P Consistency Score        C Score       UE Score  \\\n",
       "0   Mistral-7B-Instruct         0.79 ± 0.41  0.02 ± 0.67\\t    0.31 ± 0.67   \n",
       "1  Llama3-1-8B-Instruct       0.83 ± 0.38\\t    0.05 ± 0.63  0.22 ± 0.58\\t   \n",
       "2     Qwen2-7B-Instruct       0.87 ± 0.34\\t    0.23 ± 0.67  0.38 ± 0.72\\t   \n",
       "3         gpt-3.5-turbo       0.85 ± 0.36\\t     0.1 ± 0.62    0.38 ± 0.74   \n",
       "4           gpt-4-turbo       0.83 ± 0.37\\t    0.01 ± 0.58    0.42 ± 0.78   \n",
       "5           gpt-4o-mini       0.87 ± 0.33\\t    0.14 ± 0.61  0.38 ± 0.74\\t   \n",
       "6     Gemma-7B-Instruct         0.79 ± 0.41    0.19 ± 0.76    0.25 ± 0.56   \n",
       "7        gemini-1.5-pro                 NaN    0.03 ± 0.64     0.33 ± 0.7   \n",
       "\n",
       "          BLEU           R1           R2           RL       METEOR  \\\n",
       "0  0.01 ± 0.01  0.09 ± 0.08  0.01 ± 0.04  0.09 ± 0.07  0.11 ± 0.09   \n",
       "1  0.01 ± 0.02  0.11 ± 0.09  0.02 ± 0.04   0.1 ± 0.08  0.12 ± 0.09   \n",
       "2  0.01 ± 0.01  0.09 ± 0.06  0.01 ± 0.03  0.08 ± 0.06  0.12 ± 0.09   \n",
       "3  0.01 ± 0.01  0.11 ± 0.08  0.02 ± 0.04   0.1 ± 0.07   0.13 ± 0.1   \n",
       "4  0.01 ± 0.01  0.11 ± 0.08  0.02 ± 0.04   0.1 ± 0.08   0.13 ± 0.1   \n",
       "5  0.01 ± 0.01   0.1 ± 0.06  0.01 ± 0.03   0.1 ± 0.06  0.16 ± 0.09   \n",
       "6  0.01 ± 0.01  0.09 ± 0.08  0.01 ± 0.04  0.09 ± 0.07   0.12 ± 0.1   \n",
       "7          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "  BERTScore_Prec  ...  IDF Overlap Persona Distance response_time  \\\n",
       "0     0.8 ± 0.18  ...  0.07 ± 0.08       0.54 ± 0.2    6.9 ± 1.61   \n",
       "1    0.84 ± 0.07  ...  0.07 ± 0.08      0.58 ± 0.13   8.17 ± 0.11   \n",
       "2    0.82 ± 0.08  ...  0.08 ± 0.07      0.63 ± 0.13    4.7 ± 0.94   \n",
       "3    0.84 ± 0.03  ...  0.08 ± 0.08       0.6 ± 0.13     1.4 ± 0.3   \n",
       "4    0.84 ± 0.02  ...  0.08 ± 0.07      0.59 ± 0.12   4.81 ± 1.45   \n",
       "5    0.83 ± 0.04  ...  0.09 ± 0.07      0.64 ± 0.11    2.2 ± 0.67   \n",
       "6    0.75 ± 0.26  ...  0.12 ± 0.13      0.57 ± 0.24   8.64 ± 1.59   \n",
       "7    0.83 ± 0.08  ...          NaN      0.58 ± 0.15   4.83 ± 3.46   \n",
       "\n",
       "  Failure Ratio UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  0.046 ± 0.00           0.9 ± 0.2       0.83 ± 0.32          1.98 ± 1.22   \n",
       "1  0.006 ± 0.00          0.94 ± 0.1        0.8 ± 0.32          1.81 ± 1.07   \n",
       "2  0.008 ± 0.00          0.93 ± 0.1       0.87 ± 0.25          2.96 ± 1.22   \n",
       "3  0.001 ± 0.00         0.96 ± 0.03       0.87 ± 0.25          2.28 ± 0.95   \n",
       "4    0.0 ± 0.00         0.96 ± 0.02       0.91 ± 0.21           2.21 ± 0.9   \n",
       "5  0.002 ± 0.00         0.95 ± 0.04       0.96 ± 0.13          3.17 ± 1.02   \n",
       "6  0.105 ± 0.00         0.85 ± 0.29        0.73 ± 0.4          2.42 ± 1.38   \n",
       "7  0.008 ± 0.00         0.94 ± 0.09        0.9 ± 0.23          2.67 ± 1.28   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.63 ± 0.44                 0.9 ± 0.2     1.05 ± 0.34  \n",
       "1          0.66 ± 0.41                0.93 ± 0.1     1.03 ± 0.25  \n",
       "2          0.84 ± 0.32               0.93 ± 0.11     1.31 ± 0.28  \n",
       "3          0.72 ± 0.39               0.96 ± 0.03     1.16 ± 0.21  \n",
       "4          0.78 ± 0.34               0.96 ± 0.03     1.16 ± 0.19  \n",
       "5          0.91 ± 0.23               0.95 ± 0.04     1.39 ± 0.22  \n",
       "6          0.74 ± 0.41               0.85 ± 0.29     1.12 ± 0.45  \n",
       "7          0.76 ± 0.37               0.94 ± 0.09     1.24 ± 0.29  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_excel(f'../Evaluations/{Dataset}{COT_}-results.xlsx')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persoagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 54.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation scores are shown below:\n",
      "+-------------------+----------+\n",
      "|     Dimensions    |  Score   |\n",
      "+-------------------+----------+\n",
      "|    naturalness    | 0.950217 |\n",
      "|     coherence     | 0.973135 |\n",
      "|    engagingness   | 1.750486 |\n",
      "|    groundedness   | 0.999566 |\n",
      "| understandability | 0.946209 |\n",
      "|      overall      | 1.123923 |\n",
      "+-------------------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'dialogue'\n",
    "\n",
    "# a list of dialogue histories\n",
    "src_list = ['hi , do you know much about the internet ? \\n i know a lot about different sites and some website design , how about you ? \\n\\n']\n",
    "# a list of additional context that should be included into the generated response\n",
    "context_list = ['the 3 horizontal line menu on apps and websites is called a hamburger button .\\n']\n",
    "# a list of model outputs to be evaluated\n",
    "output_list = ['i do too . did you know the 3 horizontal line menu on apps and websites is called the hamburger button ?']\n",
    "\n",
    "# Prepare data for pre-trained evaluators\n",
    "data = convert_to_json(output_list=output_list, \n",
    "                       src_list=src_list, context_list=context_list)\n",
    "# Initialize evaluator for a specific task\n",
    "evaluator = get_evaluator(task)\n",
    "# Get multi-dimensional evaluation scores\n",
    "eval_scores = evaluator.evaluate(data, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 42.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for example 1: {'naturalness': 0.9502174201360719, 'coherence': 0.9731347836152868, 'engagingness': 1.7504860805525295, 'groundedness': 0.9995656267195939, 'understandability': 0.9462095037239142, 'overall': 1.1239226829494793}\n",
      "Scores for example 2: {'naturalness': 0.9675946477090701, 'coherence': 0.998674558536015, 'engagingness': 1.9936029005678884, 'groundedness': 0.9857853472625128, 'understandability': 0.9632170362278318, 'overall': 1.1817748980606635}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'dialogue'\n",
    "\n",
    "# Batch inputs: multiple dialogue histories, contexts, and model outputs\n",
    "src_list = [\n",
    "    'hi , do you know much about the internet ? \\n i know a lot about different sites and some website design , how about you ? \\n\\n',\n",
    "    'what is your favorite color ? \\n i like blue a lot , but sometimes i prefer green . \\n\\n'\n",
    "]\n",
    "context_list = [\n",
    "    'the 3 horizontal line menu on apps and websites is called a hamburger button .\\n',\n",
    "    'colors can reflect your mood and personality .\\n'\n",
    "]\n",
    "output_list = [\n",
    "    'i do too . did you know the 3 horizontal line menu on apps and websites is called the hamburger button ?',\n",
    "    'i like blue as well . it is calming and reminds me of the ocean .'\n",
    "]\n",
    "\n",
    "# Prepare data for pre-trained evaluators\n",
    "data = convert_to_json(output_list=output_list, \n",
    "                       src_list=src_list, context_list=context_list)\n",
    "\n",
    "# Initialize evaluator for a specific task\n",
    "evaluator = get_evaluator(task)\n",
    "\n",
    "# Get multi-dimensional evaluation scores for the batch\n",
    "eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "# Display scores\n",
    "for i, score in enumerate(eval_scores):\n",
    "    print(f\"Scores for example {i + 1}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'naturalness': 0.9502174201360719,\n",
       "  'coherence': 0.9731347836152868,\n",
       "  'engagingness': 1.7504860805525295,\n",
       "  'groundedness': 0.9995656267195939,\n",
       "  'understandability': 0.9462095037239142,\n",
       "  'overall': 1.1239226829494793},\n",
       " {'naturalness': 0.9675946477090701,\n",
       "  'coherence': 0.998674558536015,\n",
       "  'engagingness': 1.9936029005678884,\n",
       "  'groundedness': 0.9857853472625128,\n",
       "  'understandability': 0.9632170362278318,\n",
       "  'overall': 1.1817748980606635}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Generation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = \"FoCus\"                                # Synthetic-PersonaChat, Blended Skill Talk, PEC, ConvAI2, FoCus, IT-ConvAI2\n",
    "LLM_name = \"Gemma-7B-Instruct\"                                # Mistral-7B-Instruct, Llama3-1-8B-Instruct, Qwen2-7B-Instruct,  Gemma-7B-Instruct, gpt-3.5-turbo, gpt-4-turbo, gpt-4o-mini\n",
    "COT_SETUP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: Sure, you will like to know that this p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>User2: Technische Universität Darmstadt in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>User2: I suggest a place, for your wish of see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: The history of the house you are intere...  \n",
       "1  User2: This house was use as a stop for slaves...  \n",
       "2  User2: Sure, you will like to know that this p...  \n",
       "3  User2: Technische Universität Darmstadt in the...  \n",
       "4  User2: I suggest a place, for your wish of see...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'../Prompts/{Dataset}.csv')\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FoCus'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas        0\n",
      "context         0\n",
      "act_response    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>act_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: The history of the house you are intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: This house was use as a stop for slaves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>User2: Sure, you will like to know that this p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>User2: Technische Universität Darmstadt in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>User2: I suggest a place, for your wish of see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I would like to go to University.I live in Mic...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>User2: They offer 132 bachelors degree program...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "5  I would like to go to University.I live in Mic...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "5  User1: I think Ive been there before but I don...   \n",
       "\n",
       "                                        act_response  \n",
       "0  User2: The history of the house you are intere...  \n",
       "1  User2: This house was use as a stop for slaves...  \n",
       "2  User2: Sure, you will like to know that this p...  \n",
       "3  User2: Technische Universität Darmstadt in the...  \n",
       "4  User2: I suggest a place, for your wish of see...  \n",
       "5  User2: They offer 132 bachelors degree program...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Only For: Blended Skill Talk\n",
    "if Dataset == \"Blended Skill Talk\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[User 1 persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "# ### Only For: PEC\n",
    "if Dataset == \"PEC\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[Responder persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 2)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     150\n",
      "response_time      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Nazareth House is a place you would enjoy ...</td>\n",
       "      <td>9.720944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This house is definitely one of the ones I wou...</td>\n",
       "      <td>8.374085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think you would definitely love this place, ...</td>\n",
       "      <td>7.135097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello! I'm glad you're interested in Technisch...</td>\n",
       "      <td>11.084497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.350121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>The museum come pharmacy in which you are work...</td>\n",
       "      <td>9.927329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>This is a fascinating archaeological site, Mah...</td>\n",
       "      <td>11.045374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Hello! This is Armagh County Museum. It is a m...</td>\n",
       "      <td>11.122940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Nyanga National Park is a perfect place for yo...</td>\n",
       "      <td>8.307516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>This is Hadrians Wall, an ancient fortificatio...</td>\n",
       "      <td>10.772249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          gen_response  response_time\n",
       "0    The Nazareth House is a place you would enjoy ...       9.720944\n",
       "1    This house is definitely one of the ones I wou...       8.374085\n",
       "2    I think you would definitely love this place, ...       7.135097\n",
       "3    Hello! I'm glad you're interested in Technisch...      11.084497\n",
       "4                                                  NaN       9.350121\n",
       "..                                                 ...            ...\n",
       "995  The museum come pharmacy in which you are work...       9.927329\n",
       "996  This is a fascinating archaeological site, Mah...      11.045374\n",
       "997  Hello! This is Armagh County Museum. It is a m...      11.122940\n",
       "998  Nyanga National Park is a perfect place for yo...       8.307516\n",
       "999  This is Hadrians Wall, an ancient fortificatio...      10.772249\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COT_ = \"-COT\" if COT_SETUP else \"\"\n",
    " \n",
    "response = pd.read_csv(f'../Responses/{Dataset}/{LLM_name}{COT_}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 117\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas           0\n",
      "context            0\n",
      "gen_response     150\n",
      "response_time      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would like to visit the Nazareth House again...</td>\n",
       "      <td>User1: I think Ive been there before but I don...</td>\n",
       "      <td>The Nazareth House is a place you would enjoy ...</td>\n",
       "      <td>9.720944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been to Vermont a few times to go skiin...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>This house is definitely one of the ones I wou...</td>\n",
       "      <td>8.374085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am fascinated by the Spanish Colonial Reviva...</td>\n",
       "      <td>User1: Wow, this is amazing! What is this?\\nUs...</td>\n",
       "      <td>I think you would definitely love this place, ...</td>\n",
       "      <td>7.135097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to become a college student.I want to s...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: Hello! Wel...</td>\n",
       "      <td>Hello! I'm glad you're interested in Technisch...</td>\n",
       "      <td>11.084497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to visit england.I love church.I would ...</td>\n",
       "      <td>User1: Where is this place?\\nUser2: This place...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.350121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  I would like to visit the Nazareth House again...   \n",
       "1  I have been to Vermont a few times to go skiin...   \n",
       "2  I am fascinated by the Spanish Colonial Reviva...   \n",
       "3  I want to become a college student.I want to s...   \n",
       "4  I like to visit england.I love church.I would ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: I think Ive been there before but I don...   \n",
       "1  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "2  User1: Wow, this is amazing! What is this?\\nUs...   \n",
       "3  User1: Where is this place?\\nUser2: Hello! Wel...   \n",
       "4  User1: Where is this place?\\nUser2: This place...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  The Nazareth House is a place you would enjoy ...       9.720944  \n",
       "1  This house is definitely one of the ones I wou...       8.374085  \n",
       "2  I think you would definitely love this place, ...       7.135097  \n",
       "3  Hello! I'm glad you're interested in Technisch...      11.084497  \n",
       "4                                                NaN       9.350121  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'context': df['context'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU\n",
    "# device = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finalized Input Mapping:**\n",
    "\n",
    "- src_list: Use the context column (conversation history).\n",
    "- context_list: Use the flattened and cleaned persona column.\n",
    "- output_list: Use the gen_response (the response your model generates).\n",
    "\n",
    "**Note:**\n",
    "\n",
    "The act_response (true or reference response) is not required as an input for the UniEval evaluation process because UniEval evaluates the generated response (gen_response) based on how well it fits the provided context (conversation history) and additional persona information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "def calculate_unieval_scores(personas, contexts, gen_responses):\n",
    "    \"\"\"\n",
    "    Calculates UniEval scores for a batch of inputs.\n",
    "\n",
    "    Args:\n",
    "        personas (list): List of persona information as additional context.\n",
    "        contexts (list): List of conversation histories leading to the responses.\n",
    "        gen_responses (list): List of generated responses to be evaluated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing UniEval scores for each input.\n",
    "    \"\"\"\n",
    "    # Flatten personas if they are lists\n",
    "    personas = [' '.join(p) if isinstance(p, list) else p for p in personas]\n",
    "\n",
    "    # Prepare inputs for UniEval\n",
    "    data = convert_to_json(output_list=gen_responses, src_list=contexts, context_list=personas)\n",
    "\n",
    "    # Initialize the evaluator for dialogue tasks\n",
    "    evaluator = get_evaluator('dialogue')\n",
    "\n",
    "    # Evaluate and obtain scores for all inputs\n",
    "    eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "    return eval_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the worst UniEval score as a dictionary\n",
    "worst_unieval_score = {\n",
    "    'naturalness': 0.0,\n",
    "    'coherence': 0.0,\n",
    "    'engagingness': 0.0,\n",
    "    'groundedness': 0.0,\n",
    "    'understandability': 0.0,\n",
    "    'overall': 0.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating batches:   0%|          | 0/5 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Function to evaluate in batches or the entire DataFrame\n",
    "batch_size = 200  # Adjust batch size as needed\n",
    "\n",
    "# List to store all UniEval scores\n",
    "all_unieval_scores = []\n",
    "\n",
    "# Split into batches if necessary\n",
    "for i in tqdm(range(0, len(eval_df), batch_size), desc=\"Evaluating batches\"):\n",
    "    batch = eval_df.iloc[i:i+batch_size]\n",
    "\n",
    "    # Extract relevant fields from the batch\n",
    "    personas = batch['personas'].tolist()\n",
    "    contexts = batch['context'].tolist()\n",
    "    gen_responses = batch['gen_response'].tolist()\n",
    "\n",
    "    # Check for NaN responses and handle them\n",
    "    valid_indices = [j for j, response in enumerate(gen_responses) if pd.notna(response) and response.strip() != '']\n",
    "    invalid_indices = [j for j, response in enumerate(gen_responses) if j not in valid_indices]\n",
    "\n",
    "    # Prepare valid inputs\n",
    "    valid_personas = [personas[j] for j in valid_indices]\n",
    "    valid_contexts = [contexts[j] for j in valid_indices]\n",
    "    valid_gen_responses = [gen_responses[j] for j in valid_indices]\n",
    "\n",
    "    # Evaluate valid inputs\n",
    "    if valid_personas:\n",
    "        eval_scores = calculate_unieval_scores(valid_personas, valid_contexts, valid_gen_responses)\n",
    "        all_unieval_scores.extend(eval_scores)\n",
    "\n",
    "    # Append worst scores for invalid inputs\n",
    "    all_unieval_scores.extend([worst_unieval_score] * len(invalid_indices))\n",
    "\n",
    "# Convert all scores into a DataFrame\n",
    "metrics_df = pd.DataFrame(all_unieval_scores)\n",
    "\n",
    "# Rename columns for clarity\n",
    "metrics_df.columns = [\n",
    "    \"UniEval Naturalness\",\n",
    "    \"UniEval Coherence\",\n",
    "    \"UniEval Engagingness\",\n",
    "    \"UniEval Groundedness\",\n",
    "    \"UniEval Understandability\",\n",
    "    \"UniEval Overall\"\n",
    "]\n",
    "\n",
    "# Combine with original DataFrame if needed\n",
    "eval_df = pd.concat([eval_df.reset_index(drop=True), metrics_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean (average) and standard deviation, rounded to 2 decimal places\n",
    "avg_values = metrics_df.mean().round(2)\n",
    "std_values = metrics_df.std(ddof=0).round(2)  # Use ddof=0 for population standard deviation\n",
    "\n",
    "# Combine the average and standard deviation into the format \"avg ± std\"\n",
    "combined_values = avg_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "\n",
    "# Insert the LLM name at the beginning of the combined values\n",
    "combined_values = combined_values.tolist()\n",
    "combined_values.insert(0, LLM_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gemma-7B-Instruct</td>\n",
       "      <td>0.54 ± 0.46</td>\n",
       "      <td>0.57 ± 0.49</td>\n",
       "      <td>2.1 ± 1.97</td>\n",
       "      <td>0.55 ± 0.49</td>\n",
       "      <td>0.54 ± 0.46</td>\n",
       "      <td>0.86 ± 0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model UniEval Naturalness UniEval Coherence  \\\n",
       "0  Gemma-7B-Instruct         0.54 ± 0.46       0.57 ± 0.49   \n",
       "\n",
       "  UniEval Engagingness UniEval Groundedness UniEval Understandability  \\\n",
       "0           2.1 ± 1.97          0.55 ± 0.49               0.54 ± 0.46   \n",
       "\n",
       "  UniEval Overall  \n",
       "0     0.86 ± 0.76  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for the combined average ± std row\n",
    "result_df = pd.DataFrame([combined_values], columns=['Model'] + metrics_df.columns.tolist())\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>...</th>\n",
       "      <th>IDF Overlap</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama3-1-8B-Instruct</td>\n",
       "      <td>0.49 ± 0.5</td>\n",
       "      <td>-0.22 ± 0.87</td>\n",
       "      <td>0.17 ± 0.48\\t</td>\n",
       "      <td>0.02 ± 0.08</td>\n",
       "      <td>0.11 ± 0.15</td>\n",
       "      <td>0.03 ± 0.1</td>\n",
       "      <td>0.1 ± 0.14</td>\n",
       "      <td>0.11 ± 0.14</td>\n",
       "      <td>0.47 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.1</td>\n",
       "      <td>0.33 ± 0.33</td>\n",
       "      <td>4.54 ± 0.21</td>\n",
       "      <td>0.448 ± 0.00</td>\n",
       "      <td>0.51 ± 0.46</td>\n",
       "      <td>0.55 ± 0.49</td>\n",
       "      <td>1.71 ± 1.88</td>\n",
       "      <td>0.42 ± 0.47</td>\n",
       "      <td>0.51 ± 0.46</td>\n",
       "      <td>0.74 ± 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.82 ± 0.39</td>\n",
       "      <td>0.26 ± 0.75</td>\n",
       "      <td>0.37 ± 0.67</td>\n",
       "      <td>0.04 ± 0.09</td>\n",
       "      <td>0.2 ± 0.14</td>\n",
       "      <td>0.06 ± 0.12</td>\n",
       "      <td>0.18 ± 0.14</td>\n",
       "      <td>0.2 ± 0.15</td>\n",
       "      <td>0.78 ± 0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.07</td>\n",
       "      <td>0.51 ± 0.21</td>\n",
       "      <td>1.3 ± 0.42</td>\n",
       "      <td>0.09 ± 0.00</td>\n",
       "      <td>0.84 ± 0.27</td>\n",
       "      <td>0.91 ± 0.29</td>\n",
       "      <td>2.31 ± 1.27</td>\n",
       "      <td>0.72 ± 0.39</td>\n",
       "      <td>0.84 ± 0.27</td>\n",
       "      <td>1.12 ± 0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.81 ± 0.39\\t</td>\n",
       "      <td>0.16 ± 0.71</td>\n",
       "      <td>0.35 ± 0.69</td>\n",
       "      <td>0.03 ± 0.05</td>\n",
       "      <td>0.19 ± 0.11</td>\n",
       "      <td>0.06 ± 0.08</td>\n",
       "      <td>0.17 ± 0.1</td>\n",
       "      <td>0.22 ± 0.15</td>\n",
       "      <td>0.78 ± 0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.05</td>\n",
       "      <td>0.54 ± 0.19</td>\n",
       "      <td>1.43 ± 0.66</td>\n",
       "      <td>0.086 ± 0.00</td>\n",
       "      <td>0.85 ± 0.27</td>\n",
       "      <td>0.91 ± 0.28</td>\n",
       "      <td>2.61 ± 1.2</td>\n",
       "      <td>0.72 ± 0.36</td>\n",
       "      <td>0.86 ± 0.26</td>\n",
       "      <td>1.19 ± 0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>0.84 ± 0.36</td>\n",
       "      <td>0.14 ± 0.66</td>\n",
       "      <td>0.39 ± 0.73</td>\n",
       "      <td>0.04 ± 0.08</td>\n",
       "      <td>0.23 ± 0.13</td>\n",
       "      <td>0.08 ± 0.11</td>\n",
       "      <td>0.2 ± 0.13</td>\n",
       "      <td>0.23 ± 0.16</td>\n",
       "      <td>0.84 ± 0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.05</td>\n",
       "      <td>0.51 ± 0.15</td>\n",
       "      <td>3.32 ± 1.24</td>\n",
       "      <td>0.035 ± 0.00</td>\n",
       "      <td>0.91 ± 0.18</td>\n",
       "      <td>0.96 ± 0.18</td>\n",
       "      <td>2.2 ± 0.94</td>\n",
       "      <td>0.66 ± 0.38</td>\n",
       "      <td>0.91 ± 0.18</td>\n",
       "      <td>1.13 ± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.45 ± 0.5</td>\n",
       "      <td>-0.31 ± 0.84</td>\n",
       "      <td>0.17 ± 0.48</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.08 ± 0.09</td>\n",
       "      <td>0.1 ± 0.13</td>\n",
       "      <td>0.41 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04 ± 0.06</td>\n",
       "      <td>0.29 ± 0.3</td>\n",
       "      <td>3.74 ± 0.76</td>\n",
       "      <td>0.509 ± 0.00</td>\n",
       "      <td>0.46 ± 0.47</td>\n",
       "      <td>0.49 ± 0.5</td>\n",
       "      <td>1.72 ± 1.93</td>\n",
       "      <td>0.43 ± 0.47</td>\n",
       "      <td>0.46 ± 0.47</td>\n",
       "      <td>0.71 ± 0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mistral-7B-Instruct</td>\n",
       "      <td>0.52 ± 0.5\\t</td>\n",
       "      <td>-0.23 ± 0.82</td>\n",
       "      <td>0.21 ± 0.52</td>\n",
       "      <td>0.01 ± 0.04</td>\n",
       "      <td>0.11 ± 0.12</td>\n",
       "      <td>0.03 ± 0.06</td>\n",
       "      <td>0.1 ± 0.11</td>\n",
       "      <td>0.11 ± 0.14</td>\n",
       "      <td>0.48 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.07</td>\n",
       "      <td>0.3 ± 0.28</td>\n",
       "      <td>4.39 ± 0.36</td>\n",
       "      <td>0.435 ± 0.00</td>\n",
       "      <td>0.53 ± 0.46</td>\n",
       "      <td>0.56 ± 0.49</td>\n",
       "      <td>1.54 ± 1.55</td>\n",
       "      <td>0.45 ± 0.46</td>\n",
       "      <td>0.53 ± 0.46</td>\n",
       "      <td>0.72 ± 0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gemma-7B-Instruct</td>\n",
       "      <td>0.53 ± 0.5</td>\n",
       "      <td>-0.13 ± 0.89</td>\n",
       "      <td>0.22 ± 0.53</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.1</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.08 ± 0.09</td>\n",
       "      <td>0.09 ± 0.1</td>\n",
       "      <td>0.48 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.39 ± 0.34</td>\n",
       "      <td>5.17 ± 1.03</td>\n",
       "      <td>0.425 ± 0.00</td>\n",
       "      <td>0.54 ± 0.46</td>\n",
       "      <td>0.57 ± 0.49</td>\n",
       "      <td>2.1 ± 1.97</td>\n",
       "      <td>0.55 ± 0.49</td>\n",
       "      <td>0.54 ± 0.46</td>\n",
       "      <td>0.86 ± 0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model P Consistency Score       C Score       UE Score  \\\n",
       "0  Llama3-1-8B-Instruct          0.49 ± 0.5  -0.22 ± 0.87  0.17 ± 0.48\\t   \n",
       "1         gpt-3.5-turbo         0.82 ± 0.39   0.26 ± 0.75    0.37 ± 0.67   \n",
       "2           gpt-4o-mini       0.81 ± 0.39\\t   0.16 ± 0.71    0.35 ± 0.69   \n",
       "3           gpt-4-turbo         0.84 ± 0.36   0.14 ± 0.66    0.39 ± 0.73   \n",
       "4     Qwen2-7B-Instruct          0.45 ± 0.5  -0.31 ± 0.84    0.17 ± 0.48   \n",
       "5   Mistral-7B-Instruct        0.52 ± 0.5\\t  -0.23 ± 0.82    0.21 ± 0.52   \n",
       "6     Gemma-7B-Instruct          0.53 ± 0.5  -0.13 ± 0.89    0.22 ± 0.53   \n",
       "\n",
       "          BLEU           R1           R2           RL       METEOR  \\\n",
       "0  0.02 ± 0.08  0.11 ± 0.15   0.03 ± 0.1   0.1 ± 0.14  0.11 ± 0.14   \n",
       "1  0.04 ± 0.09   0.2 ± 0.14  0.06 ± 0.12  0.18 ± 0.14   0.2 ± 0.15   \n",
       "2  0.03 ± 0.05  0.19 ± 0.11  0.06 ± 0.08   0.17 ± 0.1  0.22 ± 0.15   \n",
       "3  0.04 ± 0.08  0.23 ± 0.13  0.08 ± 0.11   0.2 ± 0.13  0.23 ± 0.16   \n",
       "4  0.01 ± 0.02   0.08 ± 0.1  0.02 ± 0.04  0.08 ± 0.09   0.1 ± 0.13   \n",
       "5  0.01 ± 0.04  0.11 ± 0.12  0.03 ± 0.06   0.1 ± 0.11  0.11 ± 0.14   \n",
       "6  0.01 ± 0.01   0.09 ± 0.1  0.01 ± 0.03  0.08 ± 0.09   0.09 ± 0.1   \n",
       "\n",
       "  BERTScore_Prec  ...  IDF Overlap Persona Distance response_time  \\\n",
       "0    0.47 ± 0.42  ...   0.06 ± 0.1      0.33 ± 0.33   4.54 ± 0.21   \n",
       "1    0.78 ± 0.25  ...  0.07 ± 0.07      0.51 ± 0.21    1.3 ± 0.42   \n",
       "2    0.78 ± 0.24  ...  0.06 ± 0.05      0.54 ± 0.19   1.43 ± 0.66   \n",
       "3    0.84 ± 0.16  ...  0.05 ± 0.05      0.51 ± 0.15   3.32 ± 1.24   \n",
       "4    0.41 ± 0.42  ...  0.04 ± 0.06       0.29 ± 0.3   3.74 ± 0.76   \n",
       "5    0.48 ± 0.42  ...  0.05 ± 0.07       0.3 ± 0.28   4.39 ± 0.36   \n",
       "6    0.48 ± 0.42  ...   0.08 ± 0.1      0.39 ± 0.34   5.17 ± 1.03   \n",
       "\n",
       "  Failure Ratio UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  0.448 ± 0.00         0.51 ± 0.46       0.55 ± 0.49          1.71 ± 1.88   \n",
       "1   0.09 ± 0.00         0.84 ± 0.27       0.91 ± 0.29          2.31 ± 1.27   \n",
       "2  0.086 ± 0.00         0.85 ± 0.27       0.91 ± 0.28           2.61 ± 1.2   \n",
       "3  0.035 ± 0.00         0.91 ± 0.18       0.96 ± 0.18           2.2 ± 0.94   \n",
       "4  0.509 ± 0.00         0.46 ± 0.47        0.49 ± 0.5          1.72 ± 1.93   \n",
       "5  0.435 ± 0.00         0.53 ± 0.46       0.56 ± 0.49          1.54 ± 1.55   \n",
       "6  0.425 ± 0.00         0.54 ± 0.46       0.57 ± 0.49           2.1 ± 1.97   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.42 ± 0.47               0.51 ± 0.46      0.74 ± 0.7  \n",
       "1          0.72 ± 0.39               0.84 ± 0.27     1.12 ± 0.42  \n",
       "2          0.72 ± 0.36               0.86 ± 0.26     1.19 ± 0.41  \n",
       "3          0.66 ± 0.38               0.91 ± 0.18     1.13 ± 0.28  \n",
       "4          0.43 ± 0.47               0.46 ± 0.47     0.71 ± 0.75  \n",
       "5          0.45 ± 0.46               0.53 ± 0.46     0.72 ± 0.65  \n",
       "6          0.55 ± 0.49               0.54 ± 0.46     0.86 ± 0.76  \n",
       "\n",
       "[7 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the existing Excel file and update or append the average row\n",
    "output_path = f'../Evaluations/{Dataset}{COT_}-results.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing data\n",
    "    existing_df = pd.read_excel(output_path)\n",
    "    \n",
    "    # Check if the model name already exists\n",
    "    if LLM_name in existing_df['Model'].values:\n",
    "        # Update the row by appending the new columns\n",
    "        existing_index = existing_df.loc[existing_df['Model'] == LLM_name].index[0]\n",
    "        for col in result_df.columns:\n",
    "            if col not in existing_df.columns:\n",
    "                existing_df[col] = None  # Add new column if missing\n",
    "            existing_df.at[existing_index, col] = result_df[col].values[0]  # Update column values\n",
    "    else:\n",
    "        # Append the new data\n",
    "        existing_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new DataFrame\n",
    "    existing_df = result_df\n",
    "\n",
    "# # Save the updated DataFrame to an Excel file\n",
    "existing_df.to_excel(output_path, index=False)\n",
    "\n",
    "existing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>...</th>\n",
       "      <th>IDF Overlap</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama3-1-8B-Instruct</td>\n",
       "      <td>0.49 ± 0.5</td>\n",
       "      <td>-0.22 ± 0.87</td>\n",
       "      <td>0.17 ± 0.48\\t</td>\n",
       "      <td>0.02 ± 0.08</td>\n",
       "      <td>0.11 ± 0.15</td>\n",
       "      <td>0.03 ± 0.1</td>\n",
       "      <td>0.1 ± 0.14</td>\n",
       "      <td>0.11 ± 0.14</td>\n",
       "      <td>0.47 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.1</td>\n",
       "      <td>0.33 ± 0.33</td>\n",
       "      <td>4.54 ± 0.21</td>\n",
       "      <td>0.448 ± 0.00</td>\n",
       "      <td>0.51 ± 0.46</td>\n",
       "      <td>0.55 ± 0.49</td>\n",
       "      <td>1.71 ± 1.88</td>\n",
       "      <td>0.42 ± 0.47</td>\n",
       "      <td>0.51 ± 0.46</td>\n",
       "      <td>0.74 ± 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.82 ± 0.39</td>\n",
       "      <td>0.26 ± 0.75</td>\n",
       "      <td>0.37 ± 0.67</td>\n",
       "      <td>0.04 ± 0.09</td>\n",
       "      <td>0.2 ± 0.14</td>\n",
       "      <td>0.06 ± 0.12</td>\n",
       "      <td>0.18 ± 0.14</td>\n",
       "      <td>0.2 ± 0.15</td>\n",
       "      <td>0.78 ± 0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.07</td>\n",
       "      <td>0.51 ± 0.21</td>\n",
       "      <td>1.3 ± 0.42</td>\n",
       "      <td>0.09 ± 0.00</td>\n",
       "      <td>0.84 ± 0.27</td>\n",
       "      <td>0.91 ± 0.29</td>\n",
       "      <td>2.31 ± 1.27</td>\n",
       "      <td>0.72 ± 0.39</td>\n",
       "      <td>0.84 ± 0.27</td>\n",
       "      <td>1.12 ± 0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.81 ± 0.39\\t</td>\n",
       "      <td>0.16 ± 0.71</td>\n",
       "      <td>0.35 ± 0.69</td>\n",
       "      <td>0.03 ± 0.05</td>\n",
       "      <td>0.19 ± 0.11</td>\n",
       "      <td>0.06 ± 0.08</td>\n",
       "      <td>0.17 ± 0.1</td>\n",
       "      <td>0.22 ± 0.15</td>\n",
       "      <td>0.78 ± 0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.05</td>\n",
       "      <td>0.54 ± 0.19</td>\n",
       "      <td>1.43 ± 0.66</td>\n",
       "      <td>0.086 ± 0.00</td>\n",
       "      <td>0.85 ± 0.27</td>\n",
       "      <td>0.91 ± 0.28</td>\n",
       "      <td>2.61 ± 1.2</td>\n",
       "      <td>0.72 ± 0.36</td>\n",
       "      <td>0.86 ± 0.26</td>\n",
       "      <td>1.19 ± 0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>0.84 ± 0.36</td>\n",
       "      <td>0.14 ± 0.66</td>\n",
       "      <td>0.39 ± 0.73</td>\n",
       "      <td>0.04 ± 0.08</td>\n",
       "      <td>0.23 ± 0.13</td>\n",
       "      <td>0.08 ± 0.11</td>\n",
       "      <td>0.2 ± 0.13</td>\n",
       "      <td>0.23 ± 0.16</td>\n",
       "      <td>0.84 ± 0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.05</td>\n",
       "      <td>0.51 ± 0.15</td>\n",
       "      <td>3.32 ± 1.24</td>\n",
       "      <td>0.035 ± 0.00</td>\n",
       "      <td>0.91 ± 0.18</td>\n",
       "      <td>0.96 ± 0.18</td>\n",
       "      <td>2.2 ± 0.94</td>\n",
       "      <td>0.66 ± 0.38</td>\n",
       "      <td>0.91 ± 0.18</td>\n",
       "      <td>1.13 ± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.45 ± 0.5</td>\n",
       "      <td>-0.31 ± 0.84</td>\n",
       "      <td>0.17 ± 0.48</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.08 ± 0.09</td>\n",
       "      <td>0.1 ± 0.13</td>\n",
       "      <td>0.41 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04 ± 0.06</td>\n",
       "      <td>0.29 ± 0.3</td>\n",
       "      <td>3.74 ± 0.76</td>\n",
       "      <td>0.509 ± 0.00</td>\n",
       "      <td>0.46 ± 0.47</td>\n",
       "      <td>0.49 ± 0.5</td>\n",
       "      <td>1.72 ± 1.93</td>\n",
       "      <td>0.43 ± 0.47</td>\n",
       "      <td>0.46 ± 0.47</td>\n",
       "      <td>0.71 ± 0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mistral-7B-Instruct</td>\n",
       "      <td>0.52 ± 0.5\\t</td>\n",
       "      <td>-0.23 ± 0.82</td>\n",
       "      <td>0.21 ± 0.52</td>\n",
       "      <td>0.01 ± 0.04</td>\n",
       "      <td>0.11 ± 0.12</td>\n",
       "      <td>0.03 ± 0.06</td>\n",
       "      <td>0.1 ± 0.11</td>\n",
       "      <td>0.11 ± 0.14</td>\n",
       "      <td>0.48 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.07</td>\n",
       "      <td>0.3 ± 0.28</td>\n",
       "      <td>4.39 ± 0.36</td>\n",
       "      <td>0.435 ± 0.00</td>\n",
       "      <td>0.53 ± 0.46</td>\n",
       "      <td>0.56 ± 0.49</td>\n",
       "      <td>1.54 ± 1.55</td>\n",
       "      <td>0.45 ± 0.46</td>\n",
       "      <td>0.53 ± 0.46</td>\n",
       "      <td>0.72 ± 0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gemma-7B-Instruct</td>\n",
       "      <td>0.53 ± 0.5</td>\n",
       "      <td>-0.13 ± 0.89</td>\n",
       "      <td>0.22 ± 0.53</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.09 ± 0.1</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.08 ± 0.09</td>\n",
       "      <td>0.09 ± 0.1</td>\n",
       "      <td>0.48 ± 0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.39 ± 0.34</td>\n",
       "      <td>5.17 ± 1.03</td>\n",
       "      <td>0.425 ± 0.00</td>\n",
       "      <td>0.54 ± 0.46</td>\n",
       "      <td>0.57 ± 0.49</td>\n",
       "      <td>2.1 ± 1.97</td>\n",
       "      <td>0.55 ± 0.49</td>\n",
       "      <td>0.54 ± 0.46</td>\n",
       "      <td>0.86 ± 0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model P Consistency Score       C Score       UE Score  \\\n",
       "0  Llama3-1-8B-Instruct          0.49 ± 0.5  -0.22 ± 0.87  0.17 ± 0.48\\t   \n",
       "1         gpt-3.5-turbo         0.82 ± 0.39   0.26 ± 0.75    0.37 ± 0.67   \n",
       "2           gpt-4o-mini       0.81 ± 0.39\\t   0.16 ± 0.71    0.35 ± 0.69   \n",
       "3           gpt-4-turbo         0.84 ± 0.36   0.14 ± 0.66    0.39 ± 0.73   \n",
       "4     Qwen2-7B-Instruct          0.45 ± 0.5  -0.31 ± 0.84    0.17 ± 0.48   \n",
       "5   Mistral-7B-Instruct        0.52 ± 0.5\\t  -0.23 ± 0.82    0.21 ± 0.52   \n",
       "6     Gemma-7B-Instruct          0.53 ± 0.5  -0.13 ± 0.89    0.22 ± 0.53   \n",
       "\n",
       "          BLEU           R1           R2           RL       METEOR  \\\n",
       "0  0.02 ± 0.08  0.11 ± 0.15   0.03 ± 0.1   0.1 ± 0.14  0.11 ± 0.14   \n",
       "1  0.04 ± 0.09   0.2 ± 0.14  0.06 ± 0.12  0.18 ± 0.14   0.2 ± 0.15   \n",
       "2  0.03 ± 0.05  0.19 ± 0.11  0.06 ± 0.08   0.17 ± 0.1  0.22 ± 0.15   \n",
       "3  0.04 ± 0.08  0.23 ± 0.13  0.08 ± 0.11   0.2 ± 0.13  0.23 ± 0.16   \n",
       "4  0.01 ± 0.02   0.08 ± 0.1  0.02 ± 0.04  0.08 ± 0.09   0.1 ± 0.13   \n",
       "5  0.01 ± 0.04  0.11 ± 0.12  0.03 ± 0.06   0.1 ± 0.11  0.11 ± 0.14   \n",
       "6  0.01 ± 0.01   0.09 ± 0.1  0.01 ± 0.03  0.08 ± 0.09   0.09 ± 0.1   \n",
       "\n",
       "  BERTScore_Prec  ...  IDF Overlap Persona Distance response_time  \\\n",
       "0    0.47 ± 0.42  ...   0.06 ± 0.1      0.33 ± 0.33   4.54 ± 0.21   \n",
       "1    0.78 ± 0.25  ...  0.07 ± 0.07      0.51 ± 0.21    1.3 ± 0.42   \n",
       "2    0.78 ± 0.24  ...  0.06 ± 0.05      0.54 ± 0.19   1.43 ± 0.66   \n",
       "3    0.84 ± 0.16  ...  0.05 ± 0.05      0.51 ± 0.15   3.32 ± 1.24   \n",
       "4    0.41 ± 0.42  ...  0.04 ± 0.06       0.29 ± 0.3   3.74 ± 0.76   \n",
       "5    0.48 ± 0.42  ...  0.05 ± 0.07       0.3 ± 0.28   4.39 ± 0.36   \n",
       "6    0.48 ± 0.42  ...   0.08 ± 0.1      0.39 ± 0.34   5.17 ± 1.03   \n",
       "\n",
       "  Failure Ratio UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  0.448 ± 0.00         0.51 ± 0.46       0.55 ± 0.49          1.71 ± 1.88   \n",
       "1   0.09 ± 0.00         0.84 ± 0.27       0.91 ± 0.29          2.31 ± 1.27   \n",
       "2  0.086 ± 0.00         0.85 ± 0.27       0.91 ± 0.28           2.61 ± 1.2   \n",
       "3  0.035 ± 0.00         0.91 ± 0.18       0.96 ± 0.18           2.2 ± 0.94   \n",
       "4  0.509 ± 0.00         0.46 ± 0.47        0.49 ± 0.5          1.72 ± 1.93   \n",
       "5  0.435 ± 0.00         0.53 ± 0.46       0.56 ± 0.49          1.54 ± 1.55   \n",
       "6  0.425 ± 0.00         0.54 ± 0.46       0.57 ± 0.49           2.1 ± 1.97   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.42 ± 0.47               0.51 ± 0.46      0.74 ± 0.7  \n",
       "1          0.72 ± 0.39               0.84 ± 0.27     1.12 ± 0.42  \n",
       "2          0.72 ± 0.36               0.86 ± 0.26     1.19 ± 0.41  \n",
       "3          0.66 ± 0.38               0.91 ± 0.18     1.13 ± 0.28  \n",
       "4          0.43 ± 0.47               0.46 ± 0.47     0.71 ± 0.75  \n",
       "5          0.45 ± 0.46               0.53 ± 0.46     0.72 ± 0.65  \n",
       "6          0.55 ± 0.49               0.54 ± 0.46     0.86 ± 0.76  \n",
       "\n",
       "[7 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_excel(f'../Evaluations/{Dataset}{COT_}-results.xlsx')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persoagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

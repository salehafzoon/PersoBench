{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 54.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation scores are shown below:\n",
      "+-------------------+----------+\n",
      "|     Dimensions    |  Score   |\n",
      "+-------------------+----------+\n",
      "|    naturalness    | 0.950217 |\n",
      "|     coherence     | 0.973135 |\n",
      "|    engagingness   | 1.750486 |\n",
      "|    groundedness   | 0.999566 |\n",
      "| understandability | 0.946209 |\n",
      "|      overall      | 1.123923 |\n",
      "+-------------------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'dialogue'\n",
    "\n",
    "# a list of dialogue histories\n",
    "src_list = ['hi , do you know much about the internet ? \\n i know a lot about different sites and some website design , how about you ? \\n\\n']\n",
    "# a list of additional context that should be included into the generated response\n",
    "context_list = ['the 3 horizontal line menu on apps and websites is called a hamburger button .\\n']\n",
    "# a list of model outputs to be evaluated\n",
    "output_list = ['i do too . did you know the 3 horizontal line menu on apps and websites is called the hamburger button ?']\n",
    "\n",
    "# Prepare data for pre-trained evaluators\n",
    "data = convert_to_json(output_list=output_list, \n",
    "                       src_list=src_list, context_list=context_list)\n",
    "# Initialize evaluator for a specific task\n",
    "evaluator = get_evaluator(task)\n",
    "# Get multi-dimensional evaluation scores\n",
    "eval_scores = evaluator.evaluate(data, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 42.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for example 1: {'naturalness': 0.9502174201360719, 'coherence': 0.9731347836152868, 'engagingness': 1.7504860805525295, 'groundedness': 0.9995656267195939, 'understandability': 0.9462095037239142, 'overall': 1.1239226829494793}\n",
      "Scores for example 2: {'naturalness': 0.9675946477090701, 'coherence': 0.998674558536015, 'engagingness': 1.9936029005678884, 'groundedness': 0.9857853472625128, 'understandability': 0.9632170362278318, 'overall': 1.1817748980606635}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'dialogue'\n",
    "\n",
    "# Batch inputs: multiple dialogue histories, contexts, and model outputs\n",
    "src_list = [\n",
    "    'hi , do you know much about the internet ? \\n i know a lot about different sites and some website design , how about you ? \\n\\n',\n",
    "    'what is your favorite color ? \\n i like blue a lot , but sometimes i prefer green . \\n\\n'\n",
    "]\n",
    "context_list = [\n",
    "    'the 3 horizontal line menu on apps and websites is called a hamburger button .\\n',\n",
    "    'colors can reflect your mood and personality .\\n'\n",
    "]\n",
    "output_list = [\n",
    "    'i do too . did you know the 3 horizontal line menu on apps and websites is called the hamburger button ?',\n",
    "    'i like blue as well . it is calming and reminds me of the ocean .'\n",
    "]\n",
    "\n",
    "# Prepare data for pre-trained evaluators\n",
    "data = convert_to_json(output_list=output_list, \n",
    "                       src_list=src_list, context_list=context_list)\n",
    "\n",
    "# Initialize evaluator for a specific task\n",
    "evaluator = get_evaluator(task)\n",
    "\n",
    "# Get multi-dimensional evaluation scores for the batch\n",
    "eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "# Display scores\n",
    "for i, score in enumerate(eval_scores):\n",
    "    print(f\"Scores for example {i + 1}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'naturalness': 0.9502174201360719,\n",
       "  'coherence': 0.9731347836152868,\n",
       "  'engagingness': 1.7504860805525295,\n",
       "  'groundedness': 0.9995656267195939,\n",
       "  'understandability': 0.9462095037239142,\n",
       "  'overall': 1.1239226829494793},\n",
       " {'naturalness': 0.9675946477090701,\n",
       "  'coherence': 0.998674558536015,\n",
       "  'engagingness': 1.9936029005678884,\n",
       "  'groundedness': 0.9857853472625128,\n",
       "  'understandability': 0.9632170362278318,\n",
       "  'overall': 1.1817748980606635}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Generation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Set the logging level to ERROR to ignore warnings\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = \"Blended Skill Talk\"                                # Synthetic-PersonaChat, Blended Skill Talk, PEC, ConvAI2, FoCus, IT-ConvAI2\n",
    "LLM_name = \"gpt-4o-mini\"                                # Mistral-7B-Instruct, Llama3-1-8B-Instruct, Qwen2-7B-Instruct,  gpt-3.5-turbo, gpt-4-turbo, gpt-4o-mini\n",
    "COT_SETUP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (980, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>act_response</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[User 1 persona]: ['i hate talking to people.'...</td>\n",
       "      <td>I think it's because in my head, I think every...</td>\n",
       "      <td>User1: Wow, I am never shy. Do you have anxiet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[User 1 persona]: ['i have three daughters.' '...</td>\n",
       "      <td>What does your turtle eat?  Is it hard to take...</td>\n",
       "      <td>User1: My turtle ran away from me today.\\nUser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[User 1 persona]: ['i hate the taste of fish.'...</td>\n",
       "      <td>Yeah, kids grow up so quickly</td>\n",
       "      <td>User1: Our son in the Army is taking a leave t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[User 1 persona]: ['my favorite movie is good ...</td>\n",
       "      <td>Wow, you've done a marathon?  I run a bit, but...</td>\n",
       "      <td>User1: that's awesome , i like running in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[User 1 persona]: ['my hair is black.' 'i like...</td>\n",
       "      <td>I would suggest a fitness place with a rock wa...</td>\n",
       "      <td>User1: Are there different skill levels? \\nUse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  [User 1 persona]: ['i hate talking to people.'...   \n",
       "1  [User 1 persona]: ['i have three daughters.' '...   \n",
       "2  [User 1 persona]: ['i hate the taste of fish.'...   \n",
       "3  [User 1 persona]: ['my favorite movie is good ...   \n",
       "4  [User 1 persona]: ['my hair is black.' 'i like...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  I think it's because in my head, I think every...   \n",
       "1  What does your turtle eat?  Is it hard to take...   \n",
       "2                     Yeah, kids grow up so quickly    \n",
       "3  Wow, you've done a marathon?  I run a bit, but...   \n",
       "4  I would suggest a fitness place with a rock wa...   \n",
       "\n",
       "                                             context  \n",
       "0  User1: Wow, I am never shy. Do you have anxiet...  \n",
       "1  User1: My turtle ran away from me today.\\nUser...  \n",
       "2  User1: Our son in the Army is taking a leave t...  \n",
       "3  User1: that's awesome , i like running in the ...  \n",
       "4  User1: Are there different skill levels? \\nUse...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'../Prompts/{Dataset}.csv')\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Blended Skill Talk'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas        0\n",
      "act_response    0\n",
      "context         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>act_response</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i hate talking to people. i believe dragons ar...</td>\n",
       "      <td>I think it's because in my head, I think every...</td>\n",
       "      <td>User1: Wow, I am never shy. Do you have anxiet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have three daughters. my wife and i like to ...</td>\n",
       "      <td>What does your turtle eat?  Is it hard to take...</td>\n",
       "      <td>User1: My turtle ran away from me today.\\nUser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i hate the taste of fish. i like to paint.</td>\n",
       "      <td>Yeah, kids grow up so quickly</td>\n",
       "      <td>User1: Our son in the Army is taking a leave t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my favorite movie is good burger. i like canni...</td>\n",
       "      <td>Wow, you've done a marathon?  I run a bit, but...</td>\n",
       "      <td>User1: that's awesome , i like running in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my hair is black. i like rock climbing.</td>\n",
       "      <td>I would suggest a fitness place with a rock wa...</td>\n",
       "      <td>User1: Are there different skill levels? \\nUse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>my dad works at the mill and my mom is a teach...</td>\n",
       "      <td>I'm sure you'll do great. In second grade, tha...</td>\n",
       "      <td>User1: This is the first time I drop my kids o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  i hate talking to people. i believe dragons ar...   \n",
       "1  i have three daughters. my wife and i like to ...   \n",
       "2         i hate the taste of fish. i like to paint.   \n",
       "3  my favorite movie is good burger. i like canni...   \n",
       "4            my hair is black. i like rock climbing.   \n",
       "5  my dad works at the mill and my mom is a teach...   \n",
       "\n",
       "                                        act_response  \\\n",
       "0  I think it's because in my head, I think every...   \n",
       "1  What does your turtle eat?  Is it hard to take...   \n",
       "2                     Yeah, kids grow up so quickly    \n",
       "3  Wow, you've done a marathon?  I run a bit, but...   \n",
       "4  I would suggest a fitness place with a rock wa...   \n",
       "5  I'm sure you'll do great. In second grade, tha...   \n",
       "\n",
       "                                             context  \n",
       "0  User1: Wow, I am never shy. Do you have anxiet...  \n",
       "1  User1: My turtle ran away from me today.\\nUser...  \n",
       "2  User1: Our son in the Army is taking a leave t...  \n",
       "3  User1: that's awesome , i like running in the ...  \n",
       "4  User1: Are there different skill levels? \\nUse...  \n",
       "5  User1: This is the first time I drop my kids o...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Only For: Blended Skill Talk\n",
    "if Dataset == \"Blended Skill Talk\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[User 1 persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "# ### Only For: PEC\n",
    "if Dataset == \"PEC\":\n",
    "    df['personas'] = df['personas'].str.replace(r'\\[Responder persona\\]:|\\[|\\]|\"|\\'', '', regex=True).str.strip()\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (980, 2)\n",
      "\n",
      "Missing Values:\n",
      "gen_response     1\n",
      "response_time    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I guess it's just the pressure of talking to p...</td>\n",
       "      <td>1.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's hilarious! I can just imagine your turt...</td>\n",
       "      <td>0.831460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I know, right? It feels like just yesterday he...</td>\n",
       "      <td>0.902882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That's a smart idea! Canning can really help w...</td>\n",
       "      <td>0.789975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To start rock climbing, you might want to find...</td>\n",
       "      <td>2.361459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>That's great! Mind maps can be really helpful ...</td>\n",
       "      <td>0.816989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>I totally understand the dilemma you're facing...</td>\n",
       "      <td>1.033905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>I totally get that! Blue is such a beautiful c...</td>\n",
       "      <td>0.813419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>It sounds like you're going through a really t...</td>\n",
       "      <td>1.067153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>It's understandable to feel that way, especial...</td>\n",
       "      <td>1.442100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          gen_response  response_time\n",
       "0    I guess it's just the pressure of talking to p...       1.002316\n",
       "1    That's hilarious! I can just imagine your turt...       0.831460\n",
       "2    I know, right? It feels like just yesterday he...       0.902882\n",
       "3    That's a smart idea! Canning can really help w...       0.789975\n",
       "4    To start rock climbing, you might want to find...       2.361459\n",
       "..                                                 ...            ...\n",
       "975  That's great! Mind maps can be really helpful ...       0.816989\n",
       "976  I totally understand the dilemma you're facing...       1.033905\n",
       "977  I totally get that! Blue is such a beautiful c...       0.813419\n",
       "978  It sounds like you're going through a really t...       1.067153\n",
       "979  It's understandable to feel that way, especial...       1.442100\n",
       "\n",
       "[980 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COT_ = \"-COT\" if COT_SETUP else \"\"\n",
    " \n",
    "response = pd.read_csv(f'../Responses/{Dataset}/{LLM_name}{COT_}.csv')\n",
    "print(\"Shape:\", response.shape)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(response.isnull().sum())\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Response Length (in words): 82\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum number of words in each column\n",
    "max_response_length = response['gen_response'].dropna().apply(lambda x: len(x.split())).max()\n",
    "\n",
    "print(f\"Maximum Response Length (in words): {max_response_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas         0\n",
      "context          0\n",
      "gen_response     1\n",
      "response_time    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personas</th>\n",
       "      <th>context</th>\n",
       "      <th>gen_response</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i hate talking to people. i believe dragons ar...</td>\n",
       "      <td>User1: Wow, I am never shy. Do you have anxiet...</td>\n",
       "      <td>I guess it's just the pressure of talking to p...</td>\n",
       "      <td>1.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have three daughters. my wife and i like to ...</td>\n",
       "      <td>User1: My turtle ran away from me today.\\nUser...</td>\n",
       "      <td>That's hilarious! I can just imagine your turt...</td>\n",
       "      <td>0.831460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i hate the taste of fish. i like to paint.</td>\n",
       "      <td>User1: Our son in the Army is taking a leave t...</td>\n",
       "      <td>I know, right? It feels like just yesterday he...</td>\n",
       "      <td>0.902882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my favorite movie is good burger. i like canni...</td>\n",
       "      <td>User1: that's awesome , i like running in the ...</td>\n",
       "      <td>That's a smart idea! Canning can really help w...</td>\n",
       "      <td>0.789975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my hair is black. i like rock climbing.</td>\n",
       "      <td>User1: Are there different skill levels? \\nUse...</td>\n",
       "      <td>To start rock climbing, you might want to find...</td>\n",
       "      <td>2.361459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            personas  \\\n",
       "0  i hate talking to people. i believe dragons ar...   \n",
       "1  i have three daughters. my wife and i like to ...   \n",
       "2         i hate the taste of fish. i like to paint.   \n",
       "3  my favorite movie is good burger. i like canni...   \n",
       "4            my hair is black. i like rock climbing.   \n",
       "\n",
       "                                             context  \\\n",
       "0  User1: Wow, I am never shy. Do you have anxiet...   \n",
       "1  User1: My turtle ran away from me today.\\nUser...   \n",
       "2  User1: Our son in the Army is taking a leave t...   \n",
       "3  User1: that's awesome , i like running in the ...   \n",
       "4  User1: Are there different skill levels? \\nUse...   \n",
       "\n",
       "                                        gen_response  response_time  \n",
       "0  I guess it's just the pressure of talking to p...       1.002316  \n",
       "1  That's hilarious! I can just imagine your turt...       0.831460  \n",
       "2  I know, right? It feels like just yesterday he...       0.902882  \n",
       "3  That's a smart idea! Canning can really help w...       0.789975  \n",
       "4  To start rock climbing, you might want to find...       2.361459  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, remove_stop_words=True):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    if remove_stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]  # Removing stop words\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Create eval_df\n",
    "eval_df = pd.DataFrame({\n",
    "    'personas': df['personas'],\n",
    "    'context': df['context'],\n",
    "    'gen_response': response['gen_response'],\n",
    "    'response_time': response['response_time']\n",
    "})\n",
    "\n",
    "print(eval_df.isnull().sum())\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1  # device set to 0 for GPU, -1 for CPU\n",
    "# device = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finalized Input Mapping:**\n",
    "\n",
    "- src_list: Use the context column (conversation history).\n",
    "- context_list: Use the flattened and cleaned persona column.\n",
    "- output_list: Use the gen_response (the response your model generates).\n",
    "\n",
    "**Note:**\n",
    "\n",
    "The act_response (true or reference response) is not required as an input for the UniEval evaluation process because UniEval evaluates the generated response (gen_response) based on how well it fits the provided context (conversation history) and additional persona information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "def calculate_unieval_scores(personas, contexts, gen_responses):\n",
    "    \"\"\"\n",
    "    Calculates UniEval scores for a batch of inputs.\n",
    "\n",
    "    Args:\n",
    "        personas (list): List of persona information as additional context.\n",
    "        contexts (list): List of conversation histories leading to the responses.\n",
    "        gen_responses (list): List of generated responses to be evaluated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing UniEval scores for each input.\n",
    "    \"\"\"\n",
    "    # Flatten personas if they are lists\n",
    "    personas = [' '.join(p) if isinstance(p, list) else p for p in personas]\n",
    "\n",
    "    # Prepare inputs for UniEval\n",
    "    data = convert_to_json(output_list=gen_responses, src_list=contexts, context_list=personas)\n",
    "\n",
    "    # Initialize the evaluator for dialogue tasks\n",
    "    evaluator = get_evaluator('dialogue')\n",
    "\n",
    "    # Evaluate and obtain scores for all inputs\n",
    "    eval_scores = evaluator.evaluate(data, print_result=False)\n",
    "\n",
    "    return eval_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the worst UniEval score as a dictionary\n",
    "worst_unieval_score = {\n",
    "    'naturalness': 0.0,\n",
    "    'coherence': 0.0,\n",
    "    'engagingness': 0.0,\n",
    "    'groundedness': 0.0,\n",
    "    'understandability': 0.0,\n",
    "    'overall': 0.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating batches:   0%|          | 0/5 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating batches:  20%|██        | 1/5 [01:28<05:53, 88.26s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating batches:  40%|████      | 2/5 [03:01<04:32, 90.96s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating batches:  60%|██████    | 3/5 [04:27<02:58, 89.04s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating batches:  80%|████████  | 4/5 [05:55<01:28, 88.33s/it]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating batches: 100%|██████████| 5/5 [07:15<00:00, 87.10s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946804</td>\n",
       "      <td>0.971796</td>\n",
       "      <td>3.004960</td>\n",
       "      <td>0.998948</td>\n",
       "      <td>0.939764</td>\n",
       "      <td>1.372455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.952231</td>\n",
       "      <td>0.997851</td>\n",
       "      <td>3.080799</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>0.946839</td>\n",
       "      <td>1.197702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.971357</td>\n",
       "      <td>0.998264</td>\n",
       "      <td>2.206288</td>\n",
       "      <td>0.907607</td>\n",
       "      <td>0.968676</td>\n",
       "      <td>1.210438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956967</td>\n",
       "      <td>0.998880</td>\n",
       "      <td>2.881239</td>\n",
       "      <td>0.983022</td>\n",
       "      <td>0.954477</td>\n",
       "      <td>1.354917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.859593</td>\n",
       "      <td>0.999080</td>\n",
       "      <td>2.219915</td>\n",
       "      <td>0.990899</td>\n",
       "      <td>0.901610</td>\n",
       "      <td>1.194219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.962115</td>\n",
       "      <td>0.996908</td>\n",
       "      <td>1.006736</td>\n",
       "      <td>0.280973</td>\n",
       "      <td>0.957939</td>\n",
       "      <td>0.840934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.959471</td>\n",
       "      <td>0.994535</td>\n",
       "      <td>3.864800</td>\n",
       "      <td>0.972928</td>\n",
       "      <td>0.957468</td>\n",
       "      <td>1.549840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.959926</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>2.005206</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.953072</td>\n",
       "      <td>0.984064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.963703</td>\n",
       "      <td>0.999613</td>\n",
       "      <td>3.864537</td>\n",
       "      <td>0.913209</td>\n",
       "      <td>0.960440</td>\n",
       "      <td>1.540300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.967719</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>1.022506</td>\n",
       "      <td>0.320717</td>\n",
       "      <td>0.964583</td>\n",
       "      <td>0.855001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UniEval Naturalness  UniEval Coherence  UniEval Engagingness  \\\n",
       "0               0.946804           0.971796              3.004960   \n",
       "1               0.952231           0.997851              3.080799   \n",
       "2               0.971357           0.998264              2.206288   \n",
       "3               0.956967           0.998880              2.881239   \n",
       "4               0.859593           0.999080              2.219915   \n",
       "..                   ...                ...                   ...   \n",
       "975             0.962115           0.996908              1.006736   \n",
       "976             0.959471           0.994535              3.864800   \n",
       "977             0.959926           0.999218              2.005206   \n",
       "978             0.963703           0.999613              3.864537   \n",
       "979             0.967719           0.999480              1.022506   \n",
       "\n",
       "     UniEval Groundedness  UniEval Understandability  UniEval Overall  \n",
       "0                0.998948                   0.939764         1.372455  \n",
       "1                0.010788                   0.946839         1.197702  \n",
       "2                0.907607                   0.968676         1.210438  \n",
       "3                0.983022                   0.954477         1.354917  \n",
       "4                0.990899                   0.901610         1.194219  \n",
       "..                    ...                        ...              ...  \n",
       "975              0.280973                   0.957939         0.840934  \n",
       "976              0.972928                   0.957468         1.549840  \n",
       "977              0.002897                   0.953072         0.984064  \n",
       "978              0.913209                   0.960440         1.540300  \n",
       "979              0.320717                   0.964583         0.855001  \n",
       "\n",
       "[980 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Function to evaluate in batches or the entire DataFrame\n",
    "batch_size = 200  # Adjust batch size as needed\n",
    "\n",
    "# List to store all UniEval scores\n",
    "all_unieval_scores = []\n",
    "\n",
    "# Split into batches if necessary\n",
    "for i in tqdm(range(0, len(eval_df), batch_size), desc=\"Evaluating batches\"):\n",
    "    batch = eval_df.iloc[i:i+batch_size]\n",
    "\n",
    "    # Extract relevant fields from the batch\n",
    "    personas = batch['personas'].tolist()\n",
    "    contexts = batch['context'].tolist()\n",
    "    gen_responses = batch['gen_response'].tolist()\n",
    "\n",
    "    # Check for NaN responses and handle them\n",
    "    valid_indices = [j for j, response in enumerate(gen_responses) if pd.notna(response) and response.strip() != '']\n",
    "    invalid_indices = [j for j, response in enumerate(gen_responses) if j not in valid_indices]\n",
    "\n",
    "    # Prepare valid inputs\n",
    "    valid_personas = [personas[j] for j in valid_indices]\n",
    "    valid_contexts = [contexts[j] for j in valid_indices]\n",
    "    valid_gen_responses = [gen_responses[j] for j in valid_indices]\n",
    "\n",
    "    # Evaluate valid inputs\n",
    "    if valid_personas:\n",
    "        eval_scores = calculate_unieval_scores(valid_personas, valid_contexts, valid_gen_responses)\n",
    "        all_unieval_scores.extend(eval_scores)\n",
    "\n",
    "    # Append worst scores for invalid inputs\n",
    "    all_unieval_scores.extend([worst_unieval_score] * len(invalid_indices))\n",
    "\n",
    "# Convert all scores into a DataFrame\n",
    "metrics_df = pd.DataFrame(all_unieval_scores)\n",
    "\n",
    "# Rename columns for clarity\n",
    "metrics_df.columns = [\n",
    "    \"UniEval Naturalness\",\n",
    "    \"UniEval Coherence\",\n",
    "    \"UniEval Engagingness\",\n",
    "    \"UniEval Groundedness\",\n",
    "    \"UniEval Understandability\",\n",
    "    \"UniEval Overall\"\n",
    "]\n",
    "\n",
    "# Combine with original DataFrame if needed\n",
    "eval_df = pd.concat([eval_df.reset_index(drop=True), metrics_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean (average) and standard deviation, rounded to 2 decimal places\n",
    "avg_values = metrics_df.mean().round(2)\n",
    "std_values = metrics_df.std(ddof=0).round(2)  # Use ddof=0 for population standard deviation\n",
    "\n",
    "# Combine the average and standard deviation into the format \"avg ± std\"\n",
    "combined_values = avg_values.astype(str) + \" ± \" + std_values.astype(str)\n",
    "\n",
    "# Insert the LLM name at the beginning of the combined values\n",
    "combined_values = combined_values.tolist()\n",
    "combined_values.insert(0, LLM_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>0.99 ± 0.03</td>\n",
       "      <td>2.9 ± 0.84</td>\n",
       "      <td>0.57 ± 0.41</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>1.27 ± 0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  gpt-4o-mini         0.96 ± 0.03       0.99 ± 0.03           2.9 ± 0.84   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.57 ± 0.41               0.96 ± 0.03     1.27 ± 0.19  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for the combined average ± std row\n",
    "result_df = pd.DataFrame([combined_values], columns=['Model'] + metrics_df.columns.tolist())\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>...</th>\n",
       "      <th>`</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama3-1-8B-Instruct</td>\n",
       "      <td>0.79 ± 0.41</td>\n",
       "      <td>-0.11 ± 0.55</td>\n",
       "      <td>0.33 ± 0.7</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.12 ± 0.08</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.12 ± 0.09</td>\n",
       "      <td>0.81 ± 0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.1</td>\n",
       "      <td>0.45 ± 0.17</td>\n",
       "      <td>4.28 ± 0.26</td>\n",
       "      <td>0.043 ± 0.00</td>\n",
       "      <td>0.92 ± 0.19</td>\n",
       "      <td>0.92 ± 0.25</td>\n",
       "      <td>2.42 ± 1.12</td>\n",
       "      <td>0.45 ± 0.43</td>\n",
       "      <td>0.92 ± 0.19</td>\n",
       "      <td>1.12 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistral-7B-Instruct</td>\n",
       "      <td>0.81 ± 0.39\\t</td>\n",
       "      <td>-0.0 ± 0.62</td>\n",
       "      <td>0.48 ± 0.79\\t</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.1 ± 0.08</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.1 ± 0.07</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.8 ± 0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.46 ± 0.18</td>\n",
       "      <td>3.87 ± 0.72</td>\n",
       "      <td>0.052 ± 0.00</td>\n",
       "      <td>0.9 ± 0.21</td>\n",
       "      <td>0.93 ± 0.23</td>\n",
       "      <td>2.55 ± 1.18</td>\n",
       "      <td>0.54 ± 0.44</td>\n",
       "      <td>0.89 ± 0.21</td>\n",
       "      <td>1.16 ± 0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.79 ± 0.41\\t</td>\n",
       "      <td>-0.11 ± 0.56</td>\n",
       "      <td>0.39 ± 0.75</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.11 ± 0.07</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.1 ± 0.07</td>\n",
       "      <td>0.12 ± 0.08</td>\n",
       "      <td>0.82 ± 0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.08</td>\n",
       "      <td>0.46 ± 0.15</td>\n",
       "      <td>2.21 ± 0.67</td>\n",
       "      <td>0.024 ± 0.00</td>\n",
       "      <td>0.93 ± 0.15</td>\n",
       "      <td>0.97 ± 0.15</td>\n",
       "      <td>2.98 ± 1.18</td>\n",
       "      <td>0.44 ± 0.44</td>\n",
       "      <td>0.93 ± 0.15</td>\n",
       "      <td>1.25 ± 0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.83 ± 0.38</td>\n",
       "      <td>-0.01 ± 0.57\\t</td>\n",
       "      <td>0.51 ± 0.82</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.13 ± 0.09</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.13 ± 0.09</td>\n",
       "      <td>0.85 ± 0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.11</td>\n",
       "      <td>0.47 ± 0.15</td>\n",
       "      <td>0.91 ± 0.21</td>\n",
       "      <td>0.0 ± 0.00</td>\n",
       "      <td>0.96 ± 0.02</td>\n",
       "      <td>0.97 ± 0.13</td>\n",
       "      <td>2.33 ± 0.83</td>\n",
       "      <td>0.28 ± 0.4</td>\n",
       "      <td>0.95 ± 0.02</td>\n",
       "      <td>1.1 ± 0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>0.86 ± 0.35\\t</td>\n",
       "      <td>-0.05 ± 0.48</td>\n",
       "      <td>0.56 ± 0.84</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.12 ± 0.08</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.11 ± 0.07</td>\n",
       "      <td>0.12 ± 0.09</td>\n",
       "      <td>0.85 ± 0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.07</td>\n",
       "      <td>0.47 ± 0.14</td>\n",
       "      <td>1.84 ± 0.5</td>\n",
       "      <td>0.0 ± 0.00</td>\n",
       "      <td>0.96 ± 0.01</td>\n",
       "      <td>0.98 ± 0.05</td>\n",
       "      <td>2.43 ± 0.78</td>\n",
       "      <td>0.53 ± 0.42</td>\n",
       "      <td>0.96 ± 0.01</td>\n",
       "      <td>1.17 ± 0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.84 ± 0.37\\t</td>\n",
       "      <td>-0.1 ± 0.46</td>\n",
       "      <td>0.38 ± 0.74</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.13 ± 0.08</td>\n",
       "      <td>0.02 ± 0.03</td>\n",
       "      <td>0.12 ± 0.07</td>\n",
       "      <td>0.14 ± 0.09</td>\n",
       "      <td>0.85 ± 0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.07</td>\n",
       "      <td>0.48 ± 0.13</td>\n",
       "      <td>0.94 ± 0.28</td>\n",
       "      <td>0.001 ± 0.00</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>0.99 ± 0.03</td>\n",
       "      <td>2.9 ± 0.84</td>\n",
       "      <td>0.57 ± 0.41</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>1.27 ± 0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model P Consistency Score         C Score       UE Score  \\\n",
       "0  Llama3-1-8B-Instruct         0.79 ± 0.41    -0.11 ± 0.55     0.33 ± 0.7   \n",
       "1   Mistral-7B-Instruct       0.81 ± 0.39\\t     -0.0 ± 0.62  0.48 ± 0.79\\t   \n",
       "2     Qwen2-7B-Instruct       0.79 ± 0.41\\t    -0.11 ± 0.56    0.39 ± 0.75   \n",
       "3         gpt-3.5-turbo         0.83 ± 0.38  -0.01 ± 0.57\\t    0.51 ± 0.82   \n",
       "4           gpt-4-turbo       0.86 ± 0.35\\t    -0.05 ± 0.48    0.56 ± 0.84   \n",
       "5           gpt-4o-mini       0.84 ± 0.37\\t     -0.1 ± 0.46    0.38 ± 0.74   \n",
       "\n",
       "          BLEU           R1           R2           RL       METEOR  \\\n",
       "0  0.01 ± 0.02  0.12 ± 0.08  0.02 ± 0.04  0.11 ± 0.08  0.12 ± 0.09   \n",
       "1  0.01 ± 0.01   0.1 ± 0.08  0.01 ± 0.03   0.1 ± 0.07  0.11 ± 0.08   \n",
       "2  0.01 ± 0.01  0.11 ± 0.07  0.01 ± 0.03   0.1 ± 0.07  0.12 ± 0.08   \n",
       "3  0.01 ± 0.02  0.13 ± 0.09  0.02 ± 0.04  0.11 ± 0.08  0.13 ± 0.09   \n",
       "4  0.01 ± 0.02  0.12 ± 0.08  0.02 ± 0.04  0.11 ± 0.07  0.12 ± 0.09   \n",
       "5  0.01 ± 0.01  0.13 ± 0.08  0.02 ± 0.03  0.12 ± 0.07  0.14 ± 0.09   \n",
       "\n",
       "  BERTScore_Prec  ...            ` Persona Distance response_time  \\\n",
       "0    0.81 ± 0.17  ...   0.06 ± 0.1      0.45 ± 0.17   4.28 ± 0.26   \n",
       "1     0.8 ± 0.19  ...   0.08 ± 0.1      0.46 ± 0.18   3.87 ± 0.72   \n",
       "2    0.82 ± 0.13  ...  0.05 ± 0.08      0.46 ± 0.15   2.21 ± 0.67   \n",
       "3    0.85 ± 0.02  ...  0.07 ± 0.11      0.47 ± 0.15   0.91 ± 0.21   \n",
       "4    0.85 ± 0.02  ...  0.06 ± 0.07      0.47 ± 0.14    1.84 ± 0.5   \n",
       "5    0.85 ± 0.03  ...  0.05 ± 0.07      0.48 ± 0.13   0.94 ± 0.28   \n",
       "\n",
       "  Failure Ratio UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  0.043 ± 0.00         0.92 ± 0.19       0.92 ± 0.25          2.42 ± 1.12   \n",
       "1  0.052 ± 0.00          0.9 ± 0.21       0.93 ± 0.23          2.55 ± 1.18   \n",
       "2  0.024 ± 0.00         0.93 ± 0.15       0.97 ± 0.15          2.98 ± 1.18   \n",
       "3    0.0 ± 0.00         0.96 ± 0.02       0.97 ± 0.13          2.33 ± 0.83   \n",
       "4    0.0 ± 0.00         0.96 ± 0.01       0.98 ± 0.05          2.43 ± 0.78   \n",
       "5  0.001 ± 0.00         0.96 ± 0.03       0.99 ± 0.03           2.9 ± 0.84   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.45 ± 0.43               0.92 ± 0.19     1.12 ± 0.32  \n",
       "1          0.54 ± 0.44               0.89 ± 0.21     1.16 ± 0.35  \n",
       "2          0.44 ± 0.44               0.93 ± 0.15     1.25 ± 0.31  \n",
       "3           0.28 ± 0.4               0.95 ± 0.02      1.1 ± 0.18  \n",
       "4          0.53 ± 0.42               0.96 ± 0.01     1.17 ± 0.18  \n",
       "5          0.57 ± 0.41               0.96 ± 0.03     1.27 ± 0.19  \n",
       "\n",
       "[6 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the existing Excel file and update or append the average row\n",
    "output_path = f'../Evaluations/{Dataset}{COT_}-results.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing data\n",
    "    existing_df = pd.read_excel(output_path)\n",
    "    \n",
    "    # Check if the model name already exists\n",
    "    if LLM_name in existing_df['Model'].values:\n",
    "        # Update the row by appending the new columns\n",
    "        existing_index = existing_df.loc[existing_df['Model'] == LLM_name].index[0]\n",
    "        for col in result_df.columns:\n",
    "            if col not in existing_df.columns:\n",
    "                existing_df[col] = None  # Add new column if missing\n",
    "            existing_df.at[existing_index, col] = result_df[col].values[0]  # Update column values\n",
    "    else:\n",
    "        # Append the new data\n",
    "        existing_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new DataFrame\n",
    "    existing_df = result_df\n",
    "\n",
    "# # Save the updated DataFrame to an Excel file\n",
    "existing_df.to_excel(output_path, index=False)\n",
    "\n",
    "existing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>P Consistency Score</th>\n",
       "      <th>C Score</th>\n",
       "      <th>UE Score</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>RL</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore_Prec</th>\n",
       "      <th>...</th>\n",
       "      <th>`</th>\n",
       "      <th>Persona Distance</th>\n",
       "      <th>response_time</th>\n",
       "      <th>Failure Ratio</th>\n",
       "      <th>UniEval Naturalness</th>\n",
       "      <th>UniEval Coherence</th>\n",
       "      <th>UniEval Engagingness</th>\n",
       "      <th>UniEval Groundedness</th>\n",
       "      <th>UniEval Understandability</th>\n",
       "      <th>UniEval Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama3-1-8B-Instruct</td>\n",
       "      <td>0.79 ± 0.41</td>\n",
       "      <td>-0.11 ± 0.55</td>\n",
       "      <td>0.33 ± 0.7</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.12 ± 0.08</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.12 ± 0.09</td>\n",
       "      <td>0.81 ± 0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.1</td>\n",
       "      <td>0.45 ± 0.17</td>\n",
       "      <td>4.28 ± 0.26</td>\n",
       "      <td>0.043 ± 0.00</td>\n",
       "      <td>0.92 ± 0.19</td>\n",
       "      <td>0.92 ± 0.25</td>\n",
       "      <td>2.42 ± 1.12</td>\n",
       "      <td>0.45 ± 0.43</td>\n",
       "      <td>0.92 ± 0.19</td>\n",
       "      <td>1.12 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistral-7B-Instruct</td>\n",
       "      <td>0.81 ± 0.39\\t</td>\n",
       "      <td>-0.0 ± 0.62</td>\n",
       "      <td>0.48 ± 0.79\\t</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.1 ± 0.08</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.1 ± 0.07</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.8 ± 0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08 ± 0.1</td>\n",
       "      <td>0.46 ± 0.18</td>\n",
       "      <td>3.87 ± 0.72</td>\n",
       "      <td>0.052 ± 0.00</td>\n",
       "      <td>0.9 ± 0.21</td>\n",
       "      <td>0.93 ± 0.23</td>\n",
       "      <td>2.55 ± 1.18</td>\n",
       "      <td>0.54 ± 0.44</td>\n",
       "      <td>0.89 ± 0.21</td>\n",
       "      <td>1.16 ± 0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2-7B-Instruct</td>\n",
       "      <td>0.79 ± 0.41\\t</td>\n",
       "      <td>-0.11 ± 0.56</td>\n",
       "      <td>0.39 ± 0.75</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.11 ± 0.07</td>\n",
       "      <td>0.01 ± 0.03</td>\n",
       "      <td>0.1 ± 0.07</td>\n",
       "      <td>0.12 ± 0.08</td>\n",
       "      <td>0.82 ± 0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.08</td>\n",
       "      <td>0.46 ± 0.15</td>\n",
       "      <td>2.21 ± 0.67</td>\n",
       "      <td>0.024 ± 0.00</td>\n",
       "      <td>0.93 ± 0.15</td>\n",
       "      <td>0.97 ± 0.15</td>\n",
       "      <td>2.98 ± 1.18</td>\n",
       "      <td>0.44 ± 0.44</td>\n",
       "      <td>0.93 ± 0.15</td>\n",
       "      <td>1.25 ± 0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.83 ± 0.38</td>\n",
       "      <td>-0.01 ± 0.57\\t</td>\n",
       "      <td>0.51 ± 0.82</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.13 ± 0.09</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.11 ± 0.08</td>\n",
       "      <td>0.13 ± 0.09</td>\n",
       "      <td>0.85 ± 0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07 ± 0.11</td>\n",
       "      <td>0.47 ± 0.15</td>\n",
       "      <td>0.91 ± 0.21</td>\n",
       "      <td>0.0 ± 0.00</td>\n",
       "      <td>0.96 ± 0.02</td>\n",
       "      <td>0.97 ± 0.13</td>\n",
       "      <td>2.33 ± 0.83</td>\n",
       "      <td>0.28 ± 0.4</td>\n",
       "      <td>0.95 ± 0.02</td>\n",
       "      <td>1.1 ± 0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>0.86 ± 0.35\\t</td>\n",
       "      <td>-0.05 ± 0.48</td>\n",
       "      <td>0.56 ± 0.84</td>\n",
       "      <td>0.01 ± 0.02</td>\n",
       "      <td>0.12 ± 0.08</td>\n",
       "      <td>0.02 ± 0.04</td>\n",
       "      <td>0.11 ± 0.07</td>\n",
       "      <td>0.12 ± 0.09</td>\n",
       "      <td>0.85 ± 0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06 ± 0.07</td>\n",
       "      <td>0.47 ± 0.14</td>\n",
       "      <td>1.84 ± 0.5</td>\n",
       "      <td>0.0 ± 0.00</td>\n",
       "      <td>0.96 ± 0.01</td>\n",
       "      <td>0.98 ± 0.05</td>\n",
       "      <td>2.43 ± 0.78</td>\n",
       "      <td>0.53 ± 0.42</td>\n",
       "      <td>0.96 ± 0.01</td>\n",
       "      <td>1.17 ± 0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.84 ± 0.37\\t</td>\n",
       "      <td>-0.1 ± 0.46</td>\n",
       "      <td>0.38 ± 0.74</td>\n",
       "      <td>0.01 ± 0.01</td>\n",
       "      <td>0.13 ± 0.08</td>\n",
       "      <td>0.02 ± 0.03</td>\n",
       "      <td>0.12 ± 0.07</td>\n",
       "      <td>0.14 ± 0.09</td>\n",
       "      <td>0.85 ± 0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05 ± 0.07</td>\n",
       "      <td>0.48 ± 0.13</td>\n",
       "      <td>0.94 ± 0.28</td>\n",
       "      <td>0.001 ± 0.00</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>0.99 ± 0.03</td>\n",
       "      <td>2.9 ± 0.84</td>\n",
       "      <td>0.57 ± 0.41</td>\n",
       "      <td>0.96 ± 0.03</td>\n",
       "      <td>1.27 ± 0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model P Consistency Score         C Score       UE Score  \\\n",
       "0  Llama3-1-8B-Instruct         0.79 ± 0.41    -0.11 ± 0.55     0.33 ± 0.7   \n",
       "1   Mistral-7B-Instruct       0.81 ± 0.39\\t     -0.0 ± 0.62  0.48 ± 0.79\\t   \n",
       "2     Qwen2-7B-Instruct       0.79 ± 0.41\\t    -0.11 ± 0.56    0.39 ± 0.75   \n",
       "3         gpt-3.5-turbo         0.83 ± 0.38  -0.01 ± 0.57\\t    0.51 ± 0.82   \n",
       "4           gpt-4-turbo       0.86 ± 0.35\\t    -0.05 ± 0.48    0.56 ± 0.84   \n",
       "5           gpt-4o-mini       0.84 ± 0.37\\t     -0.1 ± 0.46    0.38 ± 0.74   \n",
       "\n",
       "          BLEU           R1           R2           RL       METEOR  \\\n",
       "0  0.01 ± 0.02  0.12 ± 0.08  0.02 ± 0.04  0.11 ± 0.08  0.12 ± 0.09   \n",
       "1  0.01 ± 0.01   0.1 ± 0.08  0.01 ± 0.03   0.1 ± 0.07  0.11 ± 0.08   \n",
       "2  0.01 ± 0.01  0.11 ± 0.07  0.01 ± 0.03   0.1 ± 0.07  0.12 ± 0.08   \n",
       "3  0.01 ± 0.02  0.13 ± 0.09  0.02 ± 0.04  0.11 ± 0.08  0.13 ± 0.09   \n",
       "4  0.01 ± 0.02  0.12 ± 0.08  0.02 ± 0.04  0.11 ± 0.07  0.12 ± 0.09   \n",
       "5  0.01 ± 0.01  0.13 ± 0.08  0.02 ± 0.03  0.12 ± 0.07  0.14 ± 0.09   \n",
       "\n",
       "  BERTScore_Prec  ...            ` Persona Distance response_time  \\\n",
       "0    0.81 ± 0.17  ...   0.06 ± 0.1      0.45 ± 0.17   4.28 ± 0.26   \n",
       "1     0.8 ± 0.19  ...   0.08 ± 0.1      0.46 ± 0.18   3.87 ± 0.72   \n",
       "2    0.82 ± 0.13  ...  0.05 ± 0.08      0.46 ± 0.15   2.21 ± 0.67   \n",
       "3    0.85 ± 0.02  ...  0.07 ± 0.11      0.47 ± 0.15   0.91 ± 0.21   \n",
       "4    0.85 ± 0.02  ...  0.06 ± 0.07      0.47 ± 0.14    1.84 ± 0.5   \n",
       "5    0.85 ± 0.03  ...  0.05 ± 0.07      0.48 ± 0.13   0.94 ± 0.28   \n",
       "\n",
       "  Failure Ratio UniEval Naturalness UniEval Coherence UniEval Engagingness  \\\n",
       "0  0.043 ± 0.00         0.92 ± 0.19       0.92 ± 0.25          2.42 ± 1.12   \n",
       "1  0.052 ± 0.00          0.9 ± 0.21       0.93 ± 0.23          2.55 ± 1.18   \n",
       "2  0.024 ± 0.00         0.93 ± 0.15       0.97 ± 0.15          2.98 ± 1.18   \n",
       "3    0.0 ± 0.00         0.96 ± 0.02       0.97 ± 0.13          2.33 ± 0.83   \n",
       "4    0.0 ± 0.00         0.96 ± 0.01       0.98 ± 0.05          2.43 ± 0.78   \n",
       "5  0.001 ± 0.00         0.96 ± 0.03       0.99 ± 0.03           2.9 ± 0.84   \n",
       "\n",
       "  UniEval Groundedness UniEval Understandability UniEval Overall  \n",
       "0          0.45 ± 0.43               0.92 ± 0.19     1.12 ± 0.32  \n",
       "1          0.54 ± 0.44               0.89 ± 0.21     1.16 ± 0.35  \n",
       "2          0.44 ± 0.44               0.93 ± 0.15     1.25 ± 0.31  \n",
       "3           0.28 ± 0.4               0.95 ± 0.02      1.1 ± 0.18  \n",
       "4          0.53 ± 0.42               0.96 ± 0.01     1.17 ± 0.18  \n",
       "5          0.57 ± 0.41               0.96 ± 0.03     1.27 ± 0.19  \n",
       "\n",
       "[6 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pd.read_excel(f'../Evaluations/{Dataset}{COT_}-results.xlsx')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
